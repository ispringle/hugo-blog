[{"content":"At least for a while, my time with Emacs has once again come to an end. It is not exactly the fault of Emacs, but the tooling at work is new and niche and there is no or nearly no userbase within the Emacs community that uses this tooling, which makes for a distinct lack of support in the Emacs ecosystem. As a result, I am going to take a Sabbatical from the world of Emacs and try something completely new to me, VS Code. A few reasons for this, but the primary one is that it is the tooling being used at work by the people who I work the closest with and I think there is something to be said for having a standardized toolset for a team.\nThe blog is not going away, but it will have to be somehow changed. Currently there is no support for Markdown. I could write Orgmode still but a lot of those features are very dependent on the Emacs world and I am not sure how it would work elsewhere. I could also keep using Emacs for blogging and notetaking, but I think I am going to take this time to experiment with some other choices. I tried Logseq briefly before and I like its method for notetaking, so I may try that again. I have some concerns about how that would work for blogging, but maybe I can separate those concerns.\nI think I will also take this time to convert the blog to Astro and give Solid.js a try as well. Both are tools I want to learn, and I had given Astro a few days before but could not convince it to parse orgmode files, so I had given up. But it does support Markdown and MDX, so I think I will go with that. I really want to explore writing that includes interactive elements, so MDX is very attractive to me.\nCurrently I am clocking somewhere between 55 and 60 hours a week for two different jobs, so I will likely not get to this anytime soon. But we shall see what happens. One idea I had was to export this blog (likely sans the kb) to Hugo and then use the Hugo SSG and Markdown for a while. Then when I have more time I can come back and figure out how to move to Astro. I have some ideas I want to try, including a microblogging format of sorts, so something more than Hugo is definitely my endgoal still.\n","permalink":"http://ianist.neocities.org/blog/fare-thee-well-emacs/","summary":"At least for a while, my time with Emacs has once again come to an end. It is not exactly the fault of Emacs, but the tooling at work is new and niche and there is no or nearly no userbase within the Emacs community that uses this tooling, which makes for a distinct lack of support in the Emacs ecosystem. As a result, I am going to take a Sabbatical from the world of Emacs and try something completely new to me, VS Code.","title":"Fare Thee Well, Emacs"},{"content":"Hey! I\u0026rsquo;m back after a two-ish week paternity leave. We had a baby girl on October 6th and I\u0026rsquo;ve been more or less offline since then. Our baby girl is named Penelope. Mother and baby are both doing just fine, and we are working on adjusting to the change. The most notable adjustment is that things take longer. After three children, number four really is not that much more difficult.\nIn addition to this lovely change, I\u0026rsquo;ve also started a new job as a \u0026ldquo;Senior Software Engineer\u0026rdquo; at Jack Henry. I\u0026rsquo;m working on their Banno product, which is a banking software offering for small banks and credit unions. It\u0026rsquo;s largely a NodeJS+Lit stack – so JavaScript all around. I\u0026rsquo;m specfically working on the \u0026ldquo;Customs\u0026rdquo; team which implements custom features and plugins for banks.\nI am also working part time at Hydrobuilder still. That will continue for a while, at least until they are able to find a suitable replacement – but how can I be replaced!?\n","permalink":"http://ianist.neocities.org/blog/i-am-back/","summary":"Hey! I\u0026rsquo;m back after a two-ish week paternity leave. We had a baby girl on October 6th and I\u0026rsquo;ve been more or less offline since then. Our baby girl is named Penelope. Mother and baby are both doing just fine, and we are working on adjusting to the change. The most notable adjustment is that things take longer. After three children, number four really is not that much more difficult.","title":"I Am Back"},{"content":"I have spent the last couple days hacking away at AstroJS. I think it might provide what I want in a framework. It produces static sites with no, to minimal client-side JS, and it is itself a JS framework. SSG is important mostly at a philosophical level for me, Lightscores aside, the overhead of SSR or CSR for a blog is minimal and likely unnoticeable, but I enjoy the idea of SSG. I do really like that Astro makes a signficant effort to pre-render as much of the content as possible and deliver as little client-side rendering JS as possible, NextJS is sort of a joke in this regard even though it advertises as SSR it\u0026rsquo;s really more like \u0026ldquo;Server-side-collected-client-side-rendered\u0026rdquo;. You get a massive JSON file that the client then puts together with some JS helpers.\nBeing a JS framework is probably most important. I had this notion in mind when I set out to make this blog, and my brief use of Hugo reminded me of this. I actually could probably be very content with a non-JS framework if it had JS-level support for frontend technology. A statically generated blog is largely a backend beast, in fact by the time we\u0026rsquo;re talking HTML it\u0026rsquo;s really just a few directories and a server or reverse-proxy. It\u0026rsquo;s how that HTML is generated that is the question and the best tooling for generating HTML+CSS+maybe-JavaScript is hands down the JS/Node ecosystem.\nAll of this to say, I tried Astro and it was a bit of a flop. Not entirely Astro\u0026rsquo;s fault, I\u0026rsquo;m sure it\u0026rsquo;s a great little framework that creates great results, however I never got that far because I couldn\u0026rsquo;t coax it into producing anything with my Orgmode files. I attempted to build an Astro plugin to consume the .org files and convert it to something that Astro can handle. The real problem is in the something and also in the notion of \u0026ldquo;Astro plugin\u0026rdquo;. The sense of being helpless, due to a distinct lack of most documentation on the subject and a very lackluster showing for the little documention that did exist, plus a rather non-existent community presence when it comes to the plugin world, did not help at all.\nHere\u0026rsquo;s the rub about plugins in Astro; they\u0026rsquo;re only sort-of Astro plugins. They\u0026rsquo;re actually Vite plugins with a slightly modified syntax for loading so that they get loaded by the Astro core instead of the Vite core. And here\u0026rsquo;s the rub for Vite plugins; they\u0026rsquo;re only sort-of Vite plugins. They\u0026rsquo;re actually Rollup plugins with a slightly modified syntax for loading so that… you get the idea. This makes the documentation fractured and confusing. What do I return? A String? Well okay but what\u0026rsquo;s the format of the string? HTML? No. JS! … that\u0026rsquo;s ambiguous. Okay what sort of JS? A function? Wait… it\u0026rsquo;s a string of JS…\nYes, I had a lot of headache. I gave up actually. The best I got was an error stating that I did not have a proper renderer to render my content and that I needed to install one. But the options were Vue, React, or Lit. The content was the string \u0026ldquo;Help me!\u0026rdquo;. I\u0026rsquo;m unsure how any of those would render that…\nAnd that\u0026rsquo;s the something I was referring to earlier, what do I return exactly? It\u0026rsquo;s a string that is JS, it seems sort of low effort, but I could be wrong, I\u0026rsquo;m not smart enough to write any of these tools.\nAt least for the time being I think I\u0026rsquo;ll be sticking with NextJS, though I do plan to start implementing some changes to the UI because I sort of liked some of the things I ended up doing with Hugo from a aesthetics point-of-view.\n","permalink":"http://ianist.neocities.org/blog/astro-was-a-failure-to-launch/","summary":"I have spent the last couple days hacking away at AstroJS. I think it might provide what I want in a framework. It produces static sites with no, to minimal client-side JS, and it is itself a JS framework. SSG is important mostly at a philosophical level for me, Lightscores aside, the overhead of SSR or CSR for a blog is minimal and likely unnoticeable, but I enjoy the idea of SSG.","title":"Astro Was A Failure To Launch"},{"content":"I\u0026rsquo;ve been playing with ox-hugo for a few days now. I do like a lot about it. One thing I like a lot is how it is focused on getting out of the way and just turning org files into well crafted HTML. I am rather unpleased with ox-hugo\u0026rsquo;s path for deployment, it\u0026rsquo;s a bit more manual than I like. I tried to automate it but hit a roadblock. I\u0026rsquo;ll definitely be trying this again later because the current solution isn\u0026rsquo;t acceptable to me. This is going to sound weird, but ox-hugo expects you to know all the files you want to publish, whereas Sylvan checks them for you and says \u0026ldquo;oh this is publishable and this is not.\u0026rdquo; That means that you make the conscience effort to say \u0026ldquo;publish this\u0026rdquo; but in the future you do not need to recall back to what was and what wasn\u0026rsquo;t published.\nI also dislike how unorganized the Hugo project feels. This alone is keeping me from committing to ox-hugo/Hugo. I\u0026rsquo;m somewhat displeased with Sylvan, but I can\u0026rsquo;t put my finger on the why. Part of it is because at the moment, Sylvan is wholly un-reusable. It is entirely mine and while that\u0026rsquo;s okay it was not what I was setting out to build. At some future point I may come to address this issue, but I am going to set it aside, because for the time being, if I\u0026rsquo;m not happy with Sylvan, no one will be, so there is little point in trying to build it in that direction.\nA positive outcome from the exploration into Hugo is that I had a chance to look at some stylistic things and layout ideas. I think my Sylvan is currently a bit on the unreadable side and I will address that before too long. One think I might look at in a future iteration of Sylvan… a Sylvan 1.0 – since this is very much a 0.x build – is using Astro to create a static site. There is no reason why Sylvan must be SSR\u0026rsquo;d, it could very easily be setup to use a SSG and I think I will pursue this before I start looking at anything else – other than styling and readability.\n","permalink":"http://ianist.neocities.org/blog/a-few-days-with-ox-hugo/","summary":"I\u0026rsquo;ve been playing with ox-hugo for a few days now. I do like a lot about it. One thing I like a lot is how it is focused on getting out of the way and just turning org files into well crafted HTML. I am rather unpleased with ox-hugo\u0026rsquo;s path for deployment, it\u0026rsquo;s a bit more manual than I like. I tried to automate it but hit a roadblock. I\u0026rsquo;ll definitely be trying this again later because the current solution isn\u0026rsquo;t acceptable to me.","title":"A Few Days With ox-hugo"},{"content":"I am giving ox-hugo another try. A few reasons, primarily, my NextJS efforts started feeling like holding water in my hands, and second ox-hugo is just closer to the metal, so to speak. The site will probably change apperance for a while but I hope to get it back to a close approximation of what I have style-wise currently. This post will likely be shown on the NextJS version of the blog for a while and then once I\u0026rsquo;ve gotten a deployment process setup I\u0026rsquo;ll switch to the Hugo site.\n","permalink":"http://ianist.neocities.org/blog/giving-ox-hugo-another-try/","summary":"I am giving ox-hugo another try. A few reasons, primarily, my NextJS efforts started feeling like holding water in my hands, and second ox-hugo is just closer to the metal, so to speak. The site will probably change apperance for a while but I hope to get it back to a close approximation of what I have style-wise currently. This post will likely be shown on the NextJS version of the blog for a while and then once I\u0026rsquo;ve gotten a deployment process setup I\u0026rsquo;ll switch to the Hugo site.","title":"Giving ox-hugo Another Try"},{"content":" ","permalink":"http://ianist.neocities.org/game/a-test/","summary":" ","title":"A Test"},{"content":"Sylvan is a work-in-progress, and probably will never be finished. It was my work towards an ergonomic site-generator for org-mode. I have more or less abandoned it, as I felt constrained by the Uniorg parser, but more to the point, I was concerned with the how of converting it from a very specific and custom site to one that could be used by anyone. I felt like the effort needed to take the Sylvan project to that point was fairly high, and there already existed a few better options. Sure, there isn\u0026rsquo;t a nodejs option that is low-friction, but my project would be better as a template/starter for someone and not as a framework or platform. So, to the end, I think it has served it\u0026rsquo;s purpose and is a decent example of how to get a nodejs based, org-mode capable site-generator up and running.\n","permalink":"http://ianist.neocities.org/project/sylvan/","summary":"Sylvan is a work-in-progress, and probably will never be finished. It was my work towards an ergonomic site-generator for org-mode. I have more or less abandoned it, as I felt constrained by the Uniorg parser, but more to the point, I was concerned with the how of converting it from a very specific and custom site to one that could be used by anyone. I felt like the effort needed to take the Sylvan project to that point was fairly high, and there already existed a few better options.","title":"Sylvan"},{"content":"To me the idea of \u0026ldquo;sylvan\u0026rdquo; is a tool meant to easily create beautiful sites with org-mode, while remaining unintrusive. For that reason, I am exploring some alternative, non-NextJS options for Sylvan. There\u0026rsquo;s a few reasons for this:\nAs I\u0026rsquo;ve expressed before, I\u0026rsquo;m not 100% thrilled with Sylvan as it exists today As I\u0026rsquo;ve expressed before, I\u0026rsquo;d love for a more emacs-centric tooling, but I dislike the constraints of ox-html I am taking a new job on October 10th and my primary frontend framework will be lit.dev, and I think there could be a far more interesting future for Sylvan in the world of web-components NextJS can produce static sites, but it\u0026rsquo;s very difficult to coax it into that box, and I\u0026rsquo;d prefer a site that\u0026rsquo;s statically compiled So to this end, I am experimenting with new options for the idea of Sylvan. My current experiments involve augmenting ox-html by deriving a new export backend for org-mode from it. The current working theory is that any element can be templated, if desired, and if it is templated than Sylvan will use that template file as its definition for that org element. Any elements not defined will fallback to the ox-html element. I\u0026rsquo;m not sure if this is even possible, but I\u0026rsquo;m going to give it a shot and see what I can do!\n","permalink":"http://ianist.neocities.org/blog/perhaps-a-new-path-for-sylvan/","summary":"To me the idea of \u0026ldquo;sylvan\u0026rdquo; is a tool meant to easily create beautiful sites with org-mode, while remaining unintrusive. For that reason, I am exploring some alternative, non-NextJS options for Sylvan. There\u0026rsquo;s a few reasons for this:\nAs I\u0026rsquo;ve expressed before, I\u0026rsquo;m not 100% thrilled with Sylvan as it exists today As I\u0026rsquo;ve expressed before, I\u0026rsquo;d love for a more emacs-centric tooling, but I dislike the constraints of ox-html I am taking a new job on October 10th and my primary frontend framework will be lit.","title":"Perhaps A New Path For Sylvan"},{"content":"We may or may not have a new baby in the next few days. My wife has been laboring since yesterday. The midwife and I think it won\u0026rsquo;t be much longer now. What makes this awkward is I just accepted a new job and while the new job is going to throw paternity time at me from day one, I have to get to day one first, which isn\u0026rsquo;t until October 3rd.\nMight make for an interesting next three weeks.\n","permalink":"http://ianist.neocities.org/blog/baby-incoming/","summary":"We may or may not have a new baby in the next few days. My wife has been laboring since yesterday. The midwife and I think it won\u0026rsquo;t be much longer now. What makes this awkward is I just accepted a new job and while the new job is going to throw paternity time at me from day one, I have to get to day one first, which isn\u0026rsquo;t until October 3rd.","title":"Baby, Incoming?"},{"content":"You might not know it since we\u0026rsquo;re going on almost a week since a content update to the site, but I have been doing some refactoring work on the sylvan project. I\u0026rsquo;ve cut build times in half by updating the build-api. An added benefit of this rebuild is that I can now properly use rehype plugins (retext too!). Currently I\u0026rsquo;ve got rehype-raw working which means I can add begin-export html blocks to my org files and they will populate on the site as actual HTML (and I think react, but I have not tried this yet so I do not know for sure). I\u0026rsquo;ve also been working on a refactor of the styling, not the actual look but the code behind it. Some stuff will be changing but it\u0026rsquo;s because of the updates to the code and then me making minor tweaks to the looks at the same time.\nAll this is being done in an effort to make future features easier to implement, such as making Sylvan configurable and useable by others.\n","permalink":"http://ianist.neocities.org/blog/hard-at-work/","summary":"You might not know it since we\u0026rsquo;re going on almost a week since a content update to the site, but I have been doing some refactoring work on the sylvan project. I\u0026rsquo;ve cut build times in half by updating the build-api. An added benefit of this rebuild is that I can now properly use rehype plugins (retext too!). Currently I\u0026rsquo;ve got rehype-raw working which means I can add begin-export html blocks to my org files and they will populate on the site as actual HTML (and I think react, but I have not tried this yet so I do not know for sure).","title":"Hard At Work"},{"content":"You\u0026rsquo;ll notice that my site has some nice new styles going on. I was playing with a fork of Sylvan that used Chakra-UI, however I have since trashed that because I couldn\u0026rsquo;t get the layout I wanted (after giving up on the route I then updated how my site is laid out and this ended up meaning that Chakra or Mantine or really any other components library would have actually worked\u0026hellip;). But that sparked some renewed effort into fixing the styles. Initially I was just looking for better heading font sizes and I found a way to do that, so then I started playing with some other ideas, inspired by various sites I like the look of. I think I will mostly stay with this current style, however I think I will also implement some sort of \u0026ldquo;theme\u0026rdquo; engine eventually that will let me have loads of themes, and each theme will then have a light and dark mode.\nThe current technical setup is okay \u0026ndash; and you can checkout how I\u0026rsquo;m doing it on the Sylvan project repo \u0026ndash; but I\u0026rsquo;m not sure I am ultimately satisfied with just having a light and dark mode. But at the same time\u0026hellip; I really like this look and don\u0026rsquo;t want to ultimately trash it. I think my next effort will be to differentiate between \u0026ldquo;themes\u0026rdquo; and \u0026ldquo;color scheme\u0026rdquo; so that I can then easily just load in a different style. This will probably also involve me refactoring the CSS into modules so as to avoid collisions and also will probably mean an easier time interacting with the CSS via JS.\nThis current theme is giving me Pokemon vibes. I might try to implement my own border-image with the little balls in the corners like in the original Pokemon games. I\u0026rsquo;ve also been adding little easter eggs into the site just for fun, might be worth keeping an eye out to see if you can find them all (gotta catch \u0026rsquo;em all)!\nAnd finally, I discovered through this that something is very wrong with either NextJS, Vercel, or my GitHub action. Sylvan was building perfectly fine on my machine but deploying to GH resulted in an error. Somewhere, something does not like my usage of the pages/api/ stuff. I have consigned to giving up on Vercel and will eventually be moving my project to my own infrastructure. I have the Dockerimage built and will do a little testing to make sure it\u0026rsquo;s all good and working, and then I\u0026rsquo;ll flp the switch and say goodbye to Vercel. Likely this will mean I\u0026rsquo;m moving my org repo, and perhaps even Sylvan to Gitlab because honestly I hate GitHub Actions and have only ever experienced pain when trying to build and deploy containers via GitHub Actions Likely this will mean I\u0026rsquo;m moving my org repo, and perhaps even Sylvan to Gitlab because honestly I hate GitHub Actions and have only ever experienced pain when trying to build and deploy containers via GitHub Actions.\n","permalink":"http://ianist.neocities.org/blog/nice-new-look/","summary":"You\u0026rsquo;ll notice that my site has some nice new styles going on. I was playing with a fork of Sylvan that used Chakra-UI, however I have since trashed that because I couldn\u0026rsquo;t get the layout I wanted (after giving up on the route I then updated how my site is laid out and this ended up meaning that Chakra or Mantine or really any other components library would have actually worked\u0026hellip;).","title":"Nice New Look"},{"content":"In a previous post I talked about a function I wrote that allowed me to stub out a few of the properties required for working with Sylvan. I have since updated that function a little. It\u0026rsquo;s still not ideal and I have one or two issues with it still, but I wanted to share the updated function nonetheless. As a sidenote, unless I outright delete this function for some reason, it shall always be visible in it\u0026rsquo;s most up to date from in my literate config.\nThis function now prompts for a post title, turns that into a filename, creates a buffer, writes out some initial data to that buffer, saves it to a file, and then let\u0026rsquo;s you continue writing it.\n(defun 0x44/create-new-blog-buffer () \u0026#34;Created a new blog from the specified template in a new buffer\u0026#34; (interactive) (let* (($timestamp (format-time-string \u0026#34;\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;\u0026#34; )) (title (read-from-minibuffer \u0026#34;Post Title: \u0026#34;)) (fname (concat org-blog-directory \u0026#34;/\u0026#34; (org-hugo-slug title) \u0026#34;.org\u0026#34;))) (let (($buf (generate-new-buffer title))) (switch-to-buffer $buf) (insert (format \u0026#34;:PROPERTIES:\\n:AUTHOR: %s\\n:CREATED: %s\\n:MODIFIED: %s\\n:TYPE: blog\\n:END:\\n#+title: %s\u0026#34; user-full-name $timestamp $timestamp title)) (funcall \u0026#39;org-mode) (funcall \u0026#39;org-id-new) (setq buffer-offer-save t) (set-visited-file-name fname) $buf))) You\u0026rsquo;ll notice I am using a function from ox-hugo. This is literally the only reason I have that package, so I\u0026rsquo;d like to get that dependency removed somehow eventually.\nI am not sure if (set-visited-file-name) is the appropriate function to use here, but I have been unable to find any other functions that will save the buffer to a file and then ensure that the buffer is now set to that saved file.\nThis little function works very nicely and is a marked improvement on the previous function.\n","permalink":"http://ianist.neocities.org/blog/a-better-template-func/","summary":"In a previous post I talked about a function I wrote that allowed me to stub out a few of the properties required for working with Sylvan. I have since updated that function a little. It\u0026rsquo;s still not ideal and I have one or two issues with it still, but I wanted to share the updated function nonetheless. As a sidenote, unless I outright delete this function for some reason, it shall always be visible in it\u0026rsquo;s most up to date from in my literate config.","title":"A Better Template Func"},{"content":"My experience with Emacs can be split into two parts:\nEmacs with doom Realizing Doom didn\u0026rsquo;t load and quitting Emacs as quickly as possible and trying to figure out how to get back into Doom I have been experiencing some annoyances with emacs lately. It hangs or lags or chokes on large files (over 1000 lines) and it crashes sometimes. Partly out of a desire to strip back and get a leaner emacs, and partly out of a desire to really \u0026ldquo;try\u0026rdquo; emacs without the help of someone else\u0026rsquo;s config, I am going to attempt to build my own emacs from scratch. Of course it\u0026rsquo;ll be comfy in honor of comfy.vim, comfy.nvim, and comfy.tmux. I\u0026rsquo;ll keep you posted, likely you\u0026rsquo;ll start seeing something pop up in the index before you hear from me about it.\n","permalink":"http://ianist.neocities.org/blog/emacs-from-scratch-part-0/","summary":"My experience with Emacs can be split into two parts:\nEmacs with doom Realizing Doom didn\u0026rsquo;t load and quitting Emacs as quickly as possible and trying to figure out how to get back into Doom I have been experiencing some annoyances with emacs lately. It hangs or lags or chokes on large files (over 1000 lines) and it crashes sometimes. Partly out of a desire to strip back and get a leaner emacs, and partly out of a desire to really \u0026ldquo;try\u0026rdquo; emacs without the help of someone else\u0026rsquo;s config, I am going to attempt to build my own emacs from scratch.","title":"Emacs From Scratch, Part 0"},{"content":"I have two major shortcomings that I am working to resolve with orgmode\u0026rsquo;s default org-publish:\nattachments do not work out of the gate it doesn\u0026rsquo;t get me closer to the ox-huge workflow of one blog.org file I have looked at some other potential options for my blog. NextJS is fine, I like it even, but I worked on refactoring to Chakra-UI and it\u0026rsquo;s annoying that it still isn\u0026rsquo;t really working right. The problem currently is that this other package I need called Prose has it\u0026rsquo;s own default theme settings and so everything is wonky. I guess I can get that working, but… I don\u0026rsquo;t know. I looked at the orgmode default export and it\u0026rsquo;s not bad. With a little CSS love it\u0026rsquo;s actually pretty good looking! There are some hacks I could use to make it better. Some people are doing some pretty cool and crazy stuff with their org-publish.\n","permalink":"http://ianist.neocities.org/blog/maybe-easy-is-better/","summary":"I have two major shortcomings that I am working to resolve with orgmode\u0026rsquo;s default org-publish:\nattachments do not work out of the gate it doesn\u0026rsquo;t get me closer to the ox-huge workflow of one blog.org file I have looked at some other potential options for my blog. NextJS is fine, I like it even, but I worked on refactoring to Chakra-UI and it\u0026rsquo;s annoying that it still isn\u0026rsquo;t really working right.","title":"Maybe Easy Is Better"},{"content":"For those who do not know Sylvan is my NextJS app that org files and creates webpages. It\u0026rsquo;s not a static-site generator technically since it\u0026rsquo;s doing server-side rendering, but I currently do not have it setup so that the org files are updated on the fly either (ie content only gets updated when a deployment runs). Fixing this is on the roadmap, but first I want to get it setup to be configurable so that I can, for example, change the header, the favicon, the overall title, etc. from my org repo. This will do two things, first and foremost it will mean Sylvan can be used by others without having to fork the repo, and second it will mean I can make changes to my website without changing the framework that manages the content. I haven\u0026rsquo;t exactly figured out how I plan to do this just yet. I think I will end up going with a sylvan.org file that will have some K/Vs in a drawer and Sylvan can consume that at startup via the Uniorg module and then from there the \u0026lt;nav\u0026gt; links and other things can be updated.\n","permalink":"http://ianist.neocities.org/blog/whats-next-for-sylvan/","summary":"For those who do not know Sylvan is my NextJS app that org files and creates webpages. It\u0026rsquo;s not a static-site generator technically since it\u0026rsquo;s doing server-side rendering, but I currently do not have it setup so that the org files are updated on the fly either (ie content only gets updated when a deployment runs). Fixing this is on the roadmap, but first I want to get it setup to be configurable so that I can, for example, change the header, the favicon, the overall title, etc.","title":"What's Next For Sylvan"},{"content":"At the time of this writing, my blog is still hosted with Vercel, however I think I will eventually move it to my VM. However, all the other sites and services I host have been migrated to my new VM (at the time of writing, only Nextcloud hasn\u0026rsquo;t been migrated, but it never made it into Kubernetes anyway). Why the switch? Well, I started using kubernetes after I took a job as a consultant doing SRE work. I wanted to have my personal infrastructure mirror the work I was doing professionally. Now that I am not doing that kind of work anymore, there is less motivation to keep a K8s cluster going. Additionally and primarily, I had a very hard time figuring out how to migrate Nextcloud to Kubernetes due to the amount of data our family Nextcloud instance already had and decisions I had made about the Nextcloud setup initially. So I opted to keep it on a VM and migrate everything else to K8s. Well, that costs a lot of money, I decided to cut costs and that meant either looking into moving Nextcloud to K8s or moving K8s back to a VM.\nThe decision was made for me when I went to update my resume and noticed that fluxcd was no longer automatically updating docker images when new ones were available. I looked into the problem for an hour or so but eventually just decided this was the writing on the wall and it was time to move back to a VM. I did the migration in a morning. It took about two hours, most of that two hours was spent trying to get my ansible+docker-compose stuff working. Technically that all worked just fine, but I could not get the dockerized Traefik proxy server to work. When I looked into alternatives I found that Caddy had matured a lot since I was last shopping for a reverse proxy. I tried the dockerized Caddy and it didn\u0026rsquo;t work, and then upon reflection I decided it might be a good idea to run my server on the OS level and then proxy to the container with ports. You can checkout the server setup in my literate config file.\n","permalink":"http://ianist.neocities.org/blog/why-i-migrated-from-k8s/","summary":"At the time of this writing, my blog is still hosted with Vercel, however I think I will eventually move it to my VM. However, all the other sites and services I host have been migrated to my new VM (at the time of writing, only Nextcloud hasn\u0026rsquo;t been migrated, but it never made it into Kubernetes anyway). Why the switch? Well, I started using kubernetes after I took a job as a consultant doing SRE work.","title":"Why I Migrated From K8s"},{"content":"Introduction I am migrating from Kubernetes to a VM. The tl;dr on the VM is that it\u0026rsquo;s an Ubuntu machine, serving my various sites and services with Caddy. The sites and services are all running in docker containers and the Caddy server proxies traffic to the specific containers. I am migrating from Kubernetes because it is expensive to run a cluster and it\u0026rsquo;s far more than I need. I had migrated to Kubernetes when I was doing consulting work as an SRE however, I am now very focused on being a developer, and while I don\u0026rsquo;t wish to lose my SRE skillset, I also cannot justify the cost, maintenance, or cognitive load required to keep that cluster up and working, thus a VM. The setup is pretty straightforward, it will not be winning any awards for creativity and it\u0026rsquo;s less than the pinnacle of GitOps. You can checkout the literate server setup here.\nI am interested in a firewall that will expose traffic on the ports I want open and drop all other traffic. There are a lot of tools to do this. There are fire-and-forget tools that will do all the work for you \u0026ndash; these scare me, so I didn\u0026rsquo;t even consider them or look into them at all. There are simpler configuration tools like ipcop and Ubuntu\u0026rsquo;s UFW. I not only considered ufw I started getting it setup and then hit a roadblock because I couldn\u0026rsquo;t find an easy way to DROP everything, including ICMP. I looked into it more and UFW can do this but it has to be written into a before rule and at that point I might as well see what other tools there are because I\u0026rsquo;ve never used UFW beyond the command itself, and my desires seemed to require learning and writing a UFW configuration file.\nA step up from these tools are Shorewall and ferm. I vaguely recall using Shorewall before, but their website scared me off this time around. I looked at ferm and it seemed very simple. Basically both of these tools take in their own configuration file and then output iptables rules. I could just write the iptables rules my self, but then again I could write the netfilter rules too! I settled on ferm because they had clear examples and the configuration language looks very similar to iptables rules and at the end of the day, I can export my configuration to iptables and so if I decide to drop ferm I have not really lost anything.\nferm First thing\u0026rsquo;s first, I checked out the example configs that come with the default Ubuntu install of ferm and then cat\u0026rsquo;d together the ones I was interested in ripping off using. The three I thought looked most useful are webserver.ferm, antiddos.ferm, and ipv6.ferm.\nExamples webserver.ferm # -*- shell-script -*- # # Ferm example script # # Firewall configuration for a web and SMTP server. # # Author: Max Kellermann \u0026lt;max@duempel.org\u0026gt; # @def $NET_TRUSTED = 195.135.144.144/28; table filter { chain INPUT { policy DROP; # connection tracking mod state state INVALID DROP; mod state state (ESTABLISHED RELATED) ACCEPT; # allow local connections interface lo ACCEPT; # respond to ping proto icmp icmp-type echo-request ACCEPT; # remote administration from the company network saddr $NET_TRUSTED proto tcp dport ssh ACCEPT; # our services to the world proto tcp dport (http https smtp) ACCEPT; # the rest is dropped by the above policy } # outgoing connections are not limited chain OUTPUT policy ACCEPT; # this is not a router chain FORWARD policy DROP; } antiddos.ferm # -*- shell-script -*- # # Ferm example script # # Firewall configuration to prevent basic tcp DoS/DDoS attacks # # Authors: Vlad Glagolev \u0026lt;enqlave@gmail.com\u0026gt;, Stepan Rogov \u0026lt;rogov_sa@mail.ru\u0026gt; # @def \u0026amp;ANTIDDOS($ports, $seconds, $hits, $time, $exceptions) = { proto tcp dport $ports @subchain \u0026#34;ddos_check\u0026#34; { # allow every exception as-is saddr $exceptions ACCEPT; # connection tracking mod conntrack ctstate (ESTABLISHED RELATED) ACCEPT; # check for IPs overloading $hits/$seconds rate and block them mod recent name \u0026#34;ddos_check\u0026#34; rcheck seconds $seconds hitcount $hits @subchain \u0026#34;ddos\u0026#34; { mod recent set name \u0026#34;ddos\u0026#34; NOP; DROP; } # register a packet in \u0026#34;ddos_check\u0026#34; list mod recent set name \u0026#34;ddos_check\u0026#34; NOP; # check IP in \u0026#34;ddos\u0026#34; list # if it exists and had been registered in the last $time seconds -- drop it mod recent name \u0026#34;ddos\u0026#34; rcheck seconds $time DROP; # remove packet from \u0026#34;ddos\u0026#34; list mod recent name \u0026#34;ddos\u0026#34; remove NOP; # allow ONLY new connections mod conntrack ctstate NEW ACCEPT; DROP; } } table filter { chain INPUT { policy DROP; # connection tracking mod state state INVALID REJECT; mod state state (ESTABLISHED RELATED) ACCEPT; # allow local connections interface lo ACCEPT; # ban ip addresses for 1 day which connect more than 50 times in 3 seconds, # exception is IP: 94.29.90.101 \u0026amp;ANTIDDOS((80, 443), 50, 3, 86400, 94.29.90.101); # the rest is dropped by the above policy } # outgoing connections are not limited chain OUTPUT policy ACCEPT; # this is not a router chain FORWARD policy DROP; } ipv6.ferm # -*- shell-script -*- # # Ferm example script # # IPv6 demo. # # Author: Max Kellermann \u0026lt;max@duempel.org\u0026gt; # domain ip6 table filter { chain INPUT { policy DROP; # connection tracking mod state state INVALID DROP; mod state state (ESTABLISHED RELATED) ACCEPT; # allow local connections interface lo ACCEPT; # allow ICMP (for neighbor solicitation, like ARP for IPv4) proto ipv6-icmp ACCEPT; # allow SSH connections proto tcp dport ssh ACCEPT; # ident connections are also allowed proto tcp dport auth ACCEPT; # the rest is dropped by the above policy } # outgoing connections are not limited chain OUTPUT policy ACCEPT; # this is not a router chain FORWARD policy DROP; } The Configuration ferm\u0026rsquo;s configuration is pretty straightforward, you tables and chains, you can specific a domain (ip, ipv6) for the table, and you can target specific predefined policies (ACCEPT, DROP, etc.). I am not a networking guy or a firewall guru, but I think I have enough understanding to write something\u0026hellip;\nThe filter Table We\u0026rsquo;ll write to the default table filter:\ntable filter { And we\u0026rsquo;ll start with the INPUT chain:\nchain INPUT { Seems like you start with a your catch-all, in this case I want to DROP anything that isn\u0026rsquo;t explicitly allowed, hopefully this will prevent some attacks just by not advertising this server exists.\npolicy DROP; I am still not entirely sure what \u0026ldquo;connection tracking\u0026rdquo; is or means, but this rules controls this and here is a brief synopsis of the idea.\nmod state state INVALID DROP; mod state state (ESTABLISHED RELATED) ACCEPT; This is rather self-explanatory, we allow local connections through the firewall, it probably is safe to say this won\u0026rsquo;t hurt, if an attacker is coming from local we got bigger fish to fry\u0026hellip;\ninterface lo ACCEPT; Contrary to the default settings, I do not want to respond to ICMP:\nproto icmp icmp-type echo-request DROP; Now for the things that this server needs to have open. The use of dport refers to the intended destination of the request.\nproto tcp dport (http https) ACCEPT; We also want to accept SSH connections. I might change this in the future to be over a port other than the default, but for now 22 is good enough!\nproto tcp dport ssh ACCEPT; Everything else is dropped. We also want to allow all outgoing connections, though I might look into changing this eventually and would like to log all outgoing connections at the very least. And since we\u0026rsquo;re a web server and are not in the business of routing for other machines, we will drop all FOWARD requests.\n} chain OUTPUT policy ACCEPT; chain FORWARD policy DROP; } Anti-DDoS logic To mitigate DDoS attacks, we can define a function to track requests over time for a specfic IP address and if it exceeds a given threshold, we block that address for some length of time. This comes right from the examples document, except I removed the IP address exceptions logic because I don\u0026rsquo;t have a static address and the address I do get is sometimes shared with other Starlink customers.\n@def \u0026amp;ANTIDDOS($ports, $seconds, $hits, $time) = { proto tcp dport $ports @subchain \u0026#34;ddos_check\u0026#34; { mod conntrack ctstate (ESTABLISHED RELATED) ACCEPT; mod recent name \u0026#34;ddos_check\u0026#34; rcheck seconds $seconds hitcount $hits @subchain \u0026#34;ddos\u0026#34; { mod recent set name \u0026#34;ddos\u0026#34; NOP; DROP; } mod recent set name \u0026#34;ddos_check\u0026#34; NOP; mod recent name \u0026#34;ddos\u0026#34; rcheck seconds $time DROP; mod recent name \u0026#34;ddos\u0026#34; remove NOP; mod conntrack ctstate NEW ACCEPT; DROP; } } To use this we want to do two things, first we need to define this before our filter table declaration and in that table we want to replace the line(s) that declare ports we accept with the following which says \u0026ldquo;check requests to ports 22, 88, and 443 to see if the requester has made more than 50 requests in the last three seconds, and if so, drop their request and ban them for 86400 seconds.\u0026rdquo; The docs say to do (22, 80, 443) however if you try to do that ferm will give a warning and rejects the configuration file. According to the error, arrays should not be comma separated but should just have spaces. I have opened an issue for this and hopefully it\u0026rsquo;ll be resolved before anyone else gets confused.\n\u0026amp;ANTIDDOS((22 80 443), 50, 3, 86400); IPv6 My ipv6 filter table is also right from the docs, except I am dropping ICMP and I\u0026rsquo;m routing traffic through the anti-DDoS logic.\ndomain ip6 table filter { chain INPUT { policy DROP; mod state state INVALID DROP; mod state state (ESTABLISHED RELATED) ACCEPT; interface lo ACCEPT; proto ipv6-icmp DROP; \u0026amp;ANTIDDOS((22 80 443), 50, 3, 86400); } chain OUTPUT policy ACCEPT; chain FORWARD policy DROP; } Putting It Together All of that boils down to this fairly succinct ruleset that can be put into /etc/ferm/ferm.conf and then just restart the service. You might actually want to call this the first time with ferm --interactive which will kill ferm if you get locked out due to firewall rules.\n@def \u0026amp;ANTIDDOS($ports, $seconds, $hits, $time) = { proto tcp dport $ports @subchain \u0026#34;ddos_check\u0026#34; { mod conntrack ctstate (ESTABLISHED RELATED) ACCEPT; mod recent name \u0026#34;ddos_check\u0026#34; rcheck seconds $seconds hitcount $hits @subchain \u0026#34;ddos\u0026#34; { mod recent set name \u0026#34;ddos\u0026#34; NOP; DROP; } mod recent set name \u0026#34;ddos_check\u0026#34; NOP; mod recent name \u0026#34;ddos\u0026#34; rcheck seconds $time DROP; mod recent name \u0026#34;ddos\u0026#34; remove NOP; mod conntrack ctstate NEW ACCEPT; DROP; } } table filter { chain INPUT { policy DROP; mod state state INVALID DROP; mod state state (ESTABLISHED RELATED) ACCEPT; interface lo ACCEPT; proto icmp icmp-type echo-request DROP; \u0026amp;ANTIDDOS((22 80 443), 50, 3, 86400); } chain OUTPUT policy ACCEPT; chain FORWARD policy DROP; } domain ip6 table filter { chain INPUT { policy DROP; mod state state INVALID DROP; mod state state (ESTABLISHED RELATED) ACCEPT; interface lo ACCEPT; proto ipv6-icmp DROP; \u0026amp;ANTIDDOS((22 80 443), 50, 3, 86400); } chain OUTPUT policy ACCEPT; chain FORWARD policy DROP; } Conclusion I will likely be playing with this for a while and change things to adapt with time. I would like to get better observability into what is being hit, by whom, etc. and when I have that I can review incoming requests, pick out problematic patterns and work to shut them down. This will mean changes to the firewall. My ever-up-to-date firewall configuration can be found in my literate server configuration under the firewall heading. In the future, I would like to also add fail2ban to my setup, however I have read something about how ferm can wipe out f2b\u0026rsquo;s tables and I want to research into this some more before I incorporate it into my setup. Another idea I had was to use ferm to create the iptables values and then directly insert them into iptables. This might or might not be a good idea, but it\u0026rsquo;s something I might look into.\n","permalink":"http://ianist.neocities.org/blog/setting-up-a-firewall/","summary":"Introduction I am migrating from Kubernetes to a VM. The tl;dr on the VM is that it\u0026rsquo;s an Ubuntu machine, serving my various sites and services with Caddy. The sites and services are all running in docker containers and the Caddy server proxies traffic to the specific containers. I am migrating from Kubernetes because it is expensive to run a cluster and it\u0026rsquo;s far more than I need. I had migrated to Kubernetes when I was doing consulting work as an SRE however, I am now very focused on being a developer, and while I don\u0026rsquo;t wish to lose my SRE skillset, I also cannot justify the cost, maintenance, or cognitive load required to keep that cluster up and working, thus a VM.","title":"Setting Up A Firewall"},{"content":"Me, the jury of one, is still out on whether I will continue with the Uniorg+NextJS or attempt to find a different solution. The current trouble? Parsing of Orgmode verse blocks results in a \u0026lt;pre\u0026gt; , which is not at all what I want. I could make most of the verse blocks, most of the time, look good. But what if it contains superscript text? In Org that looks like a ^{I am superscript} or a ^superscript. But when that translates to HTML it ends up being wrapped as \u0026lt;sup\u0026gt;I am superscript\u0026lt;/sup\u0026gt; which doesn\u0026rsquo;t work with the \u0026lt;pre\u0026gt; block since these blocks render text verbatim. This is a problem for Bible verses which have whitespace formatting (which is that the Orgmode verse block is meant to preserve) but also have superscript text for the verse numbers. Take a look at Isaiah 8:13:\n﻿13 It is Yahweh of hosts whom you should regard as holy.\nAnd He shall be your fear,\nAnd He shall be your cause of trembling.\nThis is extra tricky, not only is there some whitespace formatting, but the superscript is the very first element in the text which, in Orgmode, requires that you use a special zero-width, non-breaking space character.\nWhat to do? I don\u0026rsquo;t know. I was just getting happy with the idea of continuing with NextJS+Uniorg too. Suffice to say, I am going to continue plodding away at my build system for org-publish, because the exported Orgmode HTML does a wonderful job of properly displaying this exact situation:\n\u0026lt;p class=\u0026#34;verse\u0026#34;\u0026gt; ﻿\u0026lt;sup\u0026gt;13\u0026lt;/sup\u0026gt; It is Yahweh of hosts whom you should regard as holy.\u0026lt;br\u0026gt; \u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;And He shall be your fear,\u0026lt;br\u0026gt; \u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;And He shall be your cause of trembling.\u0026lt;br\u0026gt; ﻿\u0026lt;sup\u0026gt;14\u0026lt;/sup\u0026gt; Then He shall become a sanctuary;\u0026lt;br\u0026gt; \u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;But to both the houses of Israel, a stone to strike and a rock to stumble over,\u0026lt;br\u0026gt; \u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;And a snare and a trap for the inhabitants of Jerusalem.\u0026lt;br\u0026gt; ﻿\u0026lt;sup\u0026gt;15\u0026lt;/sup\u0026gt; And many will stumble over them;\u0026lt;br\u0026gt; \u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;Then they will fall and be broken;\u0026lt;br\u0026gt; \u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;They will even be snared and caught.”\u0026lt;br\u0026gt; \u0026lt;/p\u0026gt; ","permalink":"http://ianist.neocities.org/blog/still-undecided/","summary":"Me, the jury of one, is still out on whether I will continue with the Uniorg+NextJS or attempt to find a different solution. The current trouble? Parsing of Orgmode verse blocks results in a \u0026lt;pre\u0026gt; , which is not at all what I want. I could make most of the verse blocks, most of the time, look good. But what if it contains superscript text? In Org that looks like a ^{I am superscript} or a ^superscript.","title":"Still Undecided"},{"content":"So, I\u0026rsquo;m thinking about the concept of digital gardens, the ideas behind Zettelkasten, and my own interpretation of that I am currently calling \u0026ldquo;Grok\u0026rdquo;. I was reading on another digital garden about this historic concept called \u0026ldquo;commonplace books\u0026rdquo; or \u0026ldquo;commonplaces\u0026rdquo;. The idea goes back further to this Latin term called locus communis, and it goes back even further to the Greek idea of \u0026ldquo;τόπος κοινός\u0026rdquo; (topos koinos) or \u0026ldquo;literary topos\u0026rdquo;. John Locke even wrote a book on this idea called A New Method of Making Common-Place-Books. I\u0026rsquo;m interested in this for a couple reasons; first it\u0026rsquo;s interesting to see that my desire to have some place to store my ideas is shared with many in antiquity, and second as I am refining this concept and building on it and how I want to treat it conceptually as well as in practice, it\u0026rsquo;s handy to see how others, both present and past, have treated this same sort of concept. I think I ultimately dislike the Zettelkasten, at least for me because it is too fine-grained and too keyed into specfic topics. I am not a researcher, I just like a broad array of things and I enjoy seeing their interconnectedness.\nThis commonplacing (not sure if that\u0026rsquo;s a coined term or not) idea is something I find really attractive because instead of being a repository for specfic, well crafted, and atomic thoughts, it is instead a repository for a myriad of thoughts, quotes, ideas, and excerpts on a whole array of topics.\nLikely, at some future time I will update the name of my digital garden to be more in tune with this historic concept. We\u0026rsquo;ll see\u0026hellip;\n","permalink":"http://ianist.neocities.org/blog/commonplacing/","summary":"So, I\u0026rsquo;m thinking about the concept of digital gardens, the ideas behind Zettelkasten, and my own interpretation of that I am currently calling \u0026ldquo;Grok\u0026rdquo;. I was reading on another digital garden about this historic concept called \u0026ldquo;commonplace books\u0026rdquo; or \u0026ldquo;commonplaces\u0026rdquo;. The idea goes back further to this Latin term called locus communis, and it goes back even further to the Greek idea of \u0026ldquo;τόπος κοινός\u0026rdquo; (topos koinos) or \u0026ldquo;literary topos\u0026rdquo;. John Locke even wrote a book on this idea called A New Method of Making Common-Place-Books.","title":"Commonplacing"},{"content":"While looking further into ox-hugo I decided to also look further into just bog-standard org-publish. I already had some elisp to build out my org files to html and I decided to break that elisp down into a literate program that is then compiled into a build directory which contains all the shell, elisp, CSS, and Dockerfiles I need to build and deploy a website built with org-publish. I am not currently using this to deploy this or any other website, but I was pretty happy with the result and wanted to share. I think I could quickly get a website that is almost identical to my current NextJS site.\nYou can check out the build script and see how I\u0026rsquo;m doing it.\n","permalink":"http://ianist.neocities.org/blog/publishing-with-org-publish/","summary":"While looking further into ox-hugo I decided to also look further into just bog-standard org-publish. I already had some elisp to build out my org files to html and I decided to break that elisp down into a literate program that is then compiled into a build directory which contains all the shell, elisp, CSS, and Dockerfiles I need to build and deploy a website built with org-publish. I am not currently using this to deploy this or any other website, but I was pretty happy with the result and wanted to share.","title":"Publishing with org-publish"},{"content":"I got a new puppy today! I still don\u0026rsquo;t have a name for him. He\u0026rsquo;s a Catahoula Leopard dog. That tail is gonna take some getting used to, it\u0026rsquo;s not docked, that\u0026rsquo;s just what they call a \u0026ldquo;bob\u0026rdquo; tail, it\u0026rsquo;s natural and common on this breed.\n","permalink":"http://ianist.neocities.org/blog/new-puppy/","summary":"I got a new puppy today! I still don\u0026rsquo;t have a name for him. He\u0026rsquo;s a Catahoula Leopard dog. That tail is gonna take some getting used to, it\u0026rsquo;s not docked, that\u0026rsquo;s just what they call a \u0026ldquo;bob\u0026rdquo; tail, it\u0026rsquo;s natural and common on this breed.","title":"New Puppy!"},{"content":"So I\u0026rsquo;ve spent some time playing with Hugo and more specifically, I\u0026rsquo;ve been playing with ox-hugo which is a way of exporting Org files to Markdown that plays nicely with Hugo. I\u0026rsquo;m not happy with my current blog setup. I like the Sylvan site and NextJS, but blogging with it is cumbersome, in part because of the Org parser I am using. In JavaScript land there are two Org parsers, one is mostly abondonware and the other is called Uniorg. It\u0026rsquo;s great for what it is, but it\u0026rsquo;s not refined, it has a very poor way of interacting with it, it feels fragile, and the author has expressed disinterest in support rather common and crucial Orgmode features \u0026ndash; such as multiple drawers in a document, non-PROPERTIES drawers (ie LOGBOOK), and subtrees.\nIn my opinion none of these are inherintly a deal breaker, and all are things I could remedy by forking the project and building my own off of it. But, I\u0026rsquo;m not interested in spending a huge time on this and if I did, why limit myself to JavaScript? I see a few potential options:\nUse Hugo, it works out of the box and produces a very satisfactory website with nearly no fuss Fork Uniorg and add the myriad features I\u0026rsquo;d like to see Use another parser all together, such as this python parser, and then decide what to do about serving Some things in ox-huge/hugo\u0026rsquo;s favor:\nit just works converting my stylings to hugo shouldn\u0026rsquo;t be too hard ox-hugo supports a LOT of org features files attached to org files are ported it\u0026rsquo;s static Some things that I\u0026rsquo;m a little concerned about:\nNo server means less cool things No node means harder to do cool JS things I might flip the switch and if I do, you\u0026rsquo;ll know\u0026hellip;\n","permalink":"http://ianist.neocities.org/blog/playing-with-hugo/","summary":"So I\u0026rsquo;ve spent some time playing with Hugo and more specifically, I\u0026rsquo;ve been playing with ox-hugo which is a way of exporting Org files to Markdown that plays nicely with Hugo. I\u0026rsquo;m not happy with my current blog setup. I like the Sylvan site and NextJS, but blogging with it is cumbersome, in part because of the Org parser I am using. In JavaScript land there are two Org parsers, one is mostly abondonware and the other is called Uniorg.","title":"Playing With Hugo"},{"content":"Well\u0026hellip; it has happened again. The last time it was because of the YAML format interpretting timestamps as UTC unless explicitly set otherwise. And I fixed that issue\u0026hellip; but that won\u0026rsquo;t help this, since I gave up on using Contentlayer like two days later 😭.\nI\u0026rsquo;m not sure the reason for the problem this time. I even updated the timezone for the GH action so that it would be set to CST. Nonetheless, the date entries in the indices (anywhere that is listing blog posts or content) is a whole day earlier than the actual timestamp for the entry.\n","permalink":"http://ianist.neocities.org/blog/the-time-is-wrong/","summary":"Well\u0026hellip; it has happened again. The last time it was because of the YAML format interpretting timestamps as UTC unless explicitly set otherwise. And I fixed that issue\u0026hellip; but that won\u0026rsquo;t help this, since I gave up on using Contentlayer like two days later 😭.\nI\u0026rsquo;m not sure the reason for the problem this time. I even updated the timezone for the GH action so that it would be set to CST.","title":"The Time Is Wrong!"},{"content":"Vercel is the company behind Nextjs and also a hosting platform that works with static site generates (Huga, Jekyll, Zola, etc.) and server side generators (Nextjs). I\u0026rsquo;ve been using them to host my new blog since it\u0026rsquo;s inception because they promise \u0026ndash; and mostly make good on the promise \u0026ndash; easy deployments. Well\u0026hellip; ian.ist is a little different because it\u0026rsquo;s two different repos. There is the Sylvan repo which contains the Nextjs code that parses org files and displays the content and there is my private org repo which holds the content. Because I\u0026rsquo;m using a private repo I can\u0026rsquo;t use Vercel\u0026rsquo;s built in build process, and because I\u0026rsquo;m trying to build Syvlan to be more of a framework than a personal tool, even if Org was public it\u0026rsquo;d be hard/impossible to build the site with Vercel\u0026rsquo;s tooling. Luckily they have a path forwards with building and deploying with Github Actions as well. I set this build process to run in the Org repo. I have already detailed my build process in Deployment. How Do?, but I am going to just include the worflow file here as well, because it\u0026rsquo;s changed a little since then.\nname: GitHub Actions Vercel Production Deployment on: push: branches: - master repository_dispatch: types: - sylvan-update workflow_dispatch: jobs: Deploy-Production: runs-on: ubuntu-latest steps: - name: Checkout Sylvan uses: actions/checkout@v2 with: repository: pard68/sylvan - name: \u0026#34;Remove the Sylvan .git dir\u0026#34; run: \u0026#34;rm -rf .git\u0026#34; - name: Checkout Org content uses: actions/checkout@v2 with: path: org/ - name: \u0026#34;Remove files marked :PRIVATE: t\u0026#34; run: \u0026#39;find ./org -type f -exec grep -q \u0026#34;^:PRIVATE: t\\$\u0026#34; {} \\; -delete\u0026#39; - name: Move the org repo .git dir to root to satisfy Vercel run: mv org/.git ./ - name: Merge org content with default Sylvan content run: mv org/* public/ - name: Install Vercel CLI run: npm install --global vercel@latest - name: Pull Vercel Environment Information run: vercel pull --yes --environment=production --token=${{ secrets.VERCEL_TOKEN }} - name: Build Project Artifacts run: vercel build --prod --token=${{ secrets.VERCEL_TOKEN }} - name: Deploy Project Artifacts to Vercel run: vercel deploy --prebuilt --prod --token=${{ secrets.VERCEL_TOKEN }} The changes are what this post is about.\nThe issue I was facing after the initial deployment was that my Vercel project was being updated by changes to the Sylvan repo, which means that when those changes got triggered, built, and then deployed I would end up with a blank website, because there is no content in the the Sylvan repo. My initial fix was to disable Vercel from accessing my Github repos and that worked for a few days but then I noticed that the GH Actions were starting to fail so I had to come up with a new solution or get off Vercel.\nMy solution was based on a hunch. There was no reason that Vercel should know about Sylvan. I never told it about Syvlan when I created the project. The only way it could know Syvlan existed is if it was scraping the .git/ when I deployed via the Vercel CLI tool. So I followed my hunch, deleted that directory and then replaced it with the Org repo\u0026rsquo;s .git/ directory.\nSUCCESS! Almost.\nNow it was building based on triggers from the Org repo, which is better, but those builds will always fail because the org repo has no Nextjs code to deploy! So then I removed the step to copy the org repo\u0026rsquo;s git directory to the root. The Github action actually failed this time, it seems that the Vercel CLI requires the thing being uploads to use git, and without the .git/ directory, there is essentially no git.\nNext idea: dummy git repo:\n- name: Created a dummy git repo run: git init . \u0026amp;\u0026amp; git commit -a -m \u0026#34;boop\u0026#34; This didn\u0026rsquo;t work because git didn\u0026rsquo;t know my user.email or user.name. Before I invested in bootstrapping git, I had had another idea; instead of creating a dummy git, just remove the remote, which I assume is how Vercel is finding the org repo.\n- name: Move the org repo .git dir to root to satisfy Vercel run: mv org/.git ./ - name: Expunge git remote run: git remote remove origin The build and deploy worked! But when I pushed a new commit to Github Vercel tried to build the project again, which of course failed. On a whim I checked the Vercel project and it had somehow connected itself to the org repo. I deleted the connection and\u0026hellip; SUCCESS!\nIt\u0026rsquo;s a little more work than I wanted, but I can keep using Vercel at least!\n","permalink":"http://ianist.neocities.org/blog/vercel-woes/","summary":"Vercel is the company behind Nextjs and also a hosting platform that works with static site generates (Huga, Jekyll, Zola, etc.) and server side generators (Nextjs). I\u0026rsquo;ve been using them to host my new blog since it\u0026rsquo;s inception because they promise \u0026ndash; and mostly make good on the promise \u0026ndash; easy deployments. Well\u0026hellip; ian.ist is a little different because it\u0026rsquo;s two different repos. There is the Sylvan repo which contains the Nextjs code that parses org files and displays the content and there is my private org repo which holds the content.","title":"Vercel Woes"},{"content":"The Indie Web is basically an attempt at providing standards and tooling to create websites that are federated and connected to one another. Some of the things they have include IndieAuth, Webmentions, h-cards, h-entries, and syndication with POSSE. Almost all of these things are just standards that you can implement on your site, like the h-* stuff, and allow for other sites and tools to interact with your own website. Some neat things that this allows for are mostly automatic \u0026ldquo;webmentions\u0026rdquo;, which are anything from comments on a post, to response posts, and \u0026ldquo;shares\u0026rdquo;. An h-card is basically a business card that other sites can find in your \u0026lt;head\u0026gt;.\nAnywho, I had this implemented before on my 0x44.pw website and I am going to try to really implement the entire catalog of IndieWeb features here on this site in Sylvan. Why? I think it\u0026rsquo;s a cool exercise and allows for some neat interactions.\n","permalink":"http://ianist.neocities.org/blog/indie-web/","summary":"The Indie Web is basically an attempt at providing standards and tooling to create websites that are federated and connected to one another. Some of the things they have include IndieAuth, Webmentions, h-cards, h-entries, and syndication with POSSE. Almost all of these things are just standards that you can implement on your site, like the h-* stuff, and allow for other sites and tools to interact with your own website. Some neat things that this allows for are mostly automatic \u0026ldquo;webmentions\u0026rdquo;, which are anything from comments on a post, to response posts, and \u0026ldquo;shares\u0026rdquo;.","title":"Indie Web"},{"content":"At the new job (Jack Henry) we\u0026rsquo;re using a JavaScript framework called Lit. It\u0026rsquo;s a Google project that makes working with the native Web Component API a bit less painful. Because Lit is merely some syntactic sugar around the native vanilla JS API for working with WCs it doesn\u0026rsquo;t have fancy stuff like JSX (as oppossed to the other WC library, Stencil, which does). Instead Lit uses the native JavaScript template strings ie:\nconst name = \u0026#34;World\u0026#34;; const foo = html` \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Hello ${name}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt;`; This is all fine, except that in Emacs template strings are always treated as a strings and do not have syntax highlighting, auto-complete, auto-pairs, or even auto-indenting. Essentially, stock Emacs – or even Emacs with most/any JS mode enabled – will revert to Notepad level features when writing elements in Lit. \u0026ldquo;Kinda sucks\u0026rdquo; doesn\u0026rsquo;t even begin to describe how annoying it is to write Lit components in Emacs.\nI initially tried to get it working, gave up, sought out help online, found that others had this problem but no solution, and then downloaded WebStorm. I gave that a day and then tried Emacs again. This time I went to the Doom Discord and was able to determine that the ts-ls with lsp-mode could lend some help… it doesn\u0026rsquo;t really, but web-mode does help a small bit. So now I have auto-complete, auto-pairs, and auto-indenting, but still no syntax highlighting, and you sort of get the feeling that the system is still somewhat broke. But atleast it makes Lit development in Emacs tolerable.\n","permalink":"http://ianist.neocities.org/blog/javascript-template-strings-and-emacs-are-not-friends/","summary":"At the new job (Jack Henry) we\u0026rsquo;re using a JavaScript framework called Lit. It\u0026rsquo;s a Google project that makes working with the native Web Component API a bit less painful. Because Lit is merely some syntactic sugar around the native vanilla JS API for working with WCs it doesn\u0026rsquo;t have fancy stuff like JSX (as oppossed to the other WC library, Stencil, which does). Instead Lit uses the native JavaScript template strings ie:","title":"JavaScript Template Strings and Emacs Are Not Friends"},{"content":"I had mentioned tangling all the things yesterday, and I\u0026rsquo;ve gone ahead and gotten a literate Zsh config up and running this morning. I\u0026rsquo;ve also created a new repo for it here.\nSetup-wise, I went through a few different configurations to keep this DRY and eventually settled on setting global tangle settings in the properties drawer and then specifying each block\u0026rsquo;s output file in the source block. I might update this eventually, but I couldn\u0026rsquo;t convince babel to run any other way. The two things needed to get this working are the following in the file\u0026rsquo;s property drawer:\n:PROPERTIES: :header-args: :tangle yes :comment link :mkdirp yes :padline no :noweb tangle :END: And then each source block must specify the output file like such:\n:tangle ~/.zshenv After that it\u0026rsquo;s merely a matter of writing your dotfiles out inside the source blocks, organizing them in the orgfile as you like, and providing any comments you care to provide. As an example, I am going to just copy/paste the bulk of my zsh config from the literate-dotfiles repo into the rest of this post.\nEnvironment Variables Sadly, ZSH sorta sucks and the .zshenv has to live in the home directory, so we\u0026rsquo;re going to set that up and tell it to look in .config/zsh/ for all the rest of the zsh config files we might use. So we\u0026rsquo;ll setup the zshenv file to have all the right XDG settings, plus point all the various other things that need to be told to use .config to do so.\nXDG and Zsh paths export XDG_CONFIG_HOME=\u0026#34;$HOME/.config\u0026#34; export XDG_DATA_HOME=\u0026#34;$HOME/.local/share\u0026#34; export XDG_DATA_HOME=\u0026#34;$HOME/.cache/\u0026#34; export ZDOTDIR=\u0026#34;$XDG_CONFIG_HOME/zsh\u0026#34; export HISTFILE=\u0026#34;$ZDOTDIR/zhistory\u0026#34; HIST We want to make sure our history is nice and long. It\u0026rsquo;s 2022, so we shouldn\u0026rsquo;t worry too much about disk space or RAM\u0026hellip; I hope\nexport HISTSIZE=10000 export SAVEHIST=10000 EDITOR Let\u0026rsquo;s set our editor quickly so we can make sure we\u0026rsquo;re never far away from emacs.\nexport EDITOR=\u0026#34;/usr/local/bin/emacsclient\u0026#34; export VISUAL=\u0026#34;/usr/local/bin/emacsclient\u0026#34; $PATH We\u0026rsquo;ll setup some $PATH stuff now too. I really hate editing one-liner $PATH exports, so we\u0026rsquo;ll just do one per line, why not? Maybe there is a cool way to use org and iterate over a list of path values and concatenate them together, but IDK how to do that right now\u0026hellip;\nexport PATH=\u0026#34;$HOME/.cargo/bin:$PATH\u0026#34; export PATH=\u0026#34;$HOME/go/bin:$PATH\u0026#34; export PATH=\u0026#34;$HOME/.local/bin:$PATH\u0026#34; export PATH=\u0026#34;/usr/local/bin:$PATH\u0026#34; export PATH=\u0026#34;/usr/bin:$PATH\u0026#34; export PATH=\u0026#34;/bin:$PATH\u0026#34; export PATH=\u0026#34;/usr/local/sbin:$PATH\u0026#34; export PATH=\u0026#34;/usr/local/go/bin/:$PATH\u0026#34; export PATH=\u0026#34;$HOME/.emacs.d/bin/:$PATH\u0026#34; export PATH=\u0026#34;$HOME/.npm-global/bin:$PATH\u0026#34; Zshrc A E S T H E T I C Your terminal, in Technicolor!\nautoload -U colors \u0026amp;\u0026amp; colors PROMPT=\u0026#34;%B%F{magenta}λ%f%b \u0026#34; RPROMPT=\u0026#34;%*\u0026#34; Zsh Options Here is a list of all the zsh options that can be set.\nsetopt HIST_SAVE_NO_DUPS setopt INC_APPEND_HISTORY setopt HIST_IGNORE_SPACE setopt AUTO_CD setopt AUTO_PUSHD setopt PUSHD_IGNORE_DUPS setopt PUSHD_SILENT REPORTTIME=3 Ghetto Jump There are some neat \u0026ldquo;jump\u0026rdquo; plugins like j and z. But we\u0026rsquo;re just going to DIWhy it!\nalias d=\u0026#39;dirs -v\u0026#39; for index ({1..9}) alias \u0026#34;$index\u0026#34;=\u0026#34;cd + ${index}\u0026#34;; unset index Completion autoload -U compinit zstyle \u0026#39;:completion:*\u0026#39; menu select completer _complete _correct _approximate zmodload zsh/complist compinit _comp_options+=(globdots) Aliases Before we make an alias file, let\u0026rsquo;s source them from the zshrc file.\nsource $ZDOTDIR/aliases Okay, now for some aliases.\nalias c!=clear alias g=git alias ga=\u0026#34;git add\u0026#34; alias ga.=\u0026#34;git add .\u0026#34; alias gb=\u0026#34;git branch\u0026#34; alias gbd=\u0026#34;git branch -D\u0026#34; alias gc=\u0026#34;git commit\u0026#34; alias gcm=\u0026#34;git commit -m\u0026#34; alias gca=\u0026#34;git commit --amend\u0026#34; alias gcm!!=\u0026#34;git add .; git commit -m \u0026#34;Update!\u0026#34;; git push\u0026#34; alias gcl=\u0026#34;git clone\u0026#34; alias gco=\u0026#34;git checkout\u0026#34; alias gd=\u0026#34;git diff\u0026#34; alias gl=\u0026#34;git log\u0026#34; alias gm=\u0026#34;git merge\u0026#34; alias gpl=\u0026#34;git pull\u0026#34; alias gps=\u0026#34;git push\u0026#34; alias gps!=\u0026#34;git push --force\u0026#34; alias gpsu=\u0026#34;git push -u origin master\u0026#34; alias gri=\u0026#34;git rebase -i\u0026#34; alias gs=\u0026#34;git status\u0026#34; alias l=\u0026#34;ls\u0026#34; alias la=\u0026#34;ls -a\u0026#34; alias ll=\u0026#34;ls -l\u0026#34; alias lla=\u0026#34;ls -la\u0026#34; ","permalink":"http://ianist.neocities.org/blog/literate-dots-part-1/","summary":"I had mentioned tangling all the things yesterday, and I\u0026rsquo;ve gone ahead and gotten a literate Zsh config up and running this morning. I\u0026rsquo;ve also created a new repo for it here.\nSetup-wise, I went through a few different configurations to keep this DRY and eventually settled on setting global tangle settings in the properties drawer and then specifying each block\u0026rsquo;s output file in the source block. I might update this eventually, but I couldn\u0026rsquo;t convince babel to run any other way.","title":"Literate Dots Part 1 ZSH"},{"content":"So I\u0026rsquo;d like to keep some content in my org repo private \u0026ndash; things like todos, journals, and unfinished posts. Ultimately I\u0026rsquo;d like to put this sort of stuff behind a login, but as a stop-gap I\u0026rsquo;m thinking to go the brute-force way and rm it. My stop-gap is to delete any file containing the line :PRIVATE: t. I\u0026rsquo;m going with the property route so that in the future I can update my solution to be a bit more elegant without having to do any additional work to alter my files.\nSo to make this work all I have to do is add the following to a step in my GitHub deployment action:\nfind . -type f -exec grep -q \u0026#34;^:PRIVATE: t\\$\u0026#34; {} \\; -delete With this in place it is only a matter of annotating the files I don\u0026rsquo;t want to publish with the new property and they should cease to be deployed.\nMy ultimate goal is to have Uniorg change the slug for files annotated with this property and prefix a private to the path or something along those lines. Then I can setup Cloudflare to put a login prompt in front of any page that contains this specific path. The key is going to be ensuring that whatever this path alteration ends up being isn\u0026rsquo;t something that I might accidentally use in some other file \u0026ndash; say a blog post talking about private files\u0026hellip;\n","permalink":"http://ianist.neocities.org/blog/keeping-some-content-private/","summary":"So I\u0026rsquo;d like to keep some content in my org repo private \u0026ndash; things like todos, journals, and unfinished posts. Ultimately I\u0026rsquo;d like to put this sort of stuff behind a login, but as a stop-gap I\u0026rsquo;m thinking to go the brute-force way and rm it. My stop-gap is to delete any file containing the line :PRIVATE: t. I\u0026rsquo;m going with the property route so that in the future I can update my solution to be a bit more elegant without having to do any additional work to alter my files.","title":"Keeping Some Content Private A Stop-Gap"},{"content":"It\u0026rsquo;s actually kind of hard to use a template to create a new file. Apparently this is part of Doom, but I couldn\u0026rsquo;t figure out how to get teh file-templates to work in Doom. My dirty hack to get this working was to create a function that calls a new buffer, inserts some heading info into that new buffer, and then tells the buffer use the major mode of org-mode.\n(defun 0x44/create-new-blog-buffer () \u0026#34;Created a new blog from the specified template in a new buffer\u0026#34; (interactive) (let (($timestamp (format-time-string \u0026#34;\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;\u0026#34; ))) (let (($buf (generate-new-buffer \u0026#34;Untitled Blog Post\u0026#34;))) (switch-to-buffer $buf) (insert (format \u0026#34;:PROPERTIES:\\n:AUTHOR: %s\\n:CREATED: %s\\n:MODIFIED: %s\\n:TYPE: blog\\n:END:\\n#+title: \u0026#34; user-full-name $timestamp $timestamp)) (funcall \u0026#39;org-mode) (setq buffer-offer-save t) $buf))) ","permalink":"http://ianist.neocities.org/blog/my-dirt-hack-to-template-files/","summary":"It\u0026rsquo;s actually kind of hard to use a template to create a new file. Apparently this is part of Doom, but I couldn\u0026rsquo;t figure out how to get teh file-templates to work in Doom. My dirty hack to get this working was to create a function that calls a new buffer, inserts some heading info into that new buffer, and then tells the buffer use the major mode of org-mode.","title":"My Dirty Hack to Template Files"},{"content":"So I had this idea last night, and like with all great ideas I googled it see if anyone else had come up with it first. To my dismay, I was far from the first person to have this awesome idea. The idea? Literate dotfiles!\nImagine how great it\u0026rsquo;d be! You write a single file, let\u0026rsquo;s call it dotfiles.org and then inside of that you write all your dotfiles and document them. Then you just use org\u0026rsquo;s tangle feature to pull all the config code and stick it into all the right files in all the right directories. I think I will try this first with a ZSH config, since I\u0026rsquo;m getting really annoyed with Fish in emacs and Fish inside of vterm inside of emacs seems sort of overkill.\n","permalink":"http://ianist.neocities.org/blog/tangle-all-the-things/","summary":"So I had this idea last night, and like with all great ideas I googled it see if anyone else had come up with it first. To my dismay, I was far from the first person to have this awesome idea. The idea? Literate dotfiles!\nImagine how great it\u0026rsquo;d be! You write a single file, let\u0026rsquo;s call it dotfiles.org and then inside of that you write all your dotfiles and document them.","title":"Tangle All The Things"},{"content":"Introduction Currently, ian.ist is hosted with Vercel. I am using Vercel and not my Bitranchlabs Infra because it was easier, and I am also not sure if I am going to keep my Kubernetes stuff running \u0026ndash; it\u0026rsquo;s $50+ / month for something I really don\u0026rsquo;t need. Vercel is great, I have no real reason to leave, except that my website\u0026rsquo;s content is in my private org repo, while the rest of the site is in the Sylvan repo, and the org content must be mounted into the Sylvan repo in order to build this site.\nI might have a solution that would allow me to continue with Vercel, while also having these two separate repos. Vercel can either build the project for you, or it can be triggered from GitHub actions. The best way I can think to use this is to trigger the Vercel deployment from the private org-mode repo I have on Github. This action will pull in my Sylvan repo, mount the org content into that project, build the project, and then trigger the Vercel deployment. I think I can break this into two approximate parts; first, trigger Vercel deployments from the org repo and second trigger the org repo\u0026rsquo;s action when changes occur to Sylvan.\nDeploying to Vercel from a GitHub action I am just following right along with the docs they provide here. Step one is to create the workflow file in my org repo:\nname: GitHub Actions Vercel Preview Deployment env: VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }} VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }} on: push: branches-ignore: - main jobs: Deploy-Preview: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Install Vercel CLI run: npm install --global vercel@latest - name: Pull Vercel Environment Information run: vercel pull --yes --environment=preview --token=${{ secrets.VERCEL_TOKEN }} - name: Build Project Artifacts run: vercel build --token=${{ secrets.VERCEL_TOKEN }} - name: Deploy Project Artifacts to Vercel run: vercel deploy --prebuilt --token=${{ secrets.VERCEL_TOKEN }} name: GitHub Actions Vercel Production Deployment env: VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }} VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }} on: push: branches: - main jobs: Deploy-Production: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Install Vercel CLI run: npm install --global vercel@latest - name: Pull Vercel Environment Information run: vercel pull --yes --environment=production --token=${{ secrets.VERCEL_TOKEN }} - name: Build Project Artifacts run: vercel build --prod --token=${{ secrets.VERCEL_TOKEN }} - name: Deploy Project Artifacts to Vercel run: vercel deploy --prebuilt --prod --token=${{ secrets.VERCEL_TOKEN }} Of course, these alone won\u0026rsquo;t do the trick since my org repo doesn\u0026rsquo;t actually contain a NextJS project. I need to pull that NextJS code in from the Sylvan repo in a separate step. We can do this by adding another checkout step to the action:\n- name: Checkout Sylvan uses: actions/checkout@v2 with: repository: pard68/sylvan path: /app I\u0026rsquo;ll be honest, GitHub actions have always confused me, I\u0026rsquo;m never really certain how they work or where I am. I think the easiest way to do this is to actually checkout the Sylvan repo first and then checkout the org repo into a directory of the previously checked out Sylvan repo, like such:\njobs: Deploy-Production: runs-on: ubuntu-latest steps: - name: Checkout Sylvan uses: actions/checkout@v2 with: repository: pard68/sylvan - name: Checkout Org content uses: actions/checkout@v2 with: path: src/content/ UPDATE:\nI ended up copying the org repo to a directory called org/ and then using a step to mv org/* public/. I did this because there is content in the public/ directory in the Sylvan repo that I want to keep (fonts and SVGs).\nTrigger builds when Sylvan repo changes Now to trigger the build action when the Sylvan repo changes I need to add another build hook called a repository_dispatch:\non: push: branches: - master repository_dispatch: types: - build I\u0026rsquo;m not going to do this on the preview builds, just doesn\u0026rsquo;t seem like there\u0026rsquo;s much point to that, so we\u0026rsquo;ll only trigger a rebuild on the master branch. This dispatch event is basically a way for us to trigger the action from outside of GitHub \u0026ndash; which is confusing because we\u0026rsquo;re actually triggering this action from another GitHub repo\u0026rsquo;s action. Think of this as a means of triggering actions via REST. Next we create a new developer token with the repo scope and add that to the repo that we want to \u0026ldquo;watch\u0026rdquo;. And then finally we create the action on that other repo. You\u0026rsquo;ll want to update the repo name in the URI to whatever user or org\u0026rsquo;s repo is the one that is getting triggered. Also notice that the event_type is set to build, which corresponds to the dispatch type specified previously:\nname: Trigger rebuild of parent repo on: push: branches: [ main ] pull_request: branches: [ main ] workflow_dispatch: jobs: notify: runs-on: ubuntu-20.04 container: alpine/httpie steps: - name: Notify parent repo run: http post https://api.github.com/repos/\u0026lt;User/Org\u0026gt;/\u0026lt;Repo Name\u0026gt;/dispatches \u0026#34;Authorization:token ${{ secrets.NOTIFY_TOKEN }}\u0026#34; event_type=build --ignore-stdin I ended up changing the type from build to sylvan-update because that type name is what the action\u0026rsquo;s run is called and this way it\u0026rsquo;s a bit more expressive\nUpdate! Just a quick update, I have written my Github Action as a literate file, so now you can check it out here, the nifty thing about this is that the file is what I use to compile the yaml for the GH actions, so it is in some sense a \u0026ldquo;living\u0026rdquo; document and will always reflect what I am actually using.\n","permalink":"http://ianist.neocities.org/blog/deployment-how-do/","summary":"Introduction Currently, ian.ist is hosted with Vercel. I am using Vercel and not my Bitranchlabs Infra because it was easier, and I am also not sure if I am going to keep my Kubernetes stuff running \u0026ndash; it\u0026rsquo;s $50+ / month for something I really don\u0026rsquo;t need. Vercel is great, I have no real reason to leave, except that my website\u0026rsquo;s content is in my private org repo, while the rest of the site is in the Sylvan repo, and the org content must be mounted into the Sylvan repo in order to build this site.","title":"Deployment. How Do?"},{"content":"I am back to (doom)emacs+org-mode, again\u0026hellip; again\u0026hellip; again\u0026hellip;\nWhy? I like it!\nI tried to use ox-hugo. And it seemed nice, but way to much extra. Org mode can compile org files to html, why convert the files to markdown first? Just didn\u0026rsquo;t make sense. I think I shall try sticking with stock org-mode for publishing.\nI ended up finding a wonderful package called Uniorg, which is a parser that takes Org files and generates Unified ASTs that can then be manipulated by tools like Rehype to modified and spit-out HTML. This removes the annoyance of ox-hugo but means I am able to have a bit more control over my contnet \u0026ndash; or at least easier access to control \u0026ndash; than with org\u0026rsquo;s own publishing feature. Though, I did get the org-publish mostly working and producing acceptable HTML, I think.\nUniorg isn\u0026rsquo;t the end-all-be-all, but it\u0026rsquo;s fairly extensible and it is actively maintained, unlike orgajs, which seems to have either died or at least has been put on the back-burner by the maintainers. This does mean I have no need for contentlayer, I have had the thought that maybe contentlayer could get org compatibility added through the usage of Uniorg, however the more I think about that the less sense it makes, org files are already much more structured and defined than markdown with arbitrary frontmatter and Uniorg already is turning the org files into data. For the mean time, I have gutted the contentlayer aspects of Sylvan and put Uniorg in. My next step with that project is going to be figuring out how to build Sylvan with a remote repository for content, thus meaning I can keep my org directory free of the Sylvan related project files and vice versa.\nA couple things I\u0026rsquo;d like to see out of Uniorg:\nExpose drawers for gathering data from (I have managed to get PROPERTIES drawers, but none other, and the current solution for PROPERTIES drawers dumps all data from all the drawers in a file into one, meaning if multiple headings have drawers than that data is getting combined and overwritten) Respect the datatree Less boilerplate Other than that, I am fairly happy with Uniorg thus far. I will say, in org-publish\u0026rsquo;s favor, I liked the styling and layout of the default org-publish function so much that I have endeavored to incorporate some of the asthetics into my NextJS powered site.\n","permalink":"http://ianist.neocities.org/blog/migrating-to-org-mode/","summary":"I am back to (doom)emacs+org-mode, again\u0026hellip; again\u0026hellip; again\u0026hellip;\nWhy? I like it!\nI tried to use ox-hugo. And it seemed nice, but way to much extra. Org mode can compile org files to html, why convert the files to markdown first? Just didn\u0026rsquo;t make sense. I think I shall try sticking with stock org-mode for publishing.\nI ended up finding a wonderful package called Uniorg, which is a parser that takes Org files and generates Unified ASTs that can then be manipulated by tools like Rehype to modified and spit-out HTML.","title":"Migrating To Org Mode"},{"content":"As you can see this site is a serious WIP. But it\u0026rsquo;s coming along, nonetheless \u0026ndash; and dare I say it, is actually useable. Few tasks I\u0026rsquo;d like to get done next include:\nTODO RSS feed(s) DONE Start rudimentary display of `/grok` \u0026ndash; aka the knowledge base TODO Programmigcally display projects under `/project` based on GitHub and GitLab starred projects TODO Add a section for my JS and love.js games so they can all be played/explored from this site TODO Better logo/branding/header thing and a favicon that isn\u0026rsquo;t the NextJS default TODO Book review index as a gallery of book covers TODO Typography improvements including a better font, better colors, and automatically swap quotes and dashes for the appropriate curly quote or emdash, etc. I\u0026rsquo;d also really love to figure out a way to incorporate Git commits into each post/review/etc. Basically figure out when the document was added in Git and that would stand in as my `date` and then figure out last modified date/time and add that as well. And speaking of time\u0026hellip; the time values are wrong, I will need to investigate what is up with the `date-fns` library I\u0026rsquo;m using.\n","permalink":"http://ianist.neocities.org/blog/a-wip/","summary":"As you can see this site is a serious WIP. But it\u0026rsquo;s coming along, nonetheless \u0026ndash; and dare I say it, is actually useable. Few tasks I\u0026rsquo;d like to get done next include:\nTODO RSS feed(s) DONE Start rudimentary display of `/grok` \u0026ndash; aka the knowledge base TODO Programmigcally display projects under `/project` based on GitHub and GitLab starred projects TODO Add a section for my JS and love.js games so they can all be played/explored from this site TODO Better logo/branding/header thing and a favicon that isn\u0026rsquo;t the NextJS default TODO Book review index as a gallery of book covers TODO Typography improvements including a better font, better colors, and automatically swap quotes and dashes for the appropriate curly quote or emdash, etc.","title":"A WIP"},{"content":"I noticed a funny thing happening, the dates for my posts were wrong. The source of the post would contain the correct value in the frontmatter, for example the date of my first post was 2022-07-25 but when that was rendered by NextJS and spit out on the website it was coming in a whole day /earlier_, ie 2022-07-24. At first I thought the culprit was the date library, date-fns, so I dropped into a node shell to see if that was the case\u0026hellip;\n\u0026gt; date.format(date.parseISO(\u0026#39;2022-07-29\u0026#39;), \u0026#39;LLLL d, yyyy\u0026#39;) \u0026#39;July 29, 2022\u0026#39; So date-fns is not the culprit. Next step, console.log!\nconst postDate = format(parseISO(post.date), \u0026#39;LLLL d, yyyy\u0026#39;) console.log(postDate, post.date) // July 24, 2022 2022-07-25T00:00:00.000Z Weird right? The input is the 25th but the output is the 24th. Let\u0026rsquo;s see what the date-fns documentation has to say:\nLibraries like Moment and Luxon, which provide their own date time classes, manage these timestamp and time zone values internally. Since date-fns always returns a plain JS Date, which implicitly has the current system\u0026rsquo;s time zone, helper functions are needed for handling common time zone related use cases.\nOkay, not so weird maybe! But I\u0026rsquo;m not sure the answer is going to be easy. The documentation goes on to explain how to update a datetime stamp to either reflect the time in a given locale based on the UTC time or update a locale based timestamp to reflect UTC time. What we need is to update the timezone, the datetime is right, the timezone is wrong in this particular case.\nSadly the JavaScript date doesn\u0026rsquo;t really have this concept and so it sounded like it might be easier to correct the problem at the source\u0026hellip; and I figured that source was Contentlayer, since it was parsing my frontmatter.\nI did some more dgging and it looks like someone who works on Contentlayer actually attempted addressing this issue already and the tl;dr is that it\u0026rsquo;s actually not something they can fix because it\u0026rsquo;s being determined by something in front of Contentlayer, and the dev suggested it might be an issue with gray-matter, the frontmatter parser they\u0026rsquo;re using.\nI went to the repo for gray-matter and poked around, but after looking at how this library works, this is not the culprit either.\nNext step was to check in on js-yaml, which is what gray-matter is using to parse the frontmatter \u0026ndash; at least in my case since I\u0026rsquo;m using yaml frontmatter.\nThe story there is likely that I need to change how I present the date, as it wants either the date format I\u0026rsquo;m using (ie 2022-07-29) or it wants a full blown timestamp. If you use the full blown timestamp than it can set the timzezone, but otherwise you\u0026rsquo;re stuck with UTC it looks like. And this isn\u0026rsquo;t just that js-yaml library, but in fact this is a part of the YAML standard:\nIf the time zone is omitted, the timestamp is assumed to be specified in UTC. The time part may be omitted altogether, resulting in a date format. In such a case, the time part is assumed to be 00:00:00Z (start of day, UTC).\nWhich means I have few options. I can use the far more cumbersome timestamp (ie 2022-07-29T01:02:03-6.0), I could deal with the date being wrong, I could update the timestamp everytime I use it, or perhaps provide a PR to Contentlayer.\nI dislike the middle idea, so I ended up creating a PR to contentlayer. Essentially, this PR will update the date if a timezone is specified in the config file and if the date that was already fetched does not match the offset set specified in that timezone field of the config.\nHere\u0026rsquo;s the diff of my PR:\nlet dateValue = new Date(rawFieldData) if (options.date?.timezone) { - dateValue = dateFnsTz.zonedTimeToUtc(dateValue, options.date.timezone) + // NOTE offset of specified timezone in milliseconds + const desiredOffset = dateFnsTz.getTimezoneOffset(options.date.timezone) + + // NOTE offset of raw date value is in minutes, we must multiple 60 then 1000 to get milliseconds + const currentOffset = dateValue.getTimezoneOffset() * 60 * 1000 + + if (desredOffset != currentOffset) { + dateValue = new Date(dateValue.getTime() + dateFnsTz.getTimezoneOffset(options.date.timezone) * -1) + } } ","permalink":"http://ianist.neocities.org/blog/the-case-of-the-wrong-date/","summary":"I noticed a funny thing happening, the dates for my posts were wrong. The source of the post would contain the correct value in the frontmatter, for example the date of my first post was 2022-07-25 but when that was rendered by NextJS and spit out on the website it was coming in a whole day /earlier_, ie 2022-07-24. At first I thought the culprit was the date library, date-fns, so I dropped into a node shell to see if that was the case\u0026hellip;","title":"The Case of the Wrong Date"},{"content":"This is just an example of some code blocks for testing rehype prism.\nThis is the time parser I use for Planwarrior. As you can see on lines 1-3 I have a time_str function which takes a string representation of time (4:03) and then determines how many minutes that is since midnight:\ndef time_str(s): h, m = [int(x) for x in s.split(\u0026#39;:\u0026#39;)] return h * 60 + m def plan(plan): return { time_str((y := x.strip().split(\u0026#39; \u0026#39;))[0]): \u0026#39; \u0026#39;.join(y[1:]) for x in plan.strip().splitlines() } Here are some utility functions I am using for the Planwarrior project:\ndef peek_and_lookback(cur): prv = [None] + cur[:-1] nxt = cur[1:] + [None] return zip(prv, cur, nxt) def peek(x): p = x[1:] p.append(None) return zip(x, p) def wrap_ansi(s, code=\u0026#39;green\u0026#39;): c = { \u0026#39;bold\u0026#39;: [\u0026#39;\\033[1m\u0026#39;, \u0026#39;\\033[00m\u0026#39;], \u0026#39;italic\u0026#39;: [\u0026#39;\\033[3m\u0026#39;, \u0026#39;\\033[00m\u0026#39;], \u0026#39;underline\u0026#39;: [\u0026#39;\\033[4m\u0026#39;, \u0026#39;\\033[00m\u0026#39;], \u0026#39;strike\u0026#39;: [\u0026#39;\\033[9m\u0026#39;, \u0026#39;\\033[00m\u0026#39;], \u0026#39;green\u0026#39;: [\u0026#39;\\033[0;32m\u0026#39;, \u0026#39;\\033[00m\u0026#39;], } d = \u0026#39;green\u0026#39; return f\u0026#34;{c.get(code, d)[0]}{s}{c.get(code, d)[1]}\u0026#34; def pad_maybe(i): return str(i) if len(str(i)) \u0026gt; 1 else f\u0026#34;0{i}\u0026#34; ","permalink":"http://ianist.neocities.org/blog/code-example/","summary":"This is just an example of some code blocks for testing rehype prism.\nThis is the time parser I use for Planwarrior. As you can see on lines 1-3 I have a time_str function which takes a string representation of time (4:03) and then determines how many minutes that is since midnight:\ndef time_str(s): h, m = [int(x) for x in s.split(\u0026#39;:\u0026#39;)] return h * 60 + m def plan(plan): return { time_str((y := x.","title":"Code Example"},{"content":"I\u0026rsquo;ve been using contentlayer with this new NextJS blog/digital-garden/website/thing and so far I\u0026rsquo;m really liking it. Content Layer is basically a way of reading MD and MDX files and then turning them into JSON that JavaScript can then process. In addition to reading markdown into data, Content Layer also does a few other things that other libraries aren\u0026rsquo;t offering. With Content Layer I can not only turn MD into data, but it also creates TypeScript typing for that data and allows you to extrapolate and generate metadata on the fly to go with that JSONified markdown.\nFor example, on this blog I currently have two \u0026ldquo;types\u0026rdquo; of content; BlogPost and BookReview. A BlogPost is any file found in my sylvan/content/blog directory and it will be accessible from the /blog/ endpoint. Likewise BookReview content is found in sylvan/content/book. Each content type has it\u0026rsquo;s own iterate that you can import to loop/map/find/etc. over and is also located in the allDocuments iterator.\nWhere Content Layer is going to really shine is when I figure out how to hook sylvan up to my knowledgebase and then exclude some files from being generated into content \u0026ndash; for example maybe I don\u0026rsquo;t want to import my work-related documents into my personal website.\nIn the future I\u0026rsquo;d like to look into what I can do with MDX files. If I continue on with using Obsidian as a CMS, I will probably not have too much use for MDX files, but maybe for very technical or JavaScript/React related files the benefits of MDX will outweight the announce of using MDX in Obsidian. But then again, I am not entirely sold on Obsidian and am looking at getting planwarrioir, which would remove my current big use of Obsidian \u0026ndash; the Day Planner plugin.\n","permalink":"http://ianist.neocities.org/blog/contentlayer-is-cool/","summary":"I\u0026rsquo;ve been using contentlayer with this new NextJS blog/digital-garden/website/thing and so far I\u0026rsquo;m really liking it. Content Layer is basically a way of reading MD and MDX files and then turning them into JSON that JavaScript can then process. In addition to reading markdown into data, Content Layer also does a few other things that other libraries aren\u0026rsquo;t offering. With Content Layer I can not only turn MD into data, but it also creates TypeScript typing for that data and allows you to extrapolate and generate metadata on the fly to go with that JSONified markdown.","title":"ContentLayer Is Cool"},{"content":"Hello! That\u0026rsquo;s right, it\u0026rsquo;s yet another blog from me. Another blog that, let\u0026rsquo;s face it, I won\u0026rsquo;t probably use very much, and is really just an excuse to doing something creative and learning a bit at the same time. Nonethesless, I am going to create YAB and promise to update it.\nMy main motivations are:\nPlay with NextJS Create a \u0026ldquo;digital garden\u0026rdquo; for my notes In doing the above, hopefully eventually settle on platforms to use for day planning, notetaking, and writing Unlike in prior blogs of mine (0x44.pw and bitranchlabs.com) I am going to try to work on the development of this after my initial release. Meaning it\u0026rsquo;s gonna be ugly right now (and for a while)! I\u0026rsquo;ve also go to work on my neovim config a bit, get my tmux-fu back up to speed, maybe get back to using taskwarrior/timewarrior\u0026hellip; so who knows, with so much stuff to do, maybe I\u0026rsquo;ll try writing about it some!\n","permalink":"http://ianist.neocities.org/blog/hello-world/","summary":"Hello! That\u0026rsquo;s right, it\u0026rsquo;s yet another blog from me. Another blog that, let\u0026rsquo;s face it, I won\u0026rsquo;t probably use very much, and is really just an excuse to doing something creative and learning a bit at the same time. Nonethesless, I am going to create YAB and promise to update it.\nMy main motivations are:\nPlay with NextJS Create a \u0026ldquo;digital garden\u0026rdquo; for my notes In doing the above, hopefully eventually settle on platforms to use for day planning, notetaking, and writing Unlike in prior blogs of mine (0x44.","title":"Hello World"},{"content":"Introduction This is my org-publish build script. I was just writing directly to the build.el file, but then I started thinking about it, and that made no sense. If I\u0026rsquo;m using Orgmode to write a blog, I should be using it to write the thing that writes that thing that builds the blog! It\u0026rsquo;s elementary!\nWhy a build.el and not just include this in my emacs config so that it all automatically runs when I publish through emacs? Because my workflow doesn\u0026rsquo;t include me publishing via emacs. Instead I git add . \u0026amp;\u0026amp; git commit -m \u0026quot;Updates!\u0026quot; \u0026amp;\u0026amp; git push and then expect that my CI/CD will build and deploy my website for me. Because of this expectation, I\u0026rsquo;d rather have the org-publish related stuff separate from my emacs configuration so that the CI/CD has a much easier time setting up emacs. Plus, when I do want to build the site locally I just have to run sh build.sh which then will trigger build.el.\nResources https://gitlab.com/ngm/commonplace/-/blob/master/publish.el https://commonplace.doubleloop.net/how-i-publish-my-wiki-with-org-publish https://www.ereslibre.es/blog/2019/09/building-a-personal-website-with-org-mode.html https://www.gonsie.com/blorg/ox-hook.html https://orgmode.org/manual/Advanced-Export-Configuration.html Alternatives https://theiceshelf.com/firn.html https://emacs.love/weblorg/ https://github.com/org-roam/org-roam-ui/discussions/109 https://ox-hugo.scripter.co/ https://git.sr.ht/~jakob/ox-haunt README.org It seems a little weird to build an org file, with an org file. I\u0026rsquo;m really only doing this because the build directory is entry built from this org file, but the intention is that I compile the files in build locally and commit them. There is a chance that someone \u0026ndash; including future me \u0026ndash; might come upon this build directory and be uninformed about it\u0026rsquo;s creation and use.\n#+title: Readme NOTICE: This file and all files in this directory were built with =build.org= and should not be directly edited! This is the build dir for use with org-publish. It should work, but I\u0026#39;m not using it at the moment. Should just have to run `./build.sh` and it will spit out the org files in the parent directory into a `./_html/` dir. To use the Dockerfile, you\u0026#39;ll need to be in the parent directory, aka ~org/~, and then you will run =docker build -t test -f build/Dockerfile .= The final nginx container has the http port exposed. build.sh This is just a little shell script we\u0026rsquo;re using to make it easy to call the elisp code that does the real work of building the website.\nrm -rf ./_html/ emacs -Q --script build.el build.el Now onto the main attraction, build.el will do all the heavy lifting of building the website.\nFront Matter Just a little front matter to describe the software, probably pointless really, but it\u0026rsquo;s here just in-case. I\u0026rsquo;ll probably eventually fill in the commentary and description\u0026hellip;\n;;; build.el --- Description -*- lexical-binding: t; -*- ;; ;; Copyright (C) 2022 Ian S. Pringle ;; ;; Author: Ian S. Pringle \u0026lt;pard@0x44.pw\u0026gt; ;; Maintainer: Ian S. Pringle \u0026lt;pard@0x44.pw\u0026gt; ;; Created: August 02, 2022 ;; Modified: August 24, 2022 ;; Version: 0.2.0 ;; Keywords: bib convenience docs files hypermedia lisp outlines processes tools ;; Homepage: https://github.com/pard68/org ;; Package-Requires: ((emacs \u0026#34;24.4\u0026#34;)) ;; ;; This file is not part of GNU Emacs. ;; ;;; Commentary: ;; ;; Description ;; ;;; Code: Make sh-set-shell quiet The sh-set-shell gets called on files when there is shell scripts in it. I\u0026rsquo;m not sure what it does but it is very noisy and I dislike the noise. So we can inhibit it with this:\n(advice-add \u0026#39;sh-set-shell :around (lambda (orig-fun \u0026amp;rest args) (let ((inhibit-message t)) (apply orig-fun args)))) Dependencies We need to be able to install some dependencies, since we can\u0026rsquo;t count on the emacs.d directory having them installed already during CI/CD, plus we can also separate this from our packages we use for normal, everyday emacs, which means we can depend on different versions or even on things we don\u0026rsquo;t want polluting the rest of our setup.\nstraight.el I\u0026rsquo;m messing around with using straight.el in addition to use-package because the package ox-attach-publish is not on Melpa or any other package repo currently. If this works well, I will work on refactoring the above dependencies to use straight.el instead of package.el.\nThis will bootstrap straight.el, I got it straight from their git repo:\n(setq package-enable-at-startup nil) (setq straight-build-dir (expand-file-name \u0026#34;./.packages\u0026#34;)) (setq straight-use-package-by-default t) (defvar bootstrap-version) (let ((bootstrap-file (expand-file-name \u0026#34;straight/repos/straight.el/bootstrap.el\u0026#34; user-emacs-directory)) (bootstrap-version 6)) (unless (file-exists-p bootstrap-file) (with-current-buffer (url-retrieve-synchronously \u0026#34;https://raw.githubusercontent.com/radian-software/straight.el/develop/install.el\u0026#34; \u0026#39;silent \u0026#39;inhibit-cookies) (goto-char (point-max)) (eval-print-last-sexp))) (load bootstrap-file nil \u0026#39;nomessage)) (straight-use-package \u0026#39;use-package) Getting And Requiring Packages Now that we can use-package we can get on with, well, using packages. Let\u0026rsquo;s start with org and htmlize. Org is\u0026hellip; well it\u0026rsquo;s org! and htmlize is more or less pygments or highlight.js, but for org-publish.\n;; Install needed packages (use-package org) (use-package htmlize) (require \u0026#39;ox-publish) (require \u0026#39;ox-html) (require \u0026#39;htmlize) s is a package for handling strings, f is a package for working with files. I\u0026rsquo;m not actually using either right now, I just am leaving this here (untangled) as a reminder to myself to invest some time into making use of it at a future date.\n(use-package s) (use-package f) (require \u0026#39;s) (require \u0026#39;f) ox-attach-publish is a tool that theoretically converts attached files into valid links for orgmode to then use for images and such. But I haven\u0026rsquo;t gotten this working yet so it\u0026rsquo;s not being tangled into my build script.\n(use-package ox-attach-publish :straight \u0026#39;(ox-attach-publish :type git :host github :repo \u0026#34;simoninireland/ox-attach-publish\u0026#34;)) (require \u0026#39;ox-attach-publish) We require org-roam to build and parse the org-roam related files I have. Specifically, I\u0026rsquo;m looking to use this to generate the links and backlinks between those files.\n(use-package org-roam) (require \u0026#39;org-roam) (require \u0026#39;org-roam-export) Finally, we\u0026rsquo;ll require everything we need, including some things that we didn\u0026rsquo;t have to download first:\n(require \u0026#39;find-lisp) The Meat and Potatoes This is ephemeral, we don\u0026rsquo;t need no stinking backups!\n(setq make-backup-files nil) Common Variables Now to setup some variables for later use:\n(defvar build--build-dir (getenv \u0026#34;PWD\u0026#34;)) (defvar build--project-dir (concat build--build-dir \u0026#34;/..\u0026#34;)) (defvar build-publish-dir (concat build--build-dir \u0026#34;/_html\u0026#34;)) (defvar build--site-name \u0026#34;ian.ist\u0026#34;) (defvar build--publish-url \u0026#34;https://ian.ist\u0026#34;) Initialize org-roam We initialize the org-roam project and DB so that we can lean on it later to generate backlinks.\n(setq org-roam-directory build--project-dir org-roam-db-location (concat build--project-dir \u0026#34;/org-roam.db\u0026#34;)) (org-roam-update-org-id-locations) \u0026lt;head\u0026gt; Here we turn off inlining CSS and then inject our own CSS into the \u0026lt;head\u0026gt;\n(defvar build--html-head (concat \u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; type=\\\u0026#34;text/css\\\u0026#34; href=\\\u0026#34;https://gongzhitaao.org/orgcss/org.css\\\u0026#34; /\u0026gt;\u0026#34; \u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; href=\\\u0026#34;/style.css\\\u0026#34; type=\\\u0026#34;text/css\\\u0026#34; /\u0026gt;\u0026#34; \u0026#34;\u0026lt;link rel=\\\u0026#34;stylesheet\\\u0026#34; href=\\\u0026#34;https://fonts.googleapis.com/css2?family=VT323\u0026amp;family=Didact+Gothic\\\u0026#34;\u0026gt;\u0026#34;)) Some macros (setq org-export-global-macros \u0026#39;((\u0026#34;timestamp\u0026#34; . \u0026#34;@@html:\u0026lt;span class=\\\u0026#34;timestamp\\\u0026#34;\u0026gt;$1\u0026lt;/span\u0026gt;@@\u0026#34;))) Sitemap Maker We\u0026rsquo;ll use this later to setup our /{dir}/index.html pages, for example to list all blog posts:\n(defun build--org-sitemap-date-entry-format (entry _ project) \u0026#34;Build sitemap/index for a number of pages. Format ENTRY in org-publish PROJECT Sitemap format ENTRY ENTRY STYLE format that includes date.\u0026#34; (let ((filename (org-publish-find-title entry project))) (if (= (length filename) 0) (format \u0026#34;*%s*\u0026#34; entry) (format \u0026#34;{{{timestamp(%s)}}} [[file:%s][%s]]\u0026#34; (format-time-string \u0026#34;%Y-%m-%d\u0026#34; (org-publish-find-date entry project)) entry filename)))) CSS Inliner This inlines CSS, but I\u0026rsquo;m not using it right now. Eventually I\u0026rsquo;d like to pursue optimizations that would allow for in-lining critical CSS and then throwing the rest into the styles.css.\n(defun my-org-inline-css-hook (exporter) (when (eq exporter \u0026#39;html) (let* ((dir (ignore-errors (file-name-directory (buffer-file-name)))) (path (concat dir \u0026#34;style.css\u0026#34;)) (homestyle (or (null dir) (null (file-exists-p path)))) (final (if homestyle (concat build--build-dir \u0026#34;/style.css\u0026#34;) path))) ;; \u0026lt;- set your own style file path (setq org-html-head-include-default-style nil) (setq org-html-head (concat \u0026#34;\u0026lt;style type=\\\u0026#34;text/css\\\u0026#34;\u0026gt;\\n\u0026#34; \u0026#34;\u0026lt;!--/*--\u0026gt;\u0026lt;![CDATA[/*\u0026gt;\u0026lt;!--*/\\n\u0026#34; (with-temp-buffer (insert-file-contents final) (buffer-string)) \u0026#34;/*]]\u0026gt;*/--\u0026gt;\\n\u0026#34; \u0026#34;\u0026lt;/style\u0026gt;\\n\u0026#34;))))) (add-hook \u0026#39;org-export-before-processing-hook \u0026#39;my-org-inline-css-hook) Navbar / Header We\u0026rsquo;ll use this later on as the preamble for every page:\n(defvar build--nav-bar \u0026#34;\u0026lt;nav\u0026gt;\u0026lt;a href=\\\u0026#34;/index.html\\\u0026#34;\u0026gt;/index\u0026lt;/a\u0026gt; | \u0026lt;a href=\\\u0026#34;/about.html\\\u0026#34;\u0026gt;/about\u0026lt;/a\u0026gt; | \u0026lt;a href=\\\u0026#34;/blog/index.html\\\u0026#34;\u0026gt;/blog\u0026lt;/a\u0026gt; | \u0026lt;a href=\\\u0026#34;/loci/loci.html\\\u0026#34;\u0026gt;/loci\u0026lt;/a\u0026gt;\u0026#34;) (defvar build--logo (concat \u0026#34;\u0026lt;pre id=\\\u0026#34;logo\\\u0026#34;\u0026gt;\u0026#34; (shell-command-to-string (concat \u0026#34;figlet \u0026#34; build--site-name)) \u0026#34;\u0026lt;/pre\u0026gt;\u0026#34;)) (defvar build--header (concat build--logo build--nav-bar)) Footer This is the footer or postamble:\n(defvar build--footer-left \u0026#34;\u0026lt;div id=\\\u0026#34;footer-left\\\u0026#34;\u0026gt; \u0026lt;p class=\\\u0026#34;author\\\u0026#34;\u0026gt;Author: %a\u0026lt;/p\u0026gt; \u0026lt;p class=\\\u0026#34;date\\\u0026#34;\u0026gt;Site Updated: %T\u0026lt;/p\u0026gt; \u0026lt;p class=\\\u0026#34;creator\\\u0026#34;\u0026gt;Created with ❤️ \u0026amp; %c\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt;\u0026#34;) (defvar build--footer-mid \u0026#34;\u0026lt;div id=\\\u0026#34;footer-mid\\\u0026#34;\u0026gt; \u0026lt;img class\\\u0026#34;fleuron\\\u0026#34; src=\\\u0026#34;/fleuron.svg\\\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt;\u0026#34;) (defvar build--footer-right \u0026#34;\u0026lt;div id=\\\u0026#34;footer-right\\\u0026#34;\u0026gt; \u0026lt;p class=\\\u0026#34;copyright-notice\\\u0026#34;\u0026gt;Creative Commons\u0026lt;/p\u0026gt; \u0026lt;a href=\\\u0026#34;http://creativecommons.org/licenses/by-nc-sa/4.0/\\\u0026#34;\u0026gt;BY-NC-SA\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt;\u0026#34;) (defvar build--footer (concat build--footer-left build--footer-mid build--footer-right)) org-publish projects We\u0026rsquo;ll now build out the projects. Each \u0026ldquo;project\u0026rdquo; is a like a group of pages. So there is a \u0026ldquo;blog\u0026rdquo; project for all the stuff under blog directory, for example.\n(setq org-html-validation-link nil) (setq org-publish-project-alist (list \u0026ldquo;pages\u0026rdquo; project (list \u0026#34;pages\u0026#34; :base-directory build--project-dir :publishing-directory build-publish-dir :publishing-function \u0026#39;org-html-publish-to-html :html-head-extra build--html-head :html-preamble build--header :html-postamble build--footer :html-head-include-default-style nil :recursive nil :with-author t :with-creator t :with-drawer t :with-toc t :section-numbers nil) \u0026ldquo;loci\u0026rdquo; project (list \u0026#34;loci\u0026#34; :base-directory (concat build--project-dir \u0026#34;/loci\u0026#34;) :publishing-directory (concat build-publish-dir \u0026#34;/loci\u0026#34;) :publishing-function \u0026#39;org-html-publish-to-html :html-head-extra build--html-head :html-preamble build--header :html-postamble build--footer :html-head-include-default-style nil :auto-sitemap t :sitemap-filename \u0026#34;index.org\u0026#34; :sitemap-format-entry \u0026#39;build--org-sitemap-date-entry-format :sitemap-sort-files \u0026#39;alphabetically :with-author t :with-creator t :with-drawer t :with-toc t :section-numbers nil) \u0026ldquo;blog\u0026rdquo; project This contains all the files in the blog dir. I eventually would like to figure out how to make this work with a single blog.org file and then each heading or maybe subheading in that file is a \u0026ldquo;page\u0026rdquo; on the site.\n(list \u0026#34;blog\u0026#34; :base-directory (concat build--project-dir \u0026#34;/blog\u0026#34;) :publishing-directory (concat build-publish-dir \u0026#34;/blog\u0026#34;) :publishing-function \u0026#39;org-html-publish-to-html :html-head-extra build--html-head :html-preamble build--header :html-postamble build--footer :html-head-include-default-style nil :auto-sitemap t :sitemap-filename \u0026#34;index.org\u0026#34; :sitemap-format-entry \u0026#39;build--org-sitemap-date-entry-format :sitemap-sort-files \u0026#39;anti-chronologically :with-author t :with-creator t :with-drawer t :with-toc t :section-numbers nil) \u0026ldquo;static\u0026rdquo; project This contains all the static content in my org directory.\n(list \u0026#34;static\u0026#34; :base-directory \u0026#34;~/org/\u0026#34; :base-extension \u0026#34;txt\\\\|jpg\\\\|jpeg\\\\|png\\\\|svg\\\\|gif\\\\|js\u0026#34; :recursive t :publishing-directory build-publish-dir :publishing-function \u0026#39;org-publish-attachment) \u0026ldquo;assets\u0026rdquo; project This contains all the assets in my org/build directory.\n(list \u0026#34;assets\u0026#34; :base-directory \u0026#34;~/org/build\u0026#34; :base-extension \u0026#34;css\\\\|js\\\\|svg\u0026#34; :recursive nil :publishing-directory build-publish-dir :publishing-function \u0026#39;org-publish-attachment) \u0026ldquo;ian.ist\u0026rdquo; project This is just a \u0026ldquo;meta\u0026rdquo; project that contains all the above projects as components:\n(list \u0026#34;ian.ist\u0026#34; :components (list \u0026#34;pages\u0026#34; \u0026#34;loci\u0026#34; \u0026#34;blog\u0026#34; \u0026#34;static\u0026#34; \u0026#34;assets\u0026#34;) :auto-sitemap t :sitemap-filename \u0026#34;sitemap.org\u0026#34; :html-doctype \u0026#34;html5\u0026#34; :html-html5-fancy t))) org-publish And finally, we build the project!\n(org-publish \u0026#34;ian.ist\u0026#34; t) (message \u0026#34;Build completed!\u0026#34;) (provide \u0026#39;build) ;;; build.el ends here style.css html, body { height: 100%; width: 100%; } html { font-family: \u0026#34;Didact Gothic\u0026#34;; text-rendering: geometricPrecision; -webkit-font-smoothing: antialiased; } body { display: flex; flex-direction: column; margin: unset; } #content { flex: 1 0 auto; margin: auto; max-width: min(669px, 60vw); } #preamble { display: flex; flex-direction: column; align-items: center; margin: unset; } #preamble.status { margin: unset; } #preamble nav { font-size: 2em; } #preamble #logo { background-color: white; border: unset; font-size: 1.25em; padding: unset; width: fit-content; } #postamble { display: flex; flex-direction: row; align-items: center; width: 100%; justify-content: space-between; font-size: 0.7em; line-height: 1em; } #postamble * { margin: 5px; } #postamble p { margin: unset; } #postamble div:first-child, #postamble div:last-child { display: flex; flex-direction: column; flex: 1; } #postamble div:last-child * { align-self: flex-end; } #postamble div:nth-child(2) { flex: 0 0 auto; } fleuron.svg Since SVGs are just XML, I can document my favicon/fleuron in the build doc here, it\u0026rsquo;ll generate and be exported when I tangle the doc. Pretty neat!\n\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; xml:space=\u0026#34;preserve\u0026#34; width=\u0026#34;20\u0026#34; height=\u0026#34;20\u0026#34; fill-rule=\u0026#34;evenodd\u0026#34; clip-rule=\u0026#34;evenodd\u0026#34; image-rendering=\u0026#34;optimizeQuality\u0026#34; shape-rendering=\u0026#34;geometricPrecision\u0026#34; text-rendering=\u0026#34;geometricPrecision\u0026#34;\u0026gt; \u0026lt;path d=\u0026#34;M9 0v1h-.5v2H8V2H7v-.5h-.5V1H6V.5H3.5V1H3v.5h-.5V2H2v.5h-.5V3H1v1H0v2.5h.5V7h1v-.5H2V6h1v-.5h-.5V5H2V4h-.5v-.5H2V3h.5v-.5H3V2h1v-.5h.5V1H5v1h1v.5h1.5v1H8V4h1v.5h1V5h1.5v1H11v1h-1v1h.5v1h.5v.5h-.5v.5H10V8.5h-.5V8H9v-.5H8V7h-.5v-.5H6V7h-.5v.5h-1v1h-1V10H3v3.5h.5v2h1v1H5v.5h.5v.5H6v.5h.5v.5H7v.5h1v.5h2.5v.5h3v-.5H15V19h.5v-.5h.5V18h.5v-.5h.5V17h-1v.5h-.5v-1H15v.5h-.5v.5H14v1h-.5v.5H13v.5h-2V19h-.5v-2h.5v-.5h1V16h1v-.5h1.5V15h.5v-.5h.5V14h.5v-.5h.5V12h.5v-.5h.5V9H17v-.5h-.5V8H16v-.5h-3.5V8H12v.5h-1v-1h.5v-1h.5v-1h1V6h.5v.5h2V6h.5v-.5h1V5h1V4h.5v-.5h.5V3h.5v-.5h.5V2h-.5v-.5H19V1h-.5V.5H18V0h-.5v.5H17V1h-1v.5h-.5V2h.5v.5h.5V3h1v.5H17V4h.5v.5h-1V5h-1v.5H14V5h-2V4h.5V2.5H12V1h-1V0H9.5zm6.5 16.5h.5V16h-.5ZM10 .5h.5v1h.5V2h.5v.5H11v1h.5v1h-1V4H10v-.5h-.5V3H9V2h.5V1h.5Z\u0026#34;\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;/svg\u0026gt; Dockerfile This is the Dockerfile that will run the build.el build script, and then put that into an nginx container for hosting or testing. Should be noted that this needs to run from the parent directory to build, in this particular case that means in ~/org/..\nStart by grabbing silex/emacs and name it \u0026lsquo;builder\u0026rsquo;.\nFROM silex/emacs AS builder Make the working directory /org. Then make the emacs.d directory, this is mostly useless but it ensures it exists when we install stuff with our use-package in build.el. Then we just add some extra dependencies. I am not sure if I even need build-essential\u0026hellip; we need sqlite3 to build the org-roam database. And git-restorem-time is currently unused but I think I will eventually make use of it and so I\u0026rsquo;m just leaving it here as a reminder:\nWORKDIR /org RUN mkdir -p ~/.emacs.d/private/ \u0026amp;\u0026amp; apt-get update \u0026amp;\u0026amp; apt-get --yes install build-essential sqlite3 git-restore-mtime Next, copy the entire org directory to the working directory, cd into build/ and kick off the build.sh script:\nCOPY .. . run cd ./build/ \u0026amp;\u0026amp; ./build.sh Finamly, create an nginx container named \u0026lsquo;server\u0026rsquo;, copy the statically compiled assets to it, and then annotate port 80 as the port to use.\nfrom nginx as server copy --from=builder /org/build/_html/ /usr/share/nginx/html/ expose 80 ","permalink":"http://ianist.neocities.org/config/build/","summary":"Introduction This is my org-publish build script. I was just writing directly to the build.el file, but then I started thinking about it, and that made no sense. If I\u0026rsquo;m using Orgmode to write a blog, I should be using it to write the thing that writes that thing that builds the blog! It\u0026rsquo;s elementary!\nWhy a build.el and not just include this in my emacs config so that it all automatically runs when I publish through emacs?","title":"Build"},{"content":"General Settings Bootstrappin' For some reason lexical-binding makes things faster. Let\u0026rsquo;s initialize all our files with this at the top.\nHere\u0026rsquo;s config.el\u0026rsquo;s\n;;; $DOOMDIR/config.el -*- lexical-binding: t; -*- ;; DO NOT EDIT THIS FILE DIRECTLY ;; This is a file generated from a literate programing source file located at ;; `$HOME/.config/doom/config.org`. You should make any changes there and ;; regenerate it from Emacs org-mode using org-babel-tangle (C-c C-v t) Here\u0026rsquo;s init.el\u0026rsquo;s\n;;; init.el -*- lexical-binding: t; -*- ;; DO NOT EDIT THIS FILE DIRECTLY ;; This is a file generated from a literate programing source file located at ;; `$HOME/.config/doom/config.org`. You should make any changes there and ;; regenerate it from Emacs org-mode using org-babel-tangle (C-c C-v t) Here\u0026rsquo;s packages.el\u0026rsquo;s\n;; -*- no-byte-compile: t; -*- ;;; $DOOMDIR/packages.el ;; DO NOT EDIT THIS FILE DIRECTLY ;; This is a file generated from a literate programing source file located at ;; `$HOME/.config/doom/config.org`. You should make any changes there and ;; regenerate it from Emacs org-mode using org-babel-tangle (C-c C-v t) And this means we don\u0026rsquo;t have to wait for Emacs to recompile our config on each save.\n(remove-hook \u0026#39;org-mode-hook #\u0026#39;+literate-enable-recompile-h) Personal Info (setq user-full-name \u0026#34;Ian S. Pringle\u0026#34; user-mail-address \u0026#34;ian@dapringles.com\u0026#34; auth-sources \u0026#39;(\u0026#34;~/.authinfo\u0026#34;)) A E S T H E T I C Fonts I keep going back and forth on this, but I rank the \u0026ldquo;man\u0026rdquo; fonts thusly:\nCozette\u0026gt; scientifica \u0026gt; Hack \u0026gt; Monoid\nCozette is easier on the eyes and has a lot of symbols supported. But it lacks a variable pitch, so we use scientifica when we want bolds and italics. Monoid/Monoisome gives me a headache\u0026hellip; and Hack doesn\u0026rsquo;t support ligatures, so I\u0026rsquo;m going to use Hasklig for the unicode fallback.\n(setq doom-font (font-spec :family \u0026#34;CozetteVector\u0026#34; :size 18) doom-big-font (font-spec :family \u0026#34;CozetteVector\u0026#34; :size 24) doom-variable-pitch-font (font-spec :family \u0026#34;scientifica\u0026#34; :size 18) doom-unicode-font (font-spec :family \u0026#34;Hasklug Nerd Font\u0026#34; :size 18) doom-serif-font (font-spec :family \u0026#34;Didact Gothic\u0026#34; :size 18)) Theme I\u0026rsquo;m using MacOS currently and the emacs install I\u0026rsquo;m using is emacs-plus. This emacs comes with a patch that automatically can toggle a load-theme when the system preference color changes. So we\u0026rsquo;re going to use that to set our theme.\n(defun 0x44/apply-theme (appearance) \u0026#34;Load theme, taking current system appearance into account\u0026#34; (mapc #\u0026#39;disable-theme custom-enabled-themes) (pcase appearance (\u0026#39;light (load-theme \u0026#39;doom-nord-light t)) (\u0026#39;dark (load-theme \u0026#39;doom-nord t)))) (add-hook \u0026#39;ns-system-appearance-change-functions #\u0026#39;0x44/apply-theme) Dashboard Splash Image\nSet the splash image:\n(setq fancy-splash-image (expand-file-name \u0026#34;assets/blackhole-doodle.svg\u0026#34; doom-user-dir)) Add an ASCII fallback logo:\n(defun doom-dashboard-draw-ascii-emacs-banner-fn () (let* ((banner \u0026#39;(\u0026#34;,---.,-.-.,---.,---.,---.\u0026#34; \u0026#34;|---\u0026#39;| | |,---|| `---.\u0026#34; \u0026#34;`---\u0026#39;` \u0026#39; \u0026#39;`---^`---\u0026#39;`---\u0026#39;\u0026#34;)) (longest-line (apply #\u0026#39;max (mapcar #\u0026#39;length banner)))) (put-text-property (point) (dolist (line banner (point)) (insert (+doom-dashboard--center +doom-dashboard--width (concat line (make-string (max 0 (- longest-line (length line))) 32))) \u0026#34;\\n\u0026#34;)) \u0026#39;face \u0026#39;doom-dashboard-banner))) (unless (display-graphic-p) ; for some reason this messes up the graphical splash screen atm (setq +doom-dashboard-ascii-banner-fn #\u0026#39;doom-dashboard-draw-ascii-emacs-banner-fn)) SVG\nBecause the splash image can be an SVG, we can actually include the splash image in our literate config!\n\u0026lt;svg version=\u0026#34;1.1\u0026#34; id=\u0026#34;Layer_1\u0026#34; xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; xmlns:xlink=\u0026#34;http://www.w3.org/1999/xlink\u0026#34; x=\u0026#34;0px\u0026#34; y=\u0026#34;0px\u0026#34; viewBox=\u0026#34;0 0 446.204 446.204\u0026#34; style=\u0026#34;enable-background:new 0 0 446.204 446.204;\u0026#34; xml:space=\u0026#34;preserve\u0026#34;\u0026gt; \u0026lt;g\u0026gt; \u0026lt;circle style=\u0026#34;fill:#20505B;\u0026#34; cx=\u0026#34;387.446\u0026#34; cy=\u0026#34;360.897\u0026#34; r=\u0026#34;17\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#20505B;\u0026#34; d=\u0026#34;M121.517,193.247l199.248,66.818c-18.45,55.02-78.006,84.661-133.037,66.208 C132.708,307.823,103.067,248.266,121.517,193.247z\u0026#34; /\u0026gt; \u0026lt;circle style=\u0026#34;fill:#154047;\u0026#34; cx=\u0026#34;222.159\u0026#34; cy=\u0026#34;227.533\u0026#34; r=\u0026#34;74.443\u0026#34; /\u0026gt; \u0026lt;circle style=\u0026#34;fill:#092A2D;\u0026#34; cx=\u0026#34;222.159\u0026#34; cy=\u0026#34;227.533\u0026#34; r=\u0026#34;40.761\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#20505B;\u0026#34; d=\u0026#34;M325.959,219.578L141.78,157.806c27.067-31.174,71.199-44.726,112.766-30.782 C296.124,140.972,323.173,178.385,325.959,219.578z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FCBC1D;\u0026#34; d=\u0026#34;M320.765,260.065l39.474,13.233c-25.766,76.816-108.925,118.204-185.744,92.449 S56.298,256.837,82.042,180.014l39.474,13.233c-18.45,55.02,11.192,114.576,66.212,133.026 C242.758,344.726,302.315,315.084,320.765,260.065z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#EAC16E;\u0026#34; d=\u0026#34;M437.687,286.375c3.285,1.593,4.052,4.786,3.166,7.44c-0.976,2.921-3.965,5.194-7.786,3.906 l-72.828-24.422l-39.474-13.233l-199.248-66.818l-39.474-13.233l0.004-0.011L9.218,155.58c-7.28-2.431-4.382-13.335,3.148-11.837 c17.643,3.501,35.537,2.463,52.211-2.638c16.692-5.083,32.16-14.217,44.928-26.881c41.167-40.815,103.296-57.453,162.002-37.76 c58.71,19.682,98.252,70.413,106.485,127.801C383.092,239.862,405.31,270.704,437.687,286.375z M141.78,157.806l184.179,61.772 c-2.786-41.193-29.835-78.606-71.413-92.554C212.979,113.08,168.846,126.632,141.78,157.806z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#333333;\u0026#34; d=\u0026#34;M221.133,394.221c-17.736,0-35.643-2.824-53.078-8.646l-0.202-0.068 c-19.625-6.579-37.615-16.571-53.455-29.692c-2.126-1.762-2.423-4.914-0.661-7.04c1.761-2.126,4.913-2.423,7.04-0.661 c14.889,12.333,31.802,21.726,50.269,27.917l0.163,0.055c59.916,20.009,125.794,2.368,167.845-44.939 c1.835-2.063,4.994-2.25,7.06-0.416c2.063,1.835,2.249,4.995,0.415,7.059C314.053,374.326,268.204,394.221,221.133,394.221z M99.357,339.27c-1.387,0-2.766-0.573-3.754-1.696c-32.037-36.38-46.851-84.661-40.643-132.461 c0.355-2.738,2.868-4.667,5.603-4.314c2.738,0.356,4.67,2.864,4.314,5.603c-5.837,44.944,8.097,90.346,38.23,124.565 c1.825,2.072,1.625,5.231-0.448,7.057C101.71,338.859,100.531,339.27,99.357,339.27z M356.782,321.263 c-0.946,0-1.903-0.269-2.752-0.83c-2.304-1.522-2.937-4.625-1.414-6.928c3.395-5.135,6.518-10.53,9.283-16.035 c1.24-2.467,4.246-3.463,6.712-2.223c2.468,1.239,3.463,4.245,2.224,6.712c-2.942,5.857-6.266,11.597-9.877,17.061 C359.996,320.474,358.405,321.263,356.782,321.263z M425.648,264.844c-1.135,0-2.276-0.384-3.214-1.172 c-18.309-15.385-30.279-37.03-33.707-60.949c-0.392-2.734,1.507-5.267,4.24-5.659c2.739-0.393,5.267,1.508,5.658,4.24 c3.078,21.481,13.818,40.911,30.242,54.711c2.114,1.776,2.388,4.931,0.611,7.045C428.49,264.238,427.074,264.844,425.648,264.844z M388.104,181.724c-2.151,0-4.139-1.4-4.788-3.567c-6.461-21.571-16.973-41.354-31.243-58.8 c-10.62-12.984-23.084-24.28-37.047-33.572c-2.299-1.53-2.922-4.634-1.392-6.933c1.529-2.298,4.63-2.923,6.933-1.393 c14.791,9.844,27.996,21.811,39.246,35.566c15.11,18.472,26.24,39.42,33.083,62.262c0.792,2.645-0.71,5.432-3.355,6.224 C389.062,181.656,388.579,181.724,388.104,181.724z M59.938,130.953c-2.143,0-4.125-1.389-4.781-3.545 c-0.804-2.642,0.685-5.436,3.327-6.24c6.772-2.062,13.32-4.971,19.46-8.645c2.371-1.418,5.44-0.646,6.858,1.723 s0.646,5.44-1.723,6.858c-6.838,4.092-14.133,7.332-21.682,9.63C60.911,130.882,60.42,130.953,59.938,130.953z M98.345,107.973 c-1.287,0-2.573-0.494-3.551-1.479c-1.944-1.961-1.931-5.127,0.03-7.071c23.237-23.038,52.349-39.3,84.188-47.027 c32.671-7.93,66.869-6.467,98.896,4.229l0.229,0.077c5.755,1.929,11.471,4.173,16.989,6.668c2.516,1.138,3.633,4.1,2.495,6.616 c-1.137,2.516-4.097,3.636-6.616,2.496c-5.212-2.356-10.611-4.476-16.049-6.299l-0.205-0.068 c-30.252-10.104-62.539-11.486-93.381-4c-30.069,7.298-57.562,22.655-79.505,44.411C100.89,107.49,99.617,107.973,98.345,107.973z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#333333;\u0026#34; d=\u0026#34;M221.012,378.369c-15.955,0-32.167-2.537-48.107-7.881 C95.192,344.432,52.449,261.156,75.793,183.179L7.628,160.321c-5.737-1.917-8.777-7.558-7.224-13.413 c1.555-5.858,6.997-9.251,12.937-8.069c16.485,3.271,33.698,2.4,49.772-2.516c16.059-4.89,30.881-13.759,42.87-25.65 c21.187-21.005,47.731-35.833,76.765-42.879c29.848-7.244,61.09-5.886,90.348,3.93c29.26,9.809,55.005,27.561,74.451,51.335 c18.917,23.128,31.155,50.963,35.393,80.496c4.896,34.158,26.176,63.437,56.925,78.32c5.193,2.518,7.549,8.078,5.731,13.523 c-0.962,2.879-3.017,5.278-5.638,6.582c-2.58,1.284-5.594,1.454-8.489,0.478l-31.685-10.625c-2.618-0.878-4.028-3.712-3.15-6.331 c0.879-2.618,3.715-4.026,6.33-3.151l31.692,10.628c0.565,0.191,0.778,0.082,0.848,0.047c0.248-0.123,0.485-0.436,0.606-0.796 c0.305-0.915-0.243-1.181-0.606-1.356c-33.743-16.333-57.096-48.446-62.463-85.9c-3.979-27.729-15.471-53.865-33.234-75.583 c-18.252-22.313-42.419-38.976-69.89-48.186c-27.471-9.215-56.797-10.492-84.81-3.693c-27.264,6.617-52.19,20.54-72.083,40.262 c-13.139,13.032-29.389,22.754-46.992,28.114c-17.642,5.396-36.537,6.352-54.641,2.76c-0.395-0.079-1.048-0.208-1.322,0.826 c-0.273,1.029,0.356,1.239,0.732,1.364l72.833,24.424c2.566,0.861,3.981,3.607,3.193,6.197c-0.013,0.044-0.031,0.1-0.046,0.144 c-24.828,74.09,15.232,154.571,89.301,179.404c74.082,24.84,154.566-15.222,179.415-89.299c0.879-2.618,3.715-4.027,6.33-3.15 l12.159,4.078c2.618,0.878,4.028,3.712,3.15,6.331s-3.712,4.028-6.33,3.151l-7.496-2.514 C340.754,340.233,282.851,378.367,221.012,378.369z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#333333;\u0026#34; d=\u0026#34;M221.249,336.783c-11.783,0-23.612-1.914-35.111-5.77c-27.876-9.348-50.443-28.991-63.543-55.312 c-13.1-26.32-15.167-56.167-5.819-84.044c0.878-2.618,3.713-4.028,6.331-3.151c2.618,0.878,4.029,3.712,3.151,6.331 c-17.543,52.317,10.746,109.152,63.061,126.695c25.348,8.5,52.487,6.622,76.418-5.287c23.931-11.91,41.789-32.426,50.288-57.77 c0.878-2.618,3.713-4.028,6.33-3.151c2.618,0.878,4.028,3.712,3.15,6.331c-9.348,27.876-28.991,50.443-55.313,63.543 C254.726,332.894,238.036,336.782,221.249,336.783z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#333333;\u0026#34; d=\u0026#34;M325.959,224.578c-0.534,0-1.07-0.085-1.59-0.26L140.19,162.547 c-1.582-0.531-2.795-1.816-3.234-3.426c-0.438-1.61-0.045-3.333,1.049-4.593c29.358-33.813,75.729-46.47,118.131-32.245 c26.968,9.047,49.112,27.885,62.354,53.045c1.286,2.443,0.348,5.467-2.096,6.753c-2.443,1.286-5.468,0.348-6.754-2.096 c-12.038-22.872-32.169-39.997-56.685-48.222c-36.142-12.125-75.445-2.77-102.211,23.775l169.424,56.823 c-0.832-5.743-2.165-11.418-3.984-16.949c-0.862-2.623,0.564-5.449,3.188-6.312c2.622-0.865,5.449,0.564,6.313,3.187 c2.874,8.738,4.645,17.806,5.263,26.952c0.113,1.665-0.612,3.276-1.934,4.295C328.127,224.221,327.05,224.578,325.959,224.578z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#333333;\u0026#34; d=\u0026#34;M360.24,278.299c-0.527,0-1.063-0.084-1.59-0.261l-89.628-30.052 c-2.618-0.878-4.028-3.712-3.15-6.331c0.879-2.618,3.715-4.027,6.33-3.151l89.626,30.052c2.618,0.878,4.029,3.712,3.151,6.33 C364.279,276.978,362.33,278.299,360.24,278.299z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#333333;\u0026#34; d=\u0026#34;M247.581,240.523c-0.527,0-1.063-0.084-1.591-0.261L63.569,179.091 c-2.618-0.878-4.029-3.712-3.15-6.33c0.878-2.618,3.714-4.029,6.33-3.15l182.421,61.171c2.618,0.878,4.028,3.712,3.15,6.331 C251.618,239.203,249.671,240.523,247.581,240.523z\u0026#34; /\u0026gt; \u0026lt;g\u0026gt; \u0026lt;path style=\u0026#34;fill:#FCBC1D;\u0026#34; d=\u0026#34;M52.446,60.614c-2.761,0-5-2.239-5-5V34.181c0-2.761,2.239-5,5-5s5,2.239,5,5v21.434 C57.446,58.375,55.207,60.614,52.446,60.614z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FCBC1D;\u0026#34; d=\u0026#34;M63.163,49.897H41.729c-2.761,0-5-2.239-5-5s2.239-5,5-5h21.433c2.761,0,5,2.239,5,5 S65.924,49.897,63.163,49.897z\u0026#34; /\u0026gt; \u0026lt;/g\u0026gt; \u0026lt;g\u0026gt; \u0026lt;path style=\u0026#34;fill:#FCBC1D;\u0026#34; d=\u0026#34;M321.446,417.023c-2.762,0-5-2.239-5-5V390.59c0-2.761,2.238-5,5-5s5,2.239,5,5v21.433 C326.446,414.785,324.208,417.023,321.446,417.023z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FCBC1D;\u0026#34; d=\u0026#34;M332.163,406.307h-21.434c-2.762,0-5-2.239-5-5s2.238-5,5-5h21.434c2.762,0,5,2.239,5,5 S334.925,406.307,332.163,406.307z\u0026#34; /\u0026gt; \u0026lt;/g\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M378.395,263.993c-0.53,0-1.066-0.085-1.589-0.26l-40.64-13.629c-2.618-0.878-4.028-3.712-3.15-6.33 c0.879-2.618,3.714-4.029,6.33-3.15l28.051,9.407c-4.979-9.646-8.755-19.875-11.269-30.542c-0.633-2.688,1.033-5.38,3.721-6.013 c2.694-0.634,5.381,1.033,6.014,3.72c3.289,13.962,8.914,27.105,16.721,39.065c1.163,1.783,1.07,4.106-0.231,5.791 C381.387,263.298,379.914,263.993,378.395,263.993z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M357.476,204.053c-2.331,0-4.417-1.638-4.896-4.011c-4.667-23.111-15.303-44.591-30.758-62.115 c-15.504-17.579-35.577-30.854-58.051-38.39l-0.153-0.051c-32.522-10.862-67.433-9.025-98.313,5.17 c-2.509,1.152-5.478,0.054-6.631-2.455s-0.054-5.478,2.455-6.631c33.197-15.26,70.717-17.238,105.651-5.571l0.159,0.053 c24.151,8.099,45.719,22.366,62.384,41.261c16.614,18.839,28.046,41.92,33.061,66.75c0.546,2.707-1.205,5.344-3.912,5.891 C358.137,204.02,357.803,204.053,357.476,204.053z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M95.411,153.864c-1.75,0-3.449-0.92-4.366-2.556c-1.351-2.409-0.493-5.456,1.916-6.807 c9.717-5.448,18.678-12.21,26.635-20.097c7.122-7.061,14.965-13.388,23.311-18.803c2.318-1.502,5.414-0.844,6.916,1.473 c1.503,2.316,0.844,5.413-1.473,6.916c-7.772,5.043-15.078,10.937-21.714,17.517c-8.597,8.521-18.281,15.828-28.785,21.718 C97.079,153.658,96.239,153.864,95.411,153.864z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M121.813,177.949c-0.527,0-1.063-0.084-1.59-0.261l-45.638-15.304 c-2.618-0.878-4.029-3.712-3.151-6.331c0.878-2.618,3.711-4.028,6.331-3.151l45.637,15.304c2.618,0.878,4.029,3.712,3.151,6.33 C125.853,176.628,123.903,177.949,121.813,177.949z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M151.148,187.786c-0.527,0-1.063-0.084-1.59-0.261l-13.038-4.372 c-2.618-0.878-4.029-3.712-3.151-6.331c0.878-2.618,3.712-4.029,6.331-3.151l13.038,4.372c2.618,0.878,4.029,3.712,3.151,6.331 C155.187,186.466,153.238,187.786,151.148,187.786z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M310.865,241.347c-0.527,0-1.063-0.084-1.591-0.261l-140.161-47.002 c-2.618-0.878-4.029-3.712-3.151-6.331c0.878-2.618,3.712-4.029,6.331-3.151l140.161,47.002c2.618,0.878,4.028,3.712,3.15,6.331 C314.903,240.026,312.955,241.347,310.865,241.347z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M128.165,314.286c-1.382,0-2.757-0.569-3.745-1.685c-24.657-27.838-36.235-64.856-31.764-101.563 c0.334-2.741,2.829-4.69,5.568-4.359c2.741,0.334,4.693,2.827,4.359,5.568c-4.125,33.867,6.563,68.028,29.322,93.724 c1.831,2.067,1.64,5.228-0.427,7.058C130.527,313.872,129.342,314.286,128.165,314.286z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M152.458,335.412c-0.948,0-1.907-0.269-2.756-0.832c-2.344-1.552-4.664-3.201-6.895-4.9 c-2.197-1.673-2.622-4.81-0.948-7.007c1.673-2.197,4.811-2.622,7.007-0.948c2.057,1.566,4.196,3.086,6.358,4.519 c2.302,1.524,2.933,4.627,1.408,6.929C155.67,334.625,154.079,335.412,152.458,335.412z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M221.139,356.083c-13.715,0-27.542-2.188-40.987-6.679l-0.14-0.046 c-3.696-1.24-7.355-2.651-10.894-4.201c-2.529-1.108-3.682-4.057-2.574-6.586c1.109-2.529,4.058-3.68,6.586-2.574 c3.267,1.432,6.646,2.735,10.043,3.875l0.143,0.047c42.026,14.033,88.136,3.697,120.339-26.981 c2.002-1.905,5.165-1.829,7.069,0.171c1.905,2,1.828,5.164-0.171,7.069C285.963,343.604,253.88,356.083,221.139,356.083z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M321.652,304.986c-1.023,0-2.057-0.313-2.946-0.964c-2.229-1.629-2.716-4.757-1.087-6.987 c2.818-3.856,5.428-7.923,7.757-12.09c1.346-2.41,4.39-3.273,6.804-1.925c2.41,1.347,3.272,4.394,1.925,6.804 c-2.525,4.519-5.355,8.931-8.411,13.112C324.714,304.275,323.193,304.986,321.652,304.986z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#333333;\u0026#34; d=\u0026#34;M386.637,287.211c-0.33,0-0.65-0.03-0.98-0.09c-0.32-0.07-0.63-0.17-0.93-0.29 c-0.301-0.13-0.59-0.28-0.87-0.46c-0.271-0.18-0.521-0.39-0.76-0.62c-0.931-0.93-1.46-2.22-1.46-3.54c0-0.32,0.029-0.65,0.1-0.97 c0.06-0.32,0.16-0.64,0.28-0.94c0.13-0.3,0.279-0.59,0.46-0.86c0.18-0.28,0.39-0.53,0.62-0.76c0.239-0.23,0.489-0.44,0.76-0.62 c0.28-0.19,0.569-0.34,0.87-0.46c0.3-0.13,0.609-0.23,0.93-0.29c0.65-0.13,1.31-0.13,1.96,0c0.32,0.06,0.63,0.16,0.93,0.29 c0.301,0.12,0.591,0.27,0.87,0.46c0.271,0.18,0.53,0.39,0.76,0.62c0.23,0.23,0.44,0.48,0.62,0.76c0.181,0.27,0.33,0.56,0.46,0.86 c0.12,0.3,0.221,0.62,0.28,0.94c0.07,0.32,0.101,0.65,0.101,0.97c0,1.32-0.53,2.61-1.461,3.54 C389.236,286.681,387.946,287.211,386.637,287.211z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M386.259,266.62c-0.525,0-1.06-0.083-1.585-0.259l-7.862-2.626 c-2.619-0.875-4.033-3.708-3.158-6.327c0.875-2.62,3.71-4.03,6.326-3.159l7.862,2.626c2.619,0.875,4.033,3.708,3.158,6.327 C390.301,265.296,388.351,266.62,386.259,266.62z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#FFFFFF;\u0026#34; d=\u0026#34;M74.223,162.055c-0.525,0-1.059-0.083-1.584-0.259l-7.862-2.626 c-2.619-0.875-4.033-3.708-3.159-6.327c0.876-2.619,3.709-4.031,6.327-3.159l7.862,2.626c2.619,0.875,4.033,3.708,3.159,6.327 C78.265,160.731,76.315,162.055,74.223,162.055z\u0026#34; /\u0026gt; \u0026lt;path style=\u0026#34;fill:#333333;\u0026#34; d=\u0026#34;M387.446,382.897c-12.131,0-22-9.869-22-22s9.869-22,22-22s22,9.869,22,22 S399.577,382.897,387.446,382.897z M387.446,348.897c-6.617,0-12,5.383-12,12s5.383,12,12,12s12-5.383,12-12 S394.063,348.897,387.446,348.897z\u0026#34; /\u0026gt; \u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;g\u0026gt;\u0026lt;/g\u0026gt; \u0026lt;/svg\u0026gt; De-clutter\nDe-clutter the dashboard:\n(remove-hook \u0026#39;+doom-dashboard-functions #\u0026#39;doom-dashboard-widget-shortmenu) (remove-hook \u0026#39;+doom-dashboard-functions #\u0026#39;doom-dashboard-widget-footer) (add-hook! \u0026#39;+doom-dashboard-mode-hook (hide-mode-line-mode 1) (hl-line-mode -1)) (setq-hook! \u0026#39;+doom-dashboard-mode-hook evil-normal-state-cursor (list nil)) Misc. Allow babel execution in CLI actions The $DOOMDIR/cli.el file is sourced every time a CLI command is run, so we can just enable evaluation by setting org-confirm-babel-evaluate to nil there. While we\u0026rsquo;re at it, we should silence org-babel-execute-src-block to avoid polluting the output.\n;;; cli.el -*- lexical-binding: t; -*- (setq org-confirm-babel-evaluate nil) (setq +literate-config-file \u0026#34;~/org/doom.org\u0026#34;) (defun doom-shut-up-a (orig-fn \u0026amp;rest args) (quiet! (apply orig-fn args))) (advice-add \u0026#39;org-babel-execute-src-block :around #\u0026#39;doom-shut-up-a) Asynchronous config tangling This rewrites Doom\u0026rsquo;s org-mode hook to be async. If my literate config ever gets too complicated, this might need to be reevaluated.\n(defadvice! +literate-tangle-async-h () \u0026#34;A very simplified version of `+literate-tangle-h\u0026#39;, but async.\u0026#34; :override #\u0026#39;+literate-tangle-h (let ((default-directory doom-user-dir)) (async-shell-command (format \u0026#34;emacs --batch --eval \\\u0026#34;(progn \\ (require \u0026#39;org) (setq org-confirm-babel-evaluate nil) \\ (org-babel-tangle-file \\\\\\\u0026#34;%s\\\\\\\u0026#34;))\\\u0026#34;\u0026#34; +literate-config-file)))) Preserve indentation when tangling (setq org-src-preserve-indentation t) Key Mappings (map! :leader (:prefix \u0026#34;o\u0026#34; :desc \u0026#34;Open ielm\u0026#34; \u0026#34;I\u0026#34; #\u0026#39;ielm)) Doom\u0026rsquo;s init.el init.el boilerplate In Doomemacs init.el is where the Doom \u0026ldquo;config\u0026rdquo; lives. This is how you specify what Doom modules to include. You\u0026rsquo;re really not suppossed to do anything else in init.el except configure the Doom specific settings inside of the Doom! function, however, the docs also say you can add the +literate-config-file location to the init.el file, so I\u0026rsquo;m just going to do that and assume it\u0026rsquo;s all going to be okay\u0026hellip; This also has to go into the cli.el file.\n(setq +literate-config-file \u0026#34;~/org/doom.org\u0026#34;) Now we can add our Doom! block. We\u0026rsquo;re using noweb to build this, so that we can define each module\u0026rsquo;s settings in it\u0026rsquo;s own area and then export it in the right place later.\n(doom! :completion \u0026lt;\u0026lt;doom-completion\u0026gt;\u0026gt; :ui \u0026lt;\u0026lt;doom-ui\u0026gt;\u0026gt; :editor \u0026lt;\u0026lt;doom-editor\u0026gt;\u0026gt; :emacs \u0026lt;\u0026lt;doom-emacs\u0026gt;\u0026gt; :term \u0026lt;\u0026lt;doom-term\u0026gt;\u0026gt; :checkers \u0026lt;\u0026lt;doom-checkers\u0026gt;\u0026gt; :tools \u0026lt;\u0026lt;doom-tools\u0026gt;\u0026gt; :os \u0026lt;\u0026lt;doom-os\u0026gt;\u0026gt; :lang \u0026lt;\u0026lt;doom-lang\u0026gt;\u0026gt; :email \u0026lt;\u0026lt;doom-email\u0026gt;\u0026gt; :app \u0026lt;\u0026lt;doom-app\u0026gt;\u0026gt; :config \u0026lt;\u0026lt;doom-config\u0026gt;\u0026gt; ) Apps ;; calendar ;; everywhere (rss +org) Completion company (vertico +icons) Checkers syntax (spell +flyspell +everywhere +aspell) (:if (executable-find \u0026#34;languagetool\u0026#34;) grammar) Config literate (default +bindings +smartparens) Editor (evil +everywhere) file-templates fold (format +onsave) snippets word-wrap Emacs (dired +icons +ranger) electric (ibuffer +icons) undo vc Email (mu4e +gmail +org) Langs common-lisp data emacs-lisp graphql (json +tree-sitter) (javascript +tree-sitter) (lua +fennel +moonscript) markdown (org +hugo +dragndrop +pretty +roam2) php (python +poetry +pyenv +tree-sitter) (racket +xp) (rest +jq) rust sh (web +tree-sitter) yaml OS (:if IS-MAC macos) (tty +osc) Term eshell vterm Tools ansible docker (eval +overlay) (lookup +dictionary +docsets +offline) (magit +forge) make (pass +auth) tree-sitter UI I had issues with (ligatures +extra), most noteably the ligatures for True and False did not display, however if you were in a mode that had the T/F ligatures (Python, JavaScript) and you viewed the prettify-symbols-alist than you\u0026rsquo;d see the correct unicode symbol, so I\u0026rsquo;m not sure what\u0026rsquo;s up but I don\u0026rsquo;t think it\u0026rsquo;s a limitation on the font.\n;; deft doom doom-dashboard doom-quit (emoji +ascii +github +unicode) hl-todo modeline nav-flash ophints (popup +all +defaults) tabs treemacs (vc-gutter +diff-hl +pretty) (window-select +numbers +switch-window) workspaces Email To get the auth-sources stuff working on MacOS we have to:\n(after! auth-source (setq auth-sources (nreverse auth-sources))) notmuch General settings (setq +notmuch-sync-backend \u0026#39;mbsync-xdg) mu4e General settings (setq mu4e-get-mail-command \u0026#34;mbsync -c ~/.config/isync/mbsyncrc -a\u0026#34; mu4e-update-interval 300 mu4e-compose-format-flowed t mu4e-header-date-format \u0026#34;%y-%m-%d\u0026#34;) Personal Accounts ipringle@protonmail.com\n(set-email-account! \u0026#34;protonmail\u0026#34; \u0026#39;((user-mail-address . \u0026#34;ipringle@protonmail.com\u0026#34;) (mu4e-sent-folder . \u0026#34;/ipringle@protonmail.com/Sent\u0026#34;) (mu4e-drafts-folder . \u0026#34;/ipringle@protonmail.com/Drafts\u0026#34;) (mu4e-trash-folder . \u0026#34;/ipringle@protonmail.com/Trash\u0026#34;) (mu4e-refile-folder . \u0026#34;/ipringle@protonmail.com/Archive\u0026#34;) (mu4e-compose-signature . \u0026#34;---\\nFrom\\nIan S. Pringle\u0026#34;) (smtpmail-smtp-user . \u0026#34;ipringle@protonmail.com\u0026#34;) (smtpmail-smtp-server . \u0026#34;127.0.0.1\u0026#34;) (smtpmail-smtp-service . 1025)) nil) pard@0x44.pw\n(set-email-account! \u0026#34;0x44\u0026#34; \u0026#39;((user-mail-address . \u0026#34;pard@0x44.pw\u0026#34;) (mu4e-sent-folder . \u0026#34;/pard@0x44.pw/Sent\u0026#34;) (mu4e-drafts-folder . \u0026#34;/pard@0x44.pw/Drafts\u0026#34;) (mu4e-trash-folder . \u0026#34;/pard@0x44.pw/Trash\u0026#34;) (mu4e-refile-folder . \u0026#34;/pard@0x44.pw/Archive\u0026#34;) (mu4e-compose-signature . \u0026#34;---\\nFrom\\nIan S. Pringle\u0026#34;) (smtpmail-smtp-user . \u0026#34;pard@0x44.pw\u0026#34;) (smtpmail-smtp-server . \u0026#34;127.0.0.1\u0026#34;) (smtpmail-smtp-service . 1025)) nil) ian@dapringles.com\n(set-email-account! \u0026#34;dapringles\u0026#34; \u0026#39;((user-mail-address . \u0026#34;ian@dapringles.com\u0026#34;) (mu4e-sent-folder . \u0026#34;/ian@dapringles.com/Sent\u0026#34;) (mu4e-drafts-folder . \u0026#34;/ian@dapringles.com/Drafts\u0026#34;) (mu4e-trash-folder . \u0026#34;/ian@dapringles.com/Trash\u0026#34;) (mu4e-refile-folder . \u0026#34;/ian@dapringles.com/Archive\u0026#34;) (mu4e-compose-signature . \u0026#34;---\\nFrom\\nIan S. Pringle\u0026#34;) (smtpmail-smtp-user . \u0026#34;ian@dapringles.com\u0026#34;) (smtpmail-smtp-server . \u0026#34;127.0.0.1\u0026#34;) (smtpmail-smtp-service . 1025)) t) Work Account (set-email-account! \u0026#34;work\u0026#34; \u0026#39;((user-mail-address . \u0026#34;i.pringle@hbhold.com\u0026#34;) (mu4e-sent-folder . \u0026#34;/ipringle@hbhold.com/Sent Items\u0026#34;) (mu4e-drafts-folder . \u0026#34;/ipringle@hbhold.com/Drafts\u0026#34;) (mu4e-trash-folder . \u0026#34;/ipringle@hbhold.com/Deleted Items\u0026#34;) (mu4e-refile-folder . \u0026#34;/ipringle@hbhold.com/Archive\u0026#34;) (mu4e-compose-signature . \u0026#34;---\\nFrom\\nIan S. Pringle\u0026#34;) (smtpmail-smtp-user . \u0026#34;i.pringle@hbhold.com\u0026#34;) (smtpmail-smtp-server . \u0026#34;outlook.office.com\u0026#34;) (smtpmail-smtp-service . 587)) nil) Orgmode Settings Boilerplate\nLet\u0026rsquo;s add auto save to org buffers.\n;;(add-hook \u0026#39;auto-save-hook \u0026#39;org-save-all-org-buffers) Now to fix some defaults:\n(setq org-use-property-inheritance t org-log-done \u0026#39;time org-list-allow-alphabetical t org-export-in-background t org-fold-catch-invisible-edits \u0026#39;smart org-auto-align-tags nil org-tags-column 0 org-special-ctrl-a/e t org-insert-heading-respect-content t org-hide-emphasis-markers t org-pretty-entities t org-ellipsis \u0026#34;…\u0026#34; org-agenda-tags-column 0 org-agenda-block-separator ?─ org-agenda-time-grid \u0026#39;((daily today require-timed) (800 1000 1200 1400 1600 1800 2000) \u0026#34; ┄┄┄┄┄ \u0026#34; \u0026#34;┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄\u0026#34;) org-agenda-current-time-string \u0026#34;⭠ now ─────────────────────────────────────────────────\u0026#34;) Auto Save and Sync\nOne minute before the start of the next hour, save all org buffers.\n(run-at-time \u0026#34;00:59\u0026#34; 3600 \u0026#39;org-save-all-org-buffers) And then just used the baked in git sync feature:\n(require \u0026#39;org-attach-git) Org Directories\n;; Much of my org setup was stolen from http://doc.norang.ca/org-mode.html (after! org-agenda (setq org-notes (concat (getenv \u0026#34;HOME\u0026#34;) \u0026#34;/org\u0026#34;) org-directory org-notes deft-directory org-notes org-roam-directory (concat org-notes \u0026#34;/loci\u0026#34;) org-roam-dailies-directory org-notes org-blog-directory (concat org-notes \u0026#34;/blog\u0026#34;) +org-capture-inbox (concat org-notes \u0026#34;/life.org\u0026#34;) +org-capture-weekly (concat org-notes \u0026#34;/weekly.org\u0026#34;) org-agenda-files (apply \u0026#39;append (mapcar (lambda (directory) (directory-files-recursively directory org-agenda-file-regexp)) (list org-notes ))))) Org Keywords\nThe idea here is the minimize states, which minimizes the time I have to think about the state task should be in. Ultimately tasks either need to be started (TODO), are finished (DONE), or cannot be worked on (HOLD). The idea of a \u0026ldquo;NEXT\u0026rdquo; is better off-loaded to some algorithm that can determine the next best task to work on based on the effort required to finish it, the priority of the task, and whether it\u0026rsquo;s a blocker for another task. This is how Taskwarrior does it, and think this is a great thing to embrace. The KILL state is here mostly because it\u0026rsquo;s a almost zero-effort call on whether or not a task is KILL\u0026rsquo;d (ie no longer needs to be moved to a DONE state) and KILL\u0026rsquo;d, or cancelled, task is different enough from a DONE task to merit it\u0026rsquo;s own face..\nAppointments (APPT) are like TODOs that are in HOLD until a specific time and at the appointed time are immediately the active task, until completed, when they immediately are DONE. I mostly added this APPT state so that I can easily see when I have appointments and because, like KILL, it requires next to no energy to know if a task is an APPT \u0026ndash; and in fact this face would likely almost only ever been created through a capture template anyway.\nFinally we have the last three faces \u0026ndash; I don\u0026rsquo;t want to use \u0026lsquo;state\u0026rsquo; for them because they\u0026rsquo;re really not even tasks. MEET is for, wait for it, meetings \u0026ndash; but also other similar types of events. The goal with MEET is to open the capture template, keep it open for the duration of the MEET-thing and then close it. The opening of the MEET-thing would log the start time and then the closing would log the close. Why do I have NOTE and IDEA? No clue, I should probably just keep one or the other, but I feel like there is enough difference between the two concepts to warrant both. An IDEA is something to explore in detail later, like a blog post or a topic to look into. A NOTE is some knowledge or inkling I want to retain and perhaps develop later into a grok. Time will tell if I keep both faces or condense them into one.\nLastly, I have some faces for my reading list. I was controlling this with a file variable but it wasn\u0026rsquo;t working right and it doesn\u0026rsquo;t hurt anything to put this in here.\n(after! org (setq org-todo-keywords \u0026#39;( (sequence \u0026#34;TODO(t)\u0026#34; \u0026#34;|\u0026#34; \u0026#34;DONE(d!/!)\u0026#34;) (sequence \u0026#34;HOLD(h@/!)\u0026#34; \u0026#34;|\u0026#34; \u0026#34;KILL(k@/!)\u0026#34;) (sequence \u0026#34;APPT(a)\u0026#34; \u0026#34;|\u0026#34; \u0026#34;DONE(d!)\u0026#34;) (sequence \u0026#34;MEET(m)\u0026#34; \u0026#34;IDEA(i)\u0026#34; \u0026#34;NOTE(n)\u0026#34;) (sequence \u0026#34;READ(r)\u0026#34; \u0026#34;READING(R)\u0026#34; \u0026#34;|\u0026#34; \u0026#34;DONE(d@/!)\u0026#34;))) (setq org-todo-keyword-faces \u0026#39;( ;; I like the default TODO color... ;; (\u0026#34;TODO\u0026#34; :foreground \u0026#34;red\u0026#34; :weight bold) (\u0026#34;DONE\u0026#34; :foreground \u0026#34;forest green\u0026#34; :weight bold) (\u0026#34;HOLD\u0026#34; :foreground \u0026#34;magenta\u0026#34; :weight bold) (\u0026#34;KILL\u0026#34; :foreground \u0026#34;forest green\u0026#34; :weight bold) (\u0026#34;MEET\u0026#34; :foreground \u0026#34;forest green\u0026#34; :weight bold) (\u0026#34;APPT\u0026#34; :foreground \u0026#34;magenta\u0026#34; :weight bold) (\u0026#34;IDEA\u0026#34; :foreground \u0026#34;gold\u0026#34; :weight bold) (\u0026#34;NOTE\u0026#34; :foreground \u0026#34;blue\u0026#34; :weight bold) (\u0026#34;READ\u0026#34; :foreground \u0026#34;red\u0026#34; :weight bold) (\u0026#34;READING\u0026#34; :foreground \u0026#34;magenta\u0026#34; :weight bold))) (setq org-use-fast-todo-selection t) (setq org-treat-S-cursor-todo-selection-as-state-change nil) (setq org-todo-state-tags-triggers \u0026#39;((\u0026#34;KILL\u0026#34; (\u0026#34;KILL\u0026#34; . t) (\u0026#34;ARCHIVE\u0026#34; . t)) (\u0026#34;HOLD\u0026#34; (\u0026#34;HOLD\u0026#34; . t) (\u0026#34;ARCHIVE\u0026#34;)) (done (\u0026#34;HOLD\u0026#34;) (\u0026#34;ARCHIVE\u0026#34;. t)) (\u0026#34;TODO\u0026#34; (\u0026#34;HOLD\u0026#34;) (\u0026#34;KILL\u0026#34;) (\u0026#34;ARCHIVE\u0026#34;)) (\u0026#34;DONE\u0026#34; (\u0026#34;HOLD\u0026#34;) (\u0026#34;KILL\u0026#34;) (\u0026#34;ARCHIVE\u0026#34; . t)) (\u0026#34;READ\u0026#34; (\u0026#34;ARCHIVE\u0026#34;)) (\u0026#34;READING\u0026#34; (\u0026#34;ARCHIVE\u0026#34;))))) Org tags\n(after! org (setq org-tag-alist \u0026#39;( ;; Related to the computer, but not specific to work (\u0026#34;BLOG\u0026#34; . ?b) (\u0026#34;ORG\u0026#34; . ?o) ;; Related to work (\u0026#34;@work\u0026#34; . ?w) (\u0026#34;INCIDENT\u0026#34; . ?I) (\u0026#34;REQUEST\u0026#34; . ?I) ;; Related to IRL (\u0026#34;@home\u0026#34; . ?h) (\u0026#34;@farm\u0026#34; . ?f) ;; Related to traveling (\u0026#34;ERRAND\u0026#34; . ?e) (\u0026#34;@Doniphan\u0026#34; . ?D) (\u0026#34;@PoplarBluff\u0026#34; . ?P) (\u0026#34;@WestPlain\u0026#34; . ?W) (\u0026#34;@Thayer\u0026#34; . ?T) ))) Org Capture Templates\nI\u0026rsquo;m trying to keep everything to just one file. Or, at least most of everything. So we file everything into the \u0026ldquo;Inbox\u0026rdquo; heading, which is the holding tank for almost all my captures so I can later go through them and evaluate if they\u0026rsquo;re really valuable or not. Capturing is for the purpose of getting all my ideas, tasks, etc. out of my head and somewhere less ephemeral as quickly as possible. We can review the merit of the things that are captures later during a reivew period.\n(setq org-capture-templates \u0026#39;((\u0026#34;t\u0026#34; \u0026#34;Task\u0026#34; entry (file+headline +org-capture-inbox \u0026#34;Inbox\u0026#34;) \u0026#34;* TODO %? %(org-set-tags-command) \\nCREATED: %U\\n\u0026#34; :clock-in t :clock-resume t) (\u0026#34;i\u0026#34; \u0026#34;Ideas\u0026#34; entry (file+headline +org-capture-inbox \u0026#34;Inbox\u0026#34;) \u0026#34;* IDEA %?\\nCREATED: %U\\n\u0026#34; :clock-in t :clock-resume t) (\u0026#34;b\u0026#34; \u0026#34;Blog\u0026#34; entry (file+headline \u0026#34;blog.org\u0026#34; \u0026#34;New\u0026#34;) (function org-hugo-new-subtree-post-capture-template)) (\u0026#34;n\u0026#34; \u0026#34;Notes\u0026#34; entry (file+headline +org-capture-inbox \u0026#34;Inbox\u0026#34;) \u0026#34;* NOTE %?\\nCREATED: %U\\n\u0026#34; :clock-in t :clock-resume t) (\u0026#34;a\u0026#34; \u0026#34;Appointment\u0026#34; entry (file+headline +org-capture-inbox \u0026#34;Inbox\u0026#34;) \u0026#34;* APPT %? %^gAPPOINTMENT: \\nSCHEDULED: %^T\\nCREATED: %U\\n\u0026#34; :clock-in t :clock-resume t) (\u0026#34;m\u0026#34; \u0026#34;Meeting\u0026#34; entry (file+headline +org-capture-inbox \u0026#34;Meeting\u0026#34;) \u0026#34;* MEET with %? :MEETING:\\nCREATED: %U\\n\u0026#34; :clock-in t :clock-resume t) (\u0026#34;w\u0026#34; \u0026#34;Weekly Plan\u0026#34; entry (file+olp+datetree +org-capture-weekly) \u0026#34;* Goals\\n* Changes\\n* PTO\\n* Notes\\n\u0026#34; :clock-in t :clock-resume t :tree-type week) )) Because we are clocking all captures, we could easily end up with a 0:00 clock, which we want to delete, but than that\u0026rsquo;d end up with an empty :LOGBOOK: and so we should delete those since they\u0026rsquo;re ugly and pointless.\n(defun 0x44/remove-empty-drawer-on-clock-out () (interactive) (save-excursion (beginning-of-line 0) (org-remove-empty-drawer-at (point)))) (add-hook \u0026#39;org-clock-out-hook \u0026#39;0x44/remove-empty-drawer-on-clock-out \u0026#39;append) Org Clocking\n;; ;; Resume clocking task when emacs is restarted (org-clock-persistence-insinuate) ;; ;; Show lot of clocking history so it\u0026#39;s easy to pick items off the C-F11 list (setq org-clock-history-length 23) ;; Resume clocking task on clock-in if the clock is open (setq org-clock-in-resume t) ;; Separate drawers for clocking and logs (setq org-drawers (quote (\u0026#34;PROPERTIES\u0026#34; \u0026#34;LOGBOOK\u0026#34;))) ;; Save clock data and state changes and notes in the LOGBOOK drawer (setq org-clock-into-drawer t) ;; Sometimes I change tasks I\u0026#39;m clocking quickly - this removes clocked tasks with 0:00 duration (setq org-clock-out-remove-zero-time-clocks t) ;; Clock out when moving task to a done state (setq org-clock-out-when-done t) ;; Save the running clock and all clock history when exiting Emacs, load it on startup (setq org-clock-persist t) ;; Do not prompt to resume an active clock (setq org-clock-persist-query-resume nil) ;; Enable auto clock resolution for finding open clocks (setq org-clock-auto-clock-resolution (quote when-no-clock-is-running)) ;; Include current clocking task in clock reports (setq org-clock-report-include-clocking-task t) Clocking functions stolen from Norang\nSource\n(setq bh/keep-clock-running nil) (defun bh/find-project-task () \u0026#34;Move point to the parent (project) task if any\u0026#34; (save-restriction (widen) (let ((parent-task (save-excursion (org-back-to-heading \u0026#39;invisible-ok) (point)))) (while (org-up-heading-safe) (when (member (nth 2 (org-heading-components)) org-todo-keywords-1) (setq parent-task (point)))) (goto-char parent-task) parent-task))) (defun bh/punch-in (arg) \u0026#34;Start continuous clocking and set the default task to the selected task. If no task is selected set the Organization task as the default task.\u0026#34; (interactive \u0026#34;p\u0026#34;) (setq bh/keep-clock-running t) (if (equal major-mode \u0026#39;org-agenda-mode) ;; ;; We\u0026#39;re in the agenda ;; (let* ((marker (org-get-at-bol \u0026#39;org-hd-marker)) (tags (org-with-point-at marker (org-get-tags-at)))) (if (and (eq arg 4) tags) (org-agenda-clock-in \u0026#39;(16)) (bh/clock-in-organization-task-as-default))) ;; ;; We are not in the agenda ;; (save-restriction (widen) ; Find the tags on the current task (if (and (equal major-mode \u0026#39;org-mode) (not (org-before-first-heading-p)) (eq arg 4)) (org-clock-in \u0026#39;(16)) (bh/clock-in-organization-task-as-default))))) (defun bh/punch-out () (interactive) (setq bh/keep-clock-running nil) (when (org-clock-is-active) (org-clock-out)) (org-agenda-remove-restriction-lock)) (defun bh/clock-in-default-task () (save-excursion (org-with-point-at org-clock-default-task (org-clock-in)))) (defun bh/clock-in-parent-task () \u0026#34;Move point to the parent (project) task if any and clock in\u0026#34; (let ((parent-task)) (save-excursion (save-restriction (widen) (while (and (not parent-task) (org-up-heading-safe)) (when (member (nth 2 (org-heading-components)) org-todo-keywords-1) (setq parent-task (point)))) (if parent-task (org-with-point-at parent-task (org-clock-in)) (when bh/keep-clock-running (bh/clock-in-default-task))))))) (defvar bh/organization-task-id \u0026#34;0a6abfc7-3d86-4a11-8ed4-85154df397f8\u0026#34;) (defun bh/clock-in-organization-task-as-default () (interactive) (org-with-point-at (org-id-find bh/organization-task-id \u0026#39;marker) (org-clock-in \u0026#39;(16)))) (defun bh/clock-out-maybe () (when (and bh/keep-clock-running (not org-clock-clocking-in) (marker-buffer org-clock-default-task) (not org-clock-resolving-clocks-due-to-idleness)) (bh/clock-in-parent-task))) (add-hook \u0026#39;org-clock-out-hook \u0026#39;bh/clock-out-maybe \u0026#39;append) (require \u0026#39;org-id) (defun bh/clock-in-task-by-id (id) \u0026#34;Clock in a task by id\u0026#34; (org-with-point-at (org-id-find id \u0026#39;marker) (org-clock-in nil))) (defun bh/clock-in-last-task (arg) \u0026#34;Clock in the interrupted task if there is one Skip the default task and get the next one. A prefix arg forces clock in of the default task.\u0026#34; (interactive \u0026#34;p\u0026#34;) (let ((clock-in-to-task (cond ((eq arg 4) org-clock-default-task) ((and (org-clock-is-active) (equal org-clock-default-task (cadr org-clock-history))) (caddr org-clock-history)) ((org-clock-is-active) (cadr org-clock-history)) ((equal org-clock-default-task (car org-clock-history)) (cadr org-clock-history)) (t (car org-clock-history))))) (widen) (org-with-point-at clock-in-to-task (org-clock-in nil)))) Utility functions stolen fron Norang to help with the clocking functions stolen from Norang\n(defun bh/is-project-p () \u0026#34;Any task with a todo keyword subtask\u0026#34; (save-restriction (widen) (let ((has-subtask) (subtree-end (save-excursion (org-end-of-subtree t))) (is-a-task (member (nth 2 (org-heading-components)) org-todo-keywords-1))) (save-excursion (forward-line 1) (while (and (not has-subtask) (\u0026lt; (point) subtree-end) (re-search-forward \u0026#34;^\\*+ \u0026#34; subtree-end t)) (when (member (org-get-todo-state) org-todo-keywords-1) (setq has-subtask t)))) (and is-a-task has-subtask)))) (defun bh/is-project-subtree-p () \u0026#34;Any task with a todo keyword that is in a project subtree. Callers of this function already widen the buffer view.\u0026#34; (let ((task (save-excursion (org-back-to-heading \u0026#39;invisible-ok) (point)))) (save-excursion (bh/find-project-task) (if (equal (point) task) nil t)))) (defun bh/is-task-p () \u0026#34;Any task with a todo keyword and no subtask\u0026#34; (save-restriction (widen) (let ((has-subtask) (subtree-end (save-excursion (org-end-of-subtree t))) (is-a-task (member (nth 2 (org-heading-components)) org-todo-keywords-1))) (save-excursion (forward-line 1) (while (and (not has-subtask) (\u0026lt; (point) subtree-end) (re-search-forward \u0026#34;^\\*+ \u0026#34; subtree-end t)) (when (member (org-get-todo-state) org-todo-keywords-1) (setq has-subtask t)))) (and is-a-task (not has-subtask))))) (defun bh/is-subproject-p () \u0026#34;Any task which is a subtask of another project\u0026#34; (let ((is-subproject) (is-a-task (member (nth 2 (org-heading-components)) org-todo-keywords-1))) (save-excursion (while (and (not is-subproject) (org-up-heading-safe)) (when (member (nth 2 (org-heading-components)) org-todo-keywords-1) (setq is-subproject t)))) (and is-a-task is-subproject))) (defun bh/list-sublevels-for-projects-indented () \u0026#34;Set org-tags-match-list-sublevels so when restricted to a subtree we list all subtasks. This is normally used by skipping functions where this variable is already local to the agenda.\u0026#34; (if (marker-buffer org-agenda-restrict-begin) (setq org-tags-match-list-sublevels \u0026#39;indented) (setq org-tags-match-list-sublevels nil)) nil) (defun bh/list-sublevels-for-projects () \u0026#34;Set org-tags-match-list-sublevels so when restricted to a subtree we list all subtasks. This is normally used by skipping functions where this variable is already local to the agenda.\u0026#34; (if (marker-buffer org-agenda-restrict-begin) (setq org-tags-match-list-sublevels t) (setq org-tags-match-list-sublevels nil)) nil) (defvar bh/hide-scheduled-and-waiting-next-tasks t) (defun bh/toggle-next-task-display () (interactive) (setq bh/hide-scheduled-and-waiting-next-tasks (not bh/hide-scheduled-and-waiting-next-tasks)) (when (equal major-mode \u0026#39;org-agenda-mode) (org-agenda-redo)) (message \u0026#34;%s WAITING and SCHEDULED NEXT Tasks\u0026#34; (if bh/hide-scheduled-and-waiting-next-tasks \u0026#34;Hide\u0026#34; \u0026#34;Show\u0026#34;))) (defun bh/skip-stuck-projects () \u0026#34;Skip trees that are not stuck projects\u0026#34; (save-restriction (widen) (let ((next-headline (save-excursion (or (outline-next-heading) (point-max))))) (if (bh/is-project-p) (let* ((subtree-end (save-excursion (org-end-of-subtree t))) (has-next )) (save-excursion (forward-line 1) (while (and (not has-next) (\u0026lt; (point) subtree-end) (re-search-forward \u0026#34;^\\\\*+ NEXT \u0026#34; subtree-end t)) (unless (member \u0026#34;WAITING\u0026#34; (org-get-tags-at)) (setq has-next t)))) (if has-next nil next-headline)) ; a stuck project, has subtasks but no next task nil)))) (defun bh/skip-non-stuck-projects () \u0026#34;Skip trees that are not stuck projects\u0026#34; ;; (bh/list-sublevels-for-projects-indented) (save-restriction (widen) (let ((next-headline (save-excursion (or (outline-next-heading) (point-max))))) (if (bh/is-project-p) (let* ((subtree-end (save-excursion (org-end-of-subtree t))) (has-next )) (save-excursion (forward-line 1) (while (and (not has-next) (\u0026lt; (point) subtree-end) (re-search-forward \u0026#34;^\\\\*+ NEXT \u0026#34; subtree-end t)) (unless (member \u0026#34;WAITING\u0026#34; (org-get-tags-at)) (setq has-next t)))) (if has-next next-headline nil)) ; a stuck project, has subtasks but no next task next-headline)))) (defun bh/skip-non-projects () \u0026#34;Skip trees that are not projects\u0026#34; ;; (bh/list-sublevels-for-projects-indented) (if (save-excursion (bh/skip-non-stuck-projects)) (save-restriction (widen) (let ((subtree-end (save-excursion (org-end-of-subtree t)))) (cond ((bh/is-project-p) nil) ((and (bh/is-project-subtree-p) (not (bh/is-task-p))) nil) (t subtree-end)))) (save-excursion (org-end-of-subtree t)))) (defun bh/skip-non-tasks () \u0026#34;Show non-project tasks. Skip project and sub-project tasks, habits, and project related tasks.\u0026#34; (save-restriction (widen) (let ((next-headline (save-excursion (or (outline-next-heading) (point-max))))) (cond ((bh/is-task-p) nil) (t next-headline))))) (defun bh/skip-project-trees-and-habits () \u0026#34;Skip trees that are projects\u0026#34; (save-restriction (widen) (let ((subtree-end (save-excursion (org-end-of-subtree t)))) (cond ((bh/is-project-p) subtree-end) ((org-is-habit-p) subtree-end) (t nil))))) (defun bh/skip-projects-and-habits-and-single-tasks () \u0026#34;Skip trees that are projects, tasks that are habits, single non-project tasks\u0026#34; (save-restriction (widen) (let ((next-headline (save-excursion (or (outline-next-heading) (point-max))))) (cond ((org-is-habit-p) next-headline) ((and bh/hide-scheduled-and-waiting-next-tasks (member \u0026#34;WAITING\u0026#34; (org-get-tags-at))) next-headline) ((bh/is-project-p) next-headline) ((and (bh/is-task-p) (not (bh/is-project-subtree-p))) next-headline) (t nil))))) (defun bh/skip-project-tasks-maybe () \u0026#34;Show tasks related to the current restriction. When restricted to a project, skip project and sub project tasks, habits, NEXT tasks, and loose tasks. When not restricted, skip project and sub-project tasks, habits, and project related tasks.\u0026#34; (save-restriction (widen) (let* ((subtree-end (save-excursion (org-end-of-subtree t))) (next-headline (save-excursion (or (outline-next-heading) (point-max)))) (limit-to-project (marker-buffer org-agenda-restrict-begin))) (cond ((bh/is-project-p) next-headline) ((org-is-habit-p) subtree-end) ((and (not limit-to-project) (bh/is-project-subtree-p)) subtree-end) ((and limit-to-project (bh/is-project-subtree-p) (member (org-get-todo-state) (list \u0026#34;NEXT\u0026#34;))) subtree-end) (t nil))))) (defun bh/skip-project-tasks () \u0026#34;Show non-project tasks. Skip project and sub-project tasks, habits, and project related tasks.\u0026#34; (save-restriction (widen) (let* ((subtree-end (save-excursion (org-end-of-subtree t)))) (cond ((bh/is-project-p) subtree-end) ((org-is-habit-p) subtree-end) ((bh/is-project-subtree-p) subtree-end) (t nil))))) (defun bh/skip-non-project-tasks () \u0026#34;Show project tasks. Skip project and sub-project tasks, habits, and loose non-project tasks.\u0026#34; (save-restriction (widen) (let* ((subtree-end (save-excursion (org-end-of-subtree t))) (next-headline (save-excursion (or (outline-next-heading) (point-max))))) (cond ((bh/is-project-p) next-headline) ((org-is-habit-p) subtree-end) ((and (bh/is-project-subtree-p) (member (org-get-todo-state) (list \u0026#34;NEXT\u0026#34;))) subtree-end) ((not (bh/is-project-subtree-p)) subtree-end) (t nil))))) (defun bh/skip-projects-and-habits () \u0026#34;Skip trees that are projects and tasks that are habits\u0026#34; (save-restriction (widen) (let ((subtree-end (save-excursion (org-end-of-subtree t)))) (cond ((bh/is-project-p) subtree-end) ((org-is-habit-p) subtree-end) (t nil))))) (defun bh/skip-non-subprojects () \u0026#34;Skip trees that are not projects\u0026#34; (let ((next-headline (save-excursion (outline-next-heading)))) (if (bh/is-subproject-p) nil next-headline))) Keybindings to make using Norang\u0026rsquo;s stolen work easier\n(map! :map org-mode-map :after org :localleader (:prefix \u0026#34;c\u0026#34; :desc \u0026#34;Punch-In\u0026#34; \u0026#34;p\u0026#34; #\u0026#39;bh/punch-in :desc \u0026#34;Punch-In\u0026#34; \u0026#34;P\u0026#34; #\u0026#39;bh/punch-out)) Org Modules and Packages org-modern\norg-modern is a better prettifier for orgmode.\n(package! org-modern) (use-package! org-modern :hook (org-mode . global-org-modern-mode) :config (setq org-modern-label-border 0.3)) org-super-agenda\n;; (package! org-super-agenda) ;; (use-package! org-super-agenda ;; :after org-agenda ;; :config ;; (setq org-super-agenda-groups \u0026#39;( ;; (:name \u0026#34;Today\u0026#34; :date today) ;; (:name \u0026#34;Inbox\u0026#34; :tag \u0026#34;INBOX\u0026#34;))) ;; (org-super-agenda-mode)) org-habits\nInclude the habit module for reoccuring tasks\n(add-to-list \u0026#39;org-modules \u0026#39;org-habits) org-appear\nLet\u0026rsquo;s help org\u0026rsquo;s org-hide-emphasis-markers work a little better. That hook will make it so that org-appear only triggers in insert-mode:\n(package! org-appear) (use-package! org-appear :hook (org-mode . (lambda () (org-appear-mode t) (add-hook \u0026#39;evil-insert-state-entry-hook #\u0026#39;org-appear-manual-start nil t) (add-hook \u0026#39;evil-insert-state-exit-hook #\u0026#39;org-appear-manual-stop nil t))) :config (setq org-appear-trigger \u0026#39;manual org-appear-autolinks t org-appear-autosubmarkers t org-appear-autoentities t org-appear-autokeywords t org-appear-inside-latex t)) org-ol-tree\nThis makes org headings nicer.\n(package! org-ol-tree :recipe (:host github :repo \u0026#34;Townk/org-ol-tree\u0026#34;)) (use-package! org-ol-tree :commands org-ol-tree :config (defadvice! org-ol-tree-system--graphical-frame-p--pgtk () :override #\u0026#39;org-ol-tree-system--graphical-frame-p (memq window-system \u0026#39;(pgtk x w32 ns)))) (map! :map org-mode-map :after org :localleader :desc \u0026#34;Outline\u0026#34; \u0026#34;O\u0026#34; #\u0026#39;org-ol-tree) org-chef\nCapture recipes from urls!!!\n(package! org-chef) (use-package! org-chef ;; :after org-capture :config (add-to-list \u0026#39;org-capture-templates \u0026#39;(\u0026#34;c\u0026#34; \u0026#34;Cookbook\u0026#34; entry (file+headline \u0026#34;~/org/recipes.org\u0026#34; \u0026#34;Inbox\u0026#34;) \u0026#34;%(org-chef-get-recipe-from-url)\u0026#34; :empty-lines 1)) (add-to-list \u0026#39;org-capture-templates \u0026#39;(\u0026#34;M\u0026#34; \u0026#34;Manual Cookbook\u0026#34; entry (file+headline \u0026#34;~/org/recipes.org\u0026#34; \u0026#34;Inbox\u0026#34;) \u0026#34;* %^{Recipe title: }\\n :PROPERTIES:\\n :source-url:\\n :servings:\\n :prep-time:\\n :cook-time:\\n :ready-in:\\n :END:\\n** Ingredients\\n %?\\n** Directions\\n\\n\u0026#34;))) TODO Setup a capture template or two for this\nSomething like this:\norg-roam\n(after! org-roam (setq org-roam-db-gc-threshold most-positive-fixnum org-link-to-org-use-id t) (set-popup-rules! `((,(regexp-quote org-roam-buffer) ; persistent org-roam buffer :side right :width .33 :height .5 :ttl nil :modeline nil :quit nil :slot 1) (\u0026#34;^\\\\*org-roam: \u0026#34; ; node dedicated org-roam buffer :side right :width .33 :height .5 :ttl nil :modeline nil :quit nil :slot 2))) (add-hook \u0026#39;org-roam-mode-hook #\u0026#39;turn-on-visual-line-mode) (setq org-roam-capture-templates \u0026#39;((\u0026#34;d\u0026#34; \u0026#34;default\u0026#34; plain \u0026#34;%?\u0026#34; :if-new (file+head \u0026#34;${slug}.org\u0026#34; \u0026#34;#+title: ${title}\\n\u0026#34;) :immediate-finish t :unnarrowed t) (\u0026#34;r\u0026#34; \u0026#34;bibliography reference\u0026#34; plain \u0026#34;%?\u0026#34; :if-new (file+head \u0026#34;references/${citekey}.org\u0026#34; \u0026#34;#+title: ${title}\\n\u0026#34;) :unnarrowed t))) (set-company-backend! \u0026#39;org-mode \u0026#39;(company-capf)) (require \u0026#39;org-roam-protocol)) (use-package! org-roam-dailies :init (map! :leader :desc \u0026#34;org-roam-dailies-capture-today\u0026#34; \u0026#34;j\u0026#34; #\u0026#39;org-roam-dailies-capture-today) :config (setq org-roam-dailies-capture-templates \u0026#39;((\u0026#34;d\u0026#34; \u0026#34;day\u0026#34; entry \u0026#34;* %\u0026lt;%I:%M %p\u0026gt;:\\n%?\u0026#34; :target (file+datetree \u0026#34;journal.org\u0026#34; day))))) (use-package! org-roam-protocol :after org-protocol) org-roam-ui\n(package! websocket) (package! org-roam-ui :recipe (:host github :repo \u0026#34;org-roam/org-roam-ui\u0026#34; :files (\u0026#34;*.el\u0026#34; \u0026#34;out\u0026#34;))) (use-package! websocket :after org-roam) (use-package! org-roam-ui :after org-roam :commands org-roam-ui-mode :config (setq org-roam-ui-sync-theme t org-roam-ui-port 35900 org-roam-ui-follow t org-roam-ui-update-on-save t org-roam-ui-open-on-start nil)) org-ref\n;; (use-package! org-ref ;; :defer t ;; :config ;; ) (after! org-ref (setq org-ref-default-bibliography `,(list (concat org-roam-directory \u0026#34;works.bib\u0026#34;)))) org-roam-bibtex\n;; (package! org-roam-bibtex) (use-package! org-roam-bibtex :after org-roam :config (require \u0026#39;org-ref)) org-books\nThis package needs some love before I am willing to use it. Love might mean a fork\u0026hellip;\n;; (package! org-books) (use-package! org-books :after org-mode :config (require \u0026#39;org-books) (setq org-books-file (concat org-notes + \u0026#34;books.org\u0026#34;))) Misc. Quieter sh-set-shell\nThe function sh-set-shell can be very noisy. It\u0026rsquo;s used for setting a buffer\u0026rsquo;s shell. To make it quiter we can inhibit the messages and then they\u0026rsquo;ll show up in our Messages buffer but not in the buffer were it\u0026rsquo;s called from (for example the build.el file for my org-export):\n(advice-add \u0026#39;sh-set-shell :around (lambda (orig-fun \u0026amp;rest args) (let ((inhibit-message t)) (apply orig-fun args)))) org-export async fix\nThis is a fix for the async org-export not working. GH Issue:\n(defadvice! fixed-+org--fix-async-export-a (fn \u0026amp;rest args) :override #\u0026#39;+org--fix-async-export-a (let ((old-async-init-file org-export-async-init-file) (org-export-async-init-file (make-temp-file \u0026#34;doom-org-async-export\u0026#34;))) (with-temp-file org-export-async-init-file (prin1 `(progn (setq org-export-async-debug ,(or org-export-async-debug debug-on-error) load-path \u0026#39;,load-path) (unwind-protect (load ,(or old-async-init-file early-init-file) nil t) (delete-file load-file-name))) (current-buffer))) (apply fn args))) org-tangle-into-dir\nThis is a helper function to make tangling a little simpler. This function can be called inside a block header with the tangle command and prepend a directory (set in the doc\u0026rsquo;s property drawer with tangle-dir) to the path given to the function. Useful for literate configurations where you might wish to have every document tangled into the same final directory. I got this from here.\n(defun 0x44/org-tangle-into-dir (sub-path) \u0026#34;Expand the SUB-PATH into the directory given by the tangle-dir property if that property exists, else use the `default-directory\u0026#39;.\u0026#34; (expand-file-name sub-path (or (org-entry-get (point) \u0026#34;tangle-dir\u0026#34; \u0026#39;inherit) (default-directory)))) elfeed-org update\nThis is a function to update elfeed with new feeds in my elfeed-org file. I found this here.\n(require \u0026#39;dash) (defun 0x44/elfeed-org-update () \u0026#34;Automatically update elfeed feeds from elfeed.org\u0026#34; (setq +elfeed-org-last (or (and (boundp \u0026#39;elfeed-feeds) elfeed-feeds) nil)) (elfeed) (setq +elfeed-org-current elfeed-feeds) (let ((elfeed-feeds (-difference +elfeed-org-current +elfeed-org-last))) ;; (message \u0026#34;\u0026amp;s\u0026#34; elfeed-feeds) (mapc #\u0026#39;elfeed-update-feed (elfeed--shuffle (elfeed-feed-list)))) (setq elfeed-feeds +elfeed-org-current)) Blog Templates\nThis function will create a new blog post from a \u0026ldquo;template\u0026rdquo;.\n(defun 0x44/create-new-blog-buffer () \u0026#34;Created a new blog from the specified template in a new buffer\u0026#34; (interactive) (let* (($timestamp (format-time-string \u0026#34;\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;\u0026#34; )) (title (read-from-minibuffer \u0026#34;Post Title: \u0026#34;)) (fname (concat org-blog-directory \u0026#34;/\u0026#34; (org-hugo-slug title) \u0026#34;.org\u0026#34;))) (let (($buf (generate-new-buffer title))) (switch-to-buffer $buf) (insert (format \u0026#34;:PROPERTIES:\\n:AUTHOR: %s\\n:CREATED: %s\\n:MODIFIED: %s\\n:TYPE: blog\\n:END:\\n#+title: %s\u0026#34; user-full-name $timestamp $timestamp title)) (funcall \u0026#39;org-mode) (funcall \u0026#39;org-id-new) (setq buffer-offer-save t) (set-visited-file-name fname) $buf))) This creates an org-capture template for creating blog posts for ox-hugo\n(defun org-hugo-new-subtree-post-capture-template () \u0026#34;Returns `org-capture\u0026#39; template string for new Hugo post. See `org-capture-templates\u0026#39; for more information.\u0026#34; (let* ((title (read-from-minibuffer \u0026#34;Post Title: \u0026#34;)) ;Prompt to enter the post title (date (format-time-string (org-time-stamp-format :long :inactive) (org-current-time))) (fname (org-hugo-slug title))) (mapconcat #\u0026#39;identity `( ,(concat \u0026#34;* TODO \u0026#34; title) \u0026#34;:PROPERTIES:\u0026#34; \u0026#34;:AUTHOR: Ian S. Pringle\u0026#34; ,(concat \u0026#34;:EXPORT_FILE_NAME: \u0026#34; fname) ,(concat \u0026#34;DATE: \u0026#34; date) \u0026#34;:END:\u0026#34; \u0026#34;%?\\n\u0026#34;) ;Place the cursor here finally \u0026#34;\\n\u0026#34;))) Update MODIFIED property on save\nBecause of Sylvan, I like to keep a MODIFIED value in my properties drawer on most/all org files. It\u0026rsquo;s also just handy to have this data available. To get this done, I use the following:\n(defun 0x44/update-org-modified-property () (save-excursion (goto-char (point-min)) (when (re-search-forward \u0026#34;^:MODIFIED:\u0026#34; nil t) (org-entry-put (point-min) \u0026#34;MODIFIED\u0026#34; (format-time-string \u0026#34; \u0026lt;%Y-%m-%d %a %H:%M\u0026gt;\u0026#34;))))) Then to hook this in so it is triggered on a save:\n(defun 0x44/org-mode-before-save-hook () (when (eq major-mode \u0026#39;org-mode) (0x44/update-org-modified-property))) ;; (add-hook \u0026#39;before-save-hook #\u0026#39;0x44/org-mode-before-save-hook) Archive items\nThis is my stop-gap. But it flattens the structure and hides potentially valuable metadata\u0026hellip;\n(after! org-agenda (setq org-archive-mark-done nil org-archive-location \u0026#34;%s_archive::* Archived Tasks\u0026#34;) (defun 0x44/skip-non-archivable-items () \u0026#34;Skip trees that cannot be archieved\u0026#34; (save-restriction (widen) (let ((next-headline (save-excursion (or (outline-next-heading) (point-max)))) (subtree-end (save-excursion (org-end-of-subtree t)))) (if (member (org-get-todo-state) org-todo-keywords-1) (if (member (org-get-todo-state) org-done-keywords) (let* ((daynr (string-to-int (format-time-string \u0026#34;%d\u0026#34; (current-time)))) (a-month-ago (* 60 60 24 (+ daynr 1))) (last-month (format-time-string \u0026#34;%Y-%m-\u0026#34; (time-subtract (current-time) (seconds-to-time a-month-ago)))) (this-month (format-time-string \u0026#34;%Y-%m-\u0026#34; (current-time))) (subtree-is-current (save-excursion (forward-line 1) (and (\u0026lt; (point) subtree-end) (re-search-forward (concat last-month \u0026#34;\\\\|\u0026#34; this-month) subtree-end t))))) (if subtree-is-current subtree-end ; Has a date in this month or last month, skip it nil)) ; available to archive (or subtree-end (point-max))) next-headline))))) When I archive an item I want to mimic the project tree to the archive file, there is meaning in the tree and if we archive without copying the tree that archived item loses meaning. However right now I cannot figure it out and I don\u0026rsquo;t have the time. This sorta works, but not well enough to use it\u0026hellip;\n(defun 0x44/crawl-project-tree () (setq project-tree (list (nth 4 (org-heading-components)))) (save-excursion (while (org-up-heading-safe) (setq project-tree (append (list (nth 4 (org-heading-components))) project-tree)))) project-tree) (defun 0x44/refile-to (file headline) (let ((pos (save-excursion (find-file file) (org-find-exact-headline-in-buffer headline)))) (if pos (org-refile nil nil (list headline file nil pos)) (message (format \u0026#34;Headline [%s] does not exist\u0026#34; headline))))) (defun 0x44/recreate-project-tree (tree) (setq heading \u0026#34;*\u0026#34;) (while tree (print (format \u0026#34;%s %s\u0026#34; heading (pop tree))) (setq heading (concat heading \u0026#34;*\u0026#34;)))) (defun 0x44/map-project-tree () (org-refile nil nil \u0026#39;(\u0026#34;Headline\u0026#34; \u0026#34;file\u0026#34; nil 1)) (0x44/recreate-project-tree (0x44/crawl-project-tree))) org-agenda refile\n(after! org-agenda (setq org-refile-targets (quote ((nil :maxlevel . 9) (org-agenda-files :maxlevel . 9))) org-refile-use-outline-path t org-outline-path-complete-in-steps nil org-refile-allow-creating-parent-nodes (quote confirm)) (defun 0x44/org-refile-verify-target () \u0026#34;Exclude DONE state tasks from refile targets\u0026#34; (not (member (nth 2 (org-heading-components)) org-done-keywords)))) org-agenda review\n(defun 0x44/org-agenda-review-item () \u0026#34;Review items in org-agenda\u0026#34; (interactive) (org-with-wide-buffer ;; (org-todo) ;; Need a different command for updating task states in org-agenda (org-agenda-set-tags) (org-agenda-priority) (org-agenda-set-effort) (org-agenda-refile nil nil t))) (map! :map org-agenda-mode-map \u0026#34;R\u0026#34; #\u0026#39;0x44/org-agenda-review-item) Other Packages benchmark-init This is a tool for profiling emacs startup\n(package! benchmark-init) Let\u0026rsquo;s only run this when we open emacs with the --debug-init argument:\n(when init-file-debug (require \u0026#39;benchmark-init) (add-hook \u0026#39;doom-first-input-hoot #\u0026#39;benchmark-init/deactivate)) calfw We need to define our own function for opening the calfw calendar with sources.\n(defun calendar-helper () (cfw:open-calendar-buffer :contents-sources (list (cfw:org-create-source \u0026#34;Orange\u0026#34;) (cfw:ical-create-source \u0026#34;ProtonCalendar\u0026#34; (+pass-get-secret \u0026#34;ics/protonmail\u0026#34;) \u0026#34;Purple\u0026#34;) (cfw:ical-create-source \u0026#34;HBHold\u0026#34; (+pass-get-secret \u0026#34;ics/hbhold\u0026#34;) \u0026#34;Blue\u0026#34;) ))) This stuff is some helper stuff to open the calendar into a workspace called \u0026lsquo;calendar\u0026rsquo;.\n(defun =my-calendar () \u0026#34;Activate (or switch to) /my/ calendar in it\u0026#39;s workspace.\u0026#34; (interactive) (if (modulep! :ui workspaces) (progn (+workspace-switch \u0026#34;calendar\u0026#34; t) (doom/switch-to-scratch-buffer) (calendar-init) (+workspace/display)) (setq +calendar--wconf (current-window-configuration)) (delete-other-windows) (switch-to-buffer (doom-fallback-buffer)) (calendar-init))) (defun calendar-init () (if-let (win (cl-find-if (lambda (b) (string-match-p \u0026#34;^\\\\*cfw:\u0026#34; (buffer-name b))) (doom-visible-windows) :key #\u0026#39;window-buffer)) (select-window win) (calendar-helper))) ssh-deploy This is used for automatically running SCP and scripts on remote via tramp\n(package! ssh-deploy) (use-package! ssh-deploy :ensure t :hook ((after-save . ssh-deploy-after-save) (find-file . ssh-deploy-find-file)) :config (ssh-deploy-line-mode) (global-set-key (kbd \u0026#34;C-c C-z\u0026#34;) \u0026#39;ssh-deploy-prefix-map)) Apparently this is needed to make dir-locals files work with evil-mode:\n(advice-add #\u0026#39;turn-on-evil-mode :before (lambda (\u0026amp;optional args) (when (eq major-mode \u0026#39;fundamental-mode) (hack-local-variables)))) Custom Packages hammerspoon.el This just loads the hammerspoon.el code needed to get the editWithEmacs Spoon working.\n(let ((hammerspoon-module \u0026#34;~/.hammerspoon/Spoons/editWithEmacs.spoon/hammerspoon.el\u0026#34;)) (when (file-exists-p hammerspoon-module) (load hammerspoon-module))) ","permalink":"http://ianist.neocities.org/config/doom/","summary":"General Settings Bootstrappin' For some reason lexical-binding makes things faster. Let\u0026rsquo;s initialize all our files with this at the top.\nHere\u0026rsquo;s config.el\u0026rsquo;s\n;;; $DOOMDIR/config.el -*- lexical-binding: t; -*- ;; DO NOT EDIT THIS FILE DIRECTLY ;; This is a file generated from a literate programing source file located at ;; `$HOME/.config/doom/config.org`. You should make any changes there and ;; regenerate it from Emacs org-mode using org-babel-tangle (C-c C-v t) Here\u0026rsquo;s init.","title":"Doom Emacs Configuration"},{"content":"This is my Github workflow. This file is a literate file that uses org-tangle to \u0026ldquo;compile\u0026rdquo; the needed yaml for Github.\nWorkflows publish.yaml Triggers Step one, we declare the workflow, and when it can be triggered.\nIn this case, the workflow triggers on changes to the master branch:\nname: GitHub Actions Vercel Production Deployment on: push: branches: - master We also are going to trigger when the upstream NextJS project, Sylvan, is updated, so we added a repository_dispatch trigger:\nrepository_dispatch: types: - sylvan-update And lastly, let\u0026rsquo;s add the workflow_dispatch trigger so we can kick off the build manually:\nworkflow_dispatch: Jobs Next we declare the jobs, in this case there is only one, Deploy-Production, it run\u0026rsquo;s on the latest version of Ubuntu, and it has a number of steps\u0026hellip;\njobs: Deploy-Production: runs-on: ubuntu-latest steps: Steps Checkout and Cleanup\nWe actually have to checkout two different repos. First let\u0026rsquo;s checkout the Sylvan repo to the root of our action:\n- name: Checkout Sylvan uses: actions/checkout@v2 with: repository: pard68/sylvan And then we want to remove the .git/ from the Sylvan project, otherwise Vercel will link the deployment to the wrong repo (you can read more about this in the blog post I wrote detailing the matter):\n- name: \u0026#34;Remove the Sylvan .git dir\u0026#34; run: \u0026#34;rm -rf .git\u0026#34; Now we checkout the org repo (which is the repo this action runs it, but you cannot view it since it\u0026rsquo;s a private repo), and we check it out to the org/ directory within the Sylvan project:\n- name: Checkout Org content uses: actions/checkout@v2 with: path: org/ Now we\u0026rsquo;re going to remove any files that I have marked as private:\n- name: \u0026#34;Remove files marked :PRIVATE: t\u0026#34; run: \u0026#39;find ./org -type f -exec grep -q \u0026#34;^:PRIVATE: t\\$\u0026#34; {} \\; -delete\u0026#39; Vercel needs a .git directory, so we will copy the directory from the org project into the root of the action, this way the deployments will be marked with the right commits:\n- name: Move the org repo .git dir to root to satisfy Vercel run: mv org/.git ./ And we remove the remote because Vercel keeps trying to link directly to this repo and that breaks stuff:\n- name: Expunge git remote run: git remote remove origin Getting the right files to the right places\nNext on the list of steps, we want to move everything in the org directory (and thus repo) into the public directory of the Sylvan project. We do this because any text files, or pictures will now be accessible by the server. We include the .attach directory because this is where attachments are, and I like to ues attachments for pictures, especially screenshots and pictures I take on my phone:\n- name: Merge org content with default Sylvan content run: mv org/* public/ - name: Move over needed, hidden directories run: mv org/.attach/ public/ Setting the Timezone\nI don\u0026rsquo;t think this actually is doing anything, but I\u0026rsquo;m setting it just in case\u0026hellip;\n- name: Set Timezone uses: szenius/set-timezone@v1.0 with: timezoneLinux: \u0026#34;Americas/Chicago\u0026#34; Build and Deploy!\nNow we install the Vercel CLI, pull in the Vercel project, build it, and push it. This is all right from the Vercel documents with no changes:\n- name: Install Vercel CLI run: npm install --global vercel@latest - name: Pull Vercel Environment Information run: vercel pull --yes --environment=production --token=${{ secrets.VERCEL_TOKEN }} - name: Build Project Artifacts run: vercel build --prod --token=${{ secrets.VERCEL_TOKEN }} - name: Deploy Project Artifacts to Vercel run: vercel deploy --prebuilt --prod --token=${{ secrets.VERCEL_TOKEN }} ","permalink":"http://ianist.neocities.org/config/github-workflow/","summary":"This is my Github workflow. This file is a literate file that uses org-tangle to \u0026ldquo;compile\u0026rdquo; the needed yaml for Github.\nWorkflows publish.yaml Triggers Step one, we declare the workflow, and when it can be triggered.\nIn this case, the workflow triggers on changes to the master branch:\nname: GitHub Actions Vercel Production Deployment on: push: branches: - master We also are going to trigger when the upstream NextJS project, Sylvan, is updated, so we added a repository_dispatch trigger:","title":"Github Workflow"},{"content":"ˈɡrɒk, grohk, transitive verb\nTo understand profoundly through intuition or empathy To have or to have acquired an intuitive understanding of; to know (something) without having to think To get the meaning of something \u0026ldquo;Grok\u0026rdquo; is a neologism coined in the book Stranger in a Strange Land by Robert A. Heinlein. I\u0026rsquo;ve never read the book, the term is ingrained enough into the world of software that I\u0026rsquo;m confident most people who use the term have never even heard of the book or know the word\u0026rsquo;s origins.\n","permalink":"http://ianist.neocities.org/loci/grok/","summary":"ˈɡrɒk, grohk, transitive verb\nTo understand profoundly through intuition or empathy To have or to have acquired an intuitive understanding of; to know (something) without having to think To get the meaning of something \u0026ldquo;Grok\u0026rdquo; is a neologism coined in the book Stranger in a Strange Land by Robert A. Heinlein. I\u0026rsquo;ve never read the book, the term is ingrained enough into the world of software that I\u0026rsquo;m confident most people who use the term have never even heard of the book or know the word\u0026rsquo;s origins.","title":"grok"},{"content":"These are my literate dotfiles. To compile and deploy these files you need to run (org-bable-tangle). There are no additional settings that are needed to tangle this. Running the above command will create all the needed directories and files, and compile the configs specified here and deploy them to the right locations. To update a config file, make the edits and then run the same (org-bable-tangle) function to update. Because of the :cache yes directive, Org-Babel will only change files if there are changes.\nLog \u0026lt;2022-08-25 Thu\u0026gt; I\u0026rsquo;ve \u0026ldquo;disabled\u0026rdquo; yabai, spacebar, and those related things. I\u0026rsquo;ll probably eventually delete them from this doc or something like that. Yabai is not playing nicely and I\u0026rsquo;m looking for an alternative solution, likely something with just Hammerspoon alone.\n\u0026lt;2022-08-18 Thu\u0026gt; I\u0026rsquo;m trying to decide how to incorporate my doom config into this. I really want to be orgish and use one file for all my configurations. I suspect that might not eventually and ultimately be what I do though. Nonetheless, I can try!\nI\u0026rsquo;m also not sure if I want to use the README.org for my config, but it does have the advantage of being displayed automatically by nearly all VCS GUIs in the world.\nConfigurations Boilerplate This is a brief header explaining that these files are generated with org-babel and should not be directly edited. This block doesn\u0026rsquo;t actually do anything by itself, but it can be included in other files by including it in other blocks with \u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt;.\n# This file was generated from a literate dotfiles config. # This file should not be directly edited. Instead edit # the literate-dotfiles repo and then tangle the file. # The repo can be found at: # https://github.com/pard68/literate-dotfiles Shell First let\u0026rsquo;s setup the various ZSH files that the shell expects. We like A S T H E T I C home directories, so we\u0026rsquo;re going to hide our ZSH config files in the \\~/.config/ dir like the good Lord intended.\nEnvironment Variables Sadly, ZSH sorta sucks and the .zshenv has to live in the home directory, so we\u0026rsquo;re going to set that up and tell it to look in .config/zsh/ for all the rest of the zsh config files we might use. So we\u0026rsquo;ll setup the zshenv file to have all the right XDG settings, plus point all the various other things that need to be told to use .config to do so.\nFirst let\u0026rsquo;s add the boilderplate header to this file:\n\u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; XDG and Zsh paths\nexport XDG_CONFIG_HOME=\u0026#34;$HOME/.config\u0026#34; export XDG_DATA_HOME=\u0026#34;$HOME/.local/share\u0026#34; export XDG_DATA_HOME=\u0026#34;$HOME/.cache/\u0026#34; export ZDOTDIR=\u0026#34;$XDG_CONFIG_HOME/zsh\u0026#34; export HISTFILE=\u0026#34;$ZDOTDIR/zhistory\u0026#34; export DOOM_EMACS=$XDG_CONFIG_HOME/emacs export DOOMDIR=$XDG_CONFIG_HOME/doom HIST\nWe want to make sure our history is nice and long. It\u0026rsquo;s 2022, so we shouldn\u0026rsquo;t worry too much about disk space or RAM\u0026hellip; I hope\nexport HISTSIZE=10000 export SAVEHIST=10000 EDITOR\nLet\u0026rsquo;s set our editor quickly so we can make sure we\u0026rsquo;re never far away from emacs.\nexport EDITOR=\u0026#34;/usr/local/bin/emacsclient\u0026#34; export VISUAL=\u0026#34;/usr/local/bin/emacsclient\u0026#34; export ALTERNATE_EDITOR=\u0026#34;/usr/local/bin/nvim\u0026#34; $PATH\nWe\u0026rsquo;ll setup some $PATH stuff now too. I really hate editing one-liner $PATH exports, so we\u0026rsquo;ll just do one per line, why not? Maybe there is a cool way to use org and iterate over a list of path values and concatenate them together, but IDK how to do that right now\u0026hellip;\nexport PATH=\u0026#34;$HOME/.cargo/bin:$PATH\u0026#34; export PATH=\u0026#34;$HOME/go/bin:$PATH\u0026#34; export PATH=\u0026#34;$HOME/.local/bin:$PATH\u0026#34; export PATH=\u0026#34;/usr/local/bin:$PATH\u0026#34; export PATH=\u0026#34;/usr/bin:$PATH\u0026#34; export PATH=\u0026#34;/bin:$PATH\u0026#34; export PATH=\u0026#34;/usr/local/sbin:$PATH\u0026#34; export PATH=\u0026#34;/usr/local/go/bin/:$PATH\u0026#34; export PATH=\u0026#34;$XDG_CONFIG_HOME/emacs/bin/:$PATH\u0026#34; export PATH=\u0026#34;$HOME/.npm-global/bin:$PATH\u0026#34; Zshrc The zshrc file has to be prefixed with a . for Zsh to pick it up. It sorta sucks\u0026hellip; but it\u0026rsquo;s whatever I\u0026rsquo;ll never really interact with that file.\nFirst let\u0026rsquo;s add the boilderplate header to this file:\n\u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; A E S T H E T I C\nYour terminal, in Technicolor!\nautoload -U colors \u0026amp;\u0026amp; colors PROMPT=\u0026#34;(%B%T%b) %B%F{magenta}λ%f%b \u0026#34; Zsh Options\nHere is a list of all the zsh options that can be set.\nsetopt HIST_SAVE_NO_DUPS setopt INC_APPEND_HISTORY setopt HIST_IGNORE_SPACE setopt AUTO_CD setopt AUTO_PUSHD setopt PUSHD_IGNORE_DUPS setopt PUSHD_SILENT REPORTTIME=3 Ghetto Jump\nThere are some neat \u0026ldquo;jump\u0026rdquo; plugins like j and z. But we\u0026rsquo;re just going to DIWhy it!\nalias d=\u0026#39;dirs -v\u0026#39; for index ({1..9}) alias \u0026#34;$index\u0026#34;=\u0026#34;cd + ${index}\u0026#34;; unset index Completion\nautoload -U compinit zstyle \u0026#39;:completion:*\u0026#39; menu select completer _complete _correct _approximate zmodload zsh/complist compinit _comp_options+=(globdots) Aliases Before we make an alias file, let\u0026rsquo;s source them from the zshrc file.\nsource $ZDOTDIR/aliases Okay, now onto the aliases file. First let\u0026rsquo;s add the boilderplate header to this file:\n\u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; Clear\nalias c!=clear Git\nalias g=git alias ga=\u0026#34;git add\u0026#34; alias ga.=\u0026#34;git add .\u0026#34; alias gb=\u0026#34;git branch\u0026#34; alias gbd=\u0026#34;git branch -D\u0026#34; alias gc=\u0026#34;git commit\u0026#34; alias gcm=\u0026#34;git commit -m\u0026#34; alias gca=\u0026#34;git commit --amend\u0026#34; alias gcm!!=\u0026#34;git add .; git commit -m \u0026#34;Update!\u0026#34;; git push\u0026#34; alias gcl=\u0026#34;git clone\u0026#34; alias gco=\u0026#34;git checkout\u0026#34; alias gd=\u0026#34;git diff\u0026#34; alias gl=\u0026#34;git log\u0026#34; alias gm=\u0026#34;git merge\u0026#34; alias gpl=\u0026#34;git pull\u0026#34; alias gps=\u0026#34;git push\u0026#34; alias gps!=\u0026#34;git push --force\u0026#34; alias gpsu=\u0026#34;git push -u origin master\u0026#34; alias gri=\u0026#34;git rebase -i\u0026#34; alias gs=\u0026#34;git status\u0026#34; ls\nalias l=\u0026#34;ls\u0026#34; alias la=\u0026#34;ls -a\u0026#34; alias ll=\u0026#34;ls -l\u0026#34; alias lla=\u0026#34;ls -la\u0026#34; mbsync\nalias mbsync=\u0026#34;mbsync -c ~/.config/isync/mbsyncrc\u0026#34; Kitty Kitty is the terminal. I prefer to use. I don\u0026rsquo;t use it much, with emacs around, but sometimes it\u0026rsquo;s nice to have a real terminal. Before we start, let\u0026rsquo;s add the boilerplate file header:\n\u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; Font Set the font\nfont_family scientifica font_size 16.0 Default Options open_url_with default enable_audio_bell no tab_bar_style powerline background_opacity 0.9 Mappings map ctrl+h neighboring_window left map ctrl+j neighboring_window down map ctrl+k neighboring_window up map ctrl+l neighboring_window right map ctrl+] next_tab map ctrl+[ previious_tab Theme Set the theme we\u0026rsquo;ll use\ninclude theme.conf And then define that theme. This is not something I created. I got it from here.\n\u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; Background and Foreground Colors\nforeground #B4BDC3 background #1C1917 selection_foreground #B4BDC3 selection_background #3D4042 Cursor Colors\ncursor #C4CACF cursor_text_color #1C1917 Tab Colors\nactive_tab_foreground #B4BDC3 active_tab_background #65435E inactive_tab_foreground #B4BDC3 inactive_tab_background #352F2D Color Definitions\nBlack\ncolor0 #1C1917 color8 #403833 Red\ncolor1 #DE6E7C color9 #E8838F Green\ncolor2 #819B69 color10 #8BAE68 Yellow\ncolor3 #B77E64 color11 #D68C67 Blue\ncolor4 #6099C0 color12 #61ABDA Magenta\ncolor5 #B279A7 color13 #CF86C1 Cyan\ncolor6 #66A5AD color14 #65B8C1 White\ncolor7 #B4BDC3 color15 #888F94 Hammerspoon I really only want Hammerspoon around on Mac, but I\u0026rsquo;m not currently sure how to best add that conditional nature into org-babel. So we\u0026rsquo;ll just install it all and if it\u0026rsquo;s not Mac\u0026hellip; well it\u0026rsquo;ll just never get used. Also, should be noted that Hammerspoon doesn\u0026rsquo;t seem to respect the XDG stuff and just puts its config directory in the root of your home dir like a pig.\nBoilerplate --[[ \u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; --]] Hammerspoon CLI Tool\nFirst thing, let\u0026rsquo;s install the hs cli tool so we can call Hammerspoon from the terminal if we need to. By default it\u0026rsquo;ll install to the /usr/local/bin.\nrequire\u0026#39;hs.ipc\u0026#39; hs.ipc.cliInstall() Logger\nlocal configLog = hs.logger.new(\u0026#39;Config\u0026#39;) Config Reloader\nAnd let\u0026rsquo;s setup auto reloading for hammerspoon. First the reload function, stolen from here:\nreloadConfig = { watcher = {}, } function reloadConfig.reloader(paths) doReload = false for _, file in pairs(paths) do if file:sub(-4) == \u0026#34;.lua\u0026#34; then print(\u0026#34;A Lua configuration file has changed. Reloading...\u0026#34;) doReload = true end end if not doReload then print(\u0026#34;No Lua configuration files have changed. Skipping reload...\u0026#34;) return end hs.reload() end And then we register a path watcher, provide a method to stop the watcher, and then kick it off:\nhammerspoonDir = os.getenv(\u0026#34;HOME\u0026#34;) .. \u0026#34;/.hammerspoon/\u0026#34; function reloadConfig.init() reloadConfig.watcher = hs.pathwatcher.new(hammerspoonDir, reloadConfig.reloader) end function reloadConfig.start() reloadConfig.watcher:start() end function reloadConfig.stop() reloadConfig.watcher:stop() end reloadConfig.init() reloadConfig.start() Screens Let\u0026rsquo;s setup the names of our screens for use later\u0026hellip;\nlaptopScreen = hs.screen.find(\u0026#34;Built%-in Retina Display\u0026#34;) leftScreen = hs.screen.find(\u0026#34;DELL P2414H\u0026#34;) Keybindings Next let\u0026rsquo;s setup a few default key combos.\nlocal meh = {\u0026#34;ctrl\u0026#34;, \u0026#34;alt\u0026#34;, \u0026#34;shift\u0026#34;} local super = {\u0026#34;ctrl\u0026#34;, \u0026#34;alt\u0026#34;, \u0026#34;cmd\u0026#34;} local hyper = {\u0026#34;ctrl\u0026#34;, \u0026#34;alt\u0026#34;, \u0026#34;cmd\u0026#34;, \u0026#34;shift\u0026#34;} I\u0026rsquo;m lazy, so we\u0026rsquo;re going to setup some abstraction over the default hammerspoon hotkey function so I have to type even less!\nfunction bk(...) hs.hotkey.bind(...) end Since a lot of keybindings are going to be related to running external commands, we should setup some abstraction to make interacting with HS\u0026rsquo; api for running external commands a bit easier \u0026ndash; my inspiration for this from here:\nfunction strToTable(str) t = {} for word in string.gmatch(str, \u0026#34;[^%s]+\u0026#34;) do table.insert(t, word) end return t end function runCmd(bin, strArgs) args = strToTable(strArgs) local t = hs.task.new(bin, function(err, stdout, stderr) print(err, stdout, stderr) end, function(task, stdout, stderr) print(stdout, stderr) return true end, args) t:start() if tOut then print(tOut) end if tErr then print(tErr) end end function r(b, a) return function() runCmd(b, a) end end Toggle Dark Mode\nIt\u0026rsquo;d be nice to toggle the system dark-mode with a key. But to do that we need to write a little applescript first:\ntell application \u0026#34;System Events\u0026#34; tell appearance preferences set dark mode to not dark mode end tell end tell Great, and now for the keybinding:\nbk(hyper, \u0026#34;d\u0026#34;, \u0026#34;Toggle: Dark-mode\u0026#34;, function() hs.osascript.applescriptFromFile(\u0026#34;applescripts/toggle-dark-mode.applescript\u0026#34;) end) Spaces Management spaces = require(\u0026#39;hs.spaces\u0026#39;) function listAllSpaces() local allSpaces = {} for _, displaySpaces in pairs(hs.spaces.allSpaces()) do for _, spaceID in pairs(displaySpaces) do table.insert(allSpaces, spaceID) end end return allSpaces end existingSpaces = listAllSpaces() spacesMenu = hs.menubar.new() spacesMenu:setTitle(\u0026#34;👨‍🚀\u0026#34;) spacesMenu:setTooltip(\u0026#34;Spaces Manager\u0026#34;) spacesTable = { www = { id = {}, -- keep this empty layout = {}, -- keep this empty emoji = \u0026#34;🌐\u0026#34;, screen = laptopScreen, binding = {mod = super, key = \u0026#34;b\u0026#34;}, apps = { { id = {}, name =\u0026#34;Vivaldi\u0026#34;, layout = hs.layout.maximized, binding = {mod = super, key = \u0026#34;v\u0026#34;}, }, { id = {}, name =\u0026#34;Firefox\u0026#34;, layout = hs.layout.maximized, binding = {mod = super, key = \u0026#34;f\u0026#34;}, }, }, }, terminal = { id = {}, -- keep this empty layout = {}, -- keep this empty emoji = \u0026#34;💻️\u0026#34;, screen = leftScreen, binding = nil, apps = { { id = {}, name =\u0026#34;kitty\u0026#34;, layout = hs.layout.maximized, binding = {mod = super, key = \u0026#34;q\u0026#34;}, }, }, }, editor = { id = {}, -- keep this empty layout = {}, -- keep this empty emoji = \u0026#34;📜️\u0026#34;, screen = leftScreen, binding = nil, apps = { { id = {}, name =\u0026#34;emacs\u0026#34;, layout = hs.layout.maximized, binding = {mod = super, key = \u0026#34;e\u0026#34;}, }, }, }, comms = { id = {}, -- keep this empty layout = {}, -- keep this empty emoji = \u0026#34;🛰️\u0026#34;, screen = leftScreen, binding = {mod = super, key = \u0026#34;c\u0026#34;}, apps = { { id = {}, name =\u0026#34;Slack\u0026#34;, layout = hs.layout.maximized, binding = {mod = super, key = \u0026#34;s\u0026#34;}, }, { id = {}, name = \u0026#34;Microsoft Teams\u0026#34;, layout = hs.layout.maximized, binding = {mod = super, key = \u0026#34;t\u0026#34;}, }, { id = {}, name = \u0026#34;Discord\u0026#34;, layout = hs.layout.maximized, binding = {mod = super, key = \u0026#34;r\u0026#34;}, }, { id = {}, name = \u0026#34;Signal\u0026#34;, layout = hs.layout.maximized, binding = {mod = super, key = \u0026#34;g\u0026#34;}, }, }, } } function tableDiff(a, b) -- Find the difference between two tables -- Assumes that there is only one difference local aa = {} for k,v in pairs(a) do aa[v]=true end for k,v in pairs(b) do aa[v]=nil end for k,v in pairs(aa) do return k end end function setupSpace(spaceName, spaceSettings) spaces.addSpaceToScreen() local newSpaces = listAllSpaces() local spaceId = tableDiff(newSpaces, existingSpaces) spacesTable[spaceName].id = spaceId if spaceSettings.binding then print(spaceId) bk(spaceSettings.binding.mod, spaceSettings.binding.key, \u0026#34;Goto \u0026#34; .. spaceName, function() spaces.gotoSpace(spaceId) end) end existingSpaces = newSpaces for _, app in pairs(spaceSettings.apps) do hs.application.launchOrFocus(app.name) app.id = hs.application.find(app.name) table.insert(spacesTable[spaceName].layout, { app.id, nil, spaceSettings.screen, app.layout, nil, nil }) if app.binding then bk(app.binding.mod, app.binding.key, \u0026#34;Goto \u0026#34; .. app.name, function() hs.application.launchOrFocus(app.name) end) end end hs.layout.apply(spaceSettings.layout) end function initSpaces(st) for spaceName, spaceSettings in pairs(st) do setupSpace(spaceName, spaceSettings) end end function len(t) local n = 0 for _, _ in pairs(t) do n = n + 1 end return n end function cleanUnusedSpaces() local allSpaces = listAllSpaces() local allWindows = {} local spacesWindowData = {} local hasFullscreen = false for _, sid in pairs(allSpaces) do local windows = spaces.windowsForSpace(sid) for _, i in pairs(windows) do allWindows[i] = (allWindows[i] or 0) + 1 end if spaces.spaceType(sid) == \u0026#39;fullscreen\u0026#39; then hasFullscreen = true end spacesWindowData[sid] = windows end for sid, data in pairs(spacesWindowData) do remove = false local copy = data for index, id in pairs(data) do if allWindows[id] \u0026gt; 1 then copy[index] = nil end end if not hasFullscreen and len(copy) \u0026lt; 3 or hasFullscreen and len(copy) \u0026lt; 4 then configLog.i(\u0026#34;Removing\u0026#34;, sid) spaces.removeSpace(sid) end end end initSpaces(spacesTable) cleanUnusedSpaces() Then let\u0026rsquo;s cleanup the empty spaces that might have been created.\nfunction clearEmptySpaces() local allSpaces = listAllSpaces() end clearEmptySpaces() Spoons Bootstrap\nspoonManager\nspoonManager is a tool that lets us install Spoons from within Hammerspoon, which means we don\u0026rsquo;t need to include the Spoon\u0026rsquo;s source in our literate config!\nI was using this to install all spoons but then I noticed that HS has a Spoon for installing spoons and it\u0026rsquo;s a bit more feature-complete than SpoonManager, so I\u0026rsquo;m just using this to install dependencies that SpoonInstall doesn\u0026rsquo;t like (ie stackline) and SpoonInstall itself and then we\u0026rsquo;ll let everything else use SpoonInstall.\nLet\u0026rsquo;s create a table of spoons we want to manage. It\u0026rsquo;s going to be empty for now, but entries should include a table name of the spoon and the git repo or zip path of the spoon like such:\n{ name = \u0026#34;spoon\u0026#39;s name\u0026#34;, uri = \u0026#34;git repo\u0026#34;, path = \u0026#34;path relative to hammerspoon\u0026#39;s dir\u0026#34;, // this is an optional value and if it isn\u0026#39;t provided, just install into the Spoons/ dir } spoonList = { { name = \u0026#34;SpoonInstall\u0026#34;, uri = \u0026#34;https://github.com/Hammerspoon/Spoons/raw/master/Spoons/SpoonInstall.spoon.zip\u0026#34; } } \u0026lt;\u0026lt;VimModeSpoon\u0026gt;\u0026gt; \u0026lt;\u0026lt;editWithEmacsSpoon\u0026gt;\u0026gt; And of course, let\u0026rsquo;s create spoonManager and then kick off the install process\nspoonManager = {} \u0026lt;\u0026lt;spoonManagerInstallZip\u0026gt;\u0026gt; function spoonManager.installGit(spoon) gitCloneTask =hs.task.new(\u0026#39;/usr/bin/git\u0026#39;, function(a,b,c) return end, {\u0026#34;clone\u0026#34;, spoon.uri, spoon.path}) gitCloneTask:waitUntilExit() gitCloneTask:start() end function spoonManager.install(spoon) ext = string.sub(spoon.uri, -4) reloadConfig.stop() if ext == \u0026#34;.git\u0026#34; then spoonManager.installGit(spoon) end if ext == \u0026#34;.zip\u0026#34; then spoonManager.installZip(spoon) else configLog.e(\u0026#34;Unknown file type, not installing \u0026#34; .. spoon.name) end reloadConfig.start() end function spoonManager.installMaybe() if spoonList == nil then return end for _, spoon in pairs(spoonList) do install_path = \u0026#34;Spoons/\u0026#34; .. spoon.name .. \u0026#34;.spoon\u0026#34; installed = nil if spoon.path then install_path = spoon.path installed, _ = hs.fs.mkdir(spoon.path) installed = not installed if not installed then hs.fs.rmdir(spoon.path) end else installed = hs.spoons.isInstalled(spoon.name) end spoon.path = install_path if not installed then configLog.i(\u0026#34;Installing \u0026#34; .. spoon.name .. \u0026#34; from uri: \u0026#34; .. spoon.uri) hs.alert(\u0026#34;Install \u0026#34; .. spoon.name .. \u0026#34;. This will just take a moment!\u0026#34;) spoonManager.install(spoon) else configLog.i(spoon.name .. \u0026#34; already installed!\u0026#34;) end end end spoonManager.installMaybe() This part of spoonManager is not my work, I took it from the SpoonInstall source and I took it mostly to install SpoonInstall, since it\u0026rsquo;s part of a monorepo and I\u0026rsquo;d rather steal their function for installing something from a zip than try to figure out the best to do sparse git stuff.\n-- Execute a command and return its output with trailing EOLs trimmed. If the command fails, an error message is logged. function spoonManager.x(cmd, errfmt, ...) local output, status = hs.execute(cmd) if status then local trimstr = string.gsub(output, \u0026#34;\\n*$\u0026#34;, \u0026#34;\u0026#34;) return trimstr else return nil end end function spoonManager._installSpoonFromZipURL(urlparts, status, body, headers) local success=nil if (status \u0026lt; 100) or (status \u0026gt;= 400) then print(\u0026#34;Error downloading %s. Error code %d: %s\u0026#34;, urlparts.absoluteString, status, body or \u0026#34;\u0026lt;none\u0026gt;\u0026#34;) else -- Write the zip file to disk in a temporary directory local tmpdir=spoonManager.x(\u0026#34;/usr/bin/mktemp -d\u0026#34;, \u0026#34;Error creating temporary directory to download new spoon.\u0026#34;) if tmpdir then local outfile = string.format(\u0026#34;%s/%s\u0026#34;, tmpdir, urlparts.lastPathComponent) local f=assert(io.open(outfile, \u0026#34;w\u0026#34;)) f:write(body) f:close() -- Check its contents - only one *.spoon directory should be in there output = spoonManager.x(string.format(\u0026#34;/usr/bin/unzip -l %s \u0026#39;*.spoon/\u0026#39; | /usr/bin/awk \u0026#39;$NF ~ /\\\\.spoon\\\\/$/ { print $NF }\u0026#39; | /usr/bin/wc -l\u0026#34;, outfile), \u0026#34;Error examining downloaded zip file %s, leaving it in place for your examination.\u0026#34;, outfile) if output then if (tonumber(output) or 0) == 1 then -- Uncompress the zip file local outdir = string.format(\u0026#34;%s/Spoons\u0026#34;, hs.configdir) if spoonManager.x(string.format(\u0026#34;/usr/bin/unzip -o %s -d %s 2\u0026gt;\u0026amp;1\u0026#34;, outfile, outdir), \u0026#34;Error uncompressing file %s, leaving it in place for your examination.\u0026#34;, outfile) then -- And finally, install it using Hammerspoon itself print(\u0026#34;Downloaded and installed %s\u0026#34;, urlparts.absoluteString) spoonManager.x(string.format(\u0026#34;/bin/rm -rf \u0026#39;%s\u0026#39;\u0026#34;, tmpdir), \u0026#34;Error removing directory %s\u0026#34;, tmpdir) success=true end else print(\u0026#34;The downloaded zip file %s is invalid - it should contain exactly one spoon. Leaving it in place for your examination.\u0026#34;, outfile) end end end end return success end function spoonManager.installSpoonFromZipURL(url) local urlparts = hs.http.urlParts(url) local dlfile = urlparts.lastPathComponent if dlfile and dlfile ~= \u0026#34;\u0026#34; and urlparts.pathExtension == \u0026#34;zip\u0026#34; then a,b,c=hs.http.get(url) return spoonManager._installSpoonFromZipURL(urlparts, a, b, c) else print(\u0026#34;Invalid URL %s, must point to a zip file\u0026#34;, url) return nil end end function spoonManager.installZip(spoon) spoonManager.installSpoonFromZipURL(spoon.uri) end SpoonInstall\nSpoonInstall is how we\u0026rsquo;re going to install 99% of spoons, because it\u0026rsquo;s a lot better than spoonManager.\nFirst let\u0026rsquo;s setup some stuff:\nhs.loadSpoon(\u0026#39;SpoonInstall\u0026#39;) This will block HS, but I think it\u0026rsquo;s worth it\u0026hellip;\nspoon.SpoonInstall.use_syncinstall = true I\u0026rsquo;m lazy\u0026hellip;\nInstall = spoon.SpoonInstall Color Picker\nThis is a tool to help manage picking colors and selecting their value\nInstall:andUse(\u0026#34;ColorPicker\u0026#34;, { hotkeys = { show = { hyper, \u0026#34;c\u0026#34; } }, config = { show_in_menubar = false, }, start = true, }) Clipboard Tool\nIt\u0026rsquo;s a clipboard manager for text.\nInstall:andUse(\u0026#34;ClipboardTool\u0026#34;, { config = { pase_on_select = true, show_copied_alert = false, show_in_menubar = false, }, hotkeys = { toggle_clipboard = { hyper, \u0026#34;v\u0026#34; } }, start = true, }) Vim Mode\nThis spoon lets you have vim style movement in all the places!\ntable.insert(spoonList, { name = \u0026#34;VimMode\u0026#34;, uri = \u0026#34;https://github.com/dbalatero/VimMode.spoon.git\u0026#34;, path = \u0026#34;Spoons/VimMode.spoon\u0026#34; }) The settings are pretty straightforward\u0026hellip;\n-- VimMode = hs.loadSpoon(\u0026#39;VimMode\u0026#39;) -- vim = VimMode:new() -- vim:disableForApp(\u0026#39;Emacs\u0026#39;):enterWithSequence(\u0026#39;jk\u0026#39;) Edit With Emacs\nThis spoon allows me to take any text area and edit that text area with emacs, and then send the text edited in Emacs back to that textbox when done. This spoon is from the GitHub user dmgerman.\ntable.insert(spoonList, { name = \u0026#34;editWithEmacs\u0026#34;, uri = \u0026#34;https://github.com/dmgerman/editWithEmacs.spoon.git\u0026#34;}) Load Spoon and Add Bindings\nhs.loadSpoon(\u0026#34;editWithEmacs\u0026#34;) if spoon.editWithEmacs then local bindings = { edit_selection = { hyper, \u0026#34;e\u0026#34; }, edit_all = { meh, \u0026#34;e\u0026#34; } } spoon.editWithEmacs:bindHotkeys(bindings) end hammerspoon.el\nFor this to work we need to load some elisp with (load \u0026quot;~/.hammerspoon/Spoons/editWithEmacs.spoon/hammerspoon.el\u0026quot;). Make sure to put that somewhere into your emacs config.\n;;; editWithEmacs.el --- communicate with hammerspoon to editWithEmacs anywhere ;; Copyright (C) 2021 Daniel M. German \u0026lt;dmg@turingmachine.org\u0026gt; ;; Jeremy Friesen \u0026lt;emacs@jeremyfriesen.com\u0026gt; ;; ;; Author: Daniel M. German \u0026lt;dmg@turingmachine.org\u0026gt; ;; Jeremy Friesen \u0026lt;emacs@jeremyfriesen.com\u0026gt; ;; ;; Maintainer: Daniel M. German \u0026lt;dmg@turingmachine.org\u0026gt; ;; ;; Keywords: hammerspoon, os x ;; Homepage: https://github.com/dmgerman/editWithEmacs.spoon ;; GNU Emacs is free software: you can redistribute it and/or modify ;; it under the terms of the GNU General Public License as published by ;; the Free Software Foundation, either version 3 of the License, or ;; (at your option) any later version. ;; GNU Emacs is distributed in the hope that it will be useful, ;; but WITHOUT ANY WARRANTY; without even the implied warranty of ;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the ;; GNU General Public License for more details. ;; You should have received a copy of the GNU General Public License ;; along with GNU Emacs. If not, see \u0026lt;https://www.gnu.org/licenses/\u0026gt;. ;;; Commentary: ;; Use emacs and hammerspoon to edit text in any input box in os x ;; See: https://github.com/dmgerman/editWithEmacs.spoon ;; ;;; Code: (defvar hammerspoon-buffer-mode \u0026#39;markdown-mode \u0026#34;Name of major mode for hammerspoon editing\u0026#34;) (defvar hammerspoon-buffer-name \u0026#34;*hammerspoon_edit*\u0026#34; \u0026#34;Name of the buffer used to edit in emacs.\u0026#34;) (defvar hammerspoon-edit-minor-map nil \u0026#34;Keymap used in hammer-edit-minor-mode.\u0026#34;) (unless hammerspoon-edit-minor-map (let ((map (make-sparse-keymap))) (define-key map (kbd \u0026#34;C-c C-c\u0026#34;) \u0026#39;hammerspoon-edit-end) (define-key map (kbd \u0026#34;C-c m\u0026#34;) \u0026#39;hammerspoon-toggle-mode) (define-key map (kbd \u0026#34;C-c h\u0026#34;) \u0026#39;hammerspoon-test) ;; for testing (setq hammerspoon-edit-minor-map map))) (define-minor-mode hammerspoon-edit-minor-mode \u0026#34;Minor mode to help with editing with hammerspoon\u0026#34; :global nil :lighter \u0026#34;_hs-edit_\u0026#34; :keymap hammerspoon-edit-minor-map ;; if disabling `undo-tree-mode\u0026#39;, rebuild `buffer-undo-list\u0026#39; from tree so ;; Emacs undo can work ) (defun hammerspoon-toggle-mode () \u0026#34;Toggle from Markdown Mode to Org Mode.\u0026#34; (interactive) (if (string-equal \u0026#34;markdown-mode\u0026#34; (format \u0026#34;%s\u0026#34; major-mode)) (org-mode) (markdown-mode)) (hammerspoon-edit-minor-mode)) (defun hammerspoon-do (command) \u0026#34;Send Hammerspoon the given COMMAND.\u0026#34; (interactive \u0026#34;sHammerspoon Command:\u0026#34;) (setq hs-binary (executable-find \u0026#34;hs\u0026#34;)) (if hs-binary (call-process hs-binary nil 0 nil \u0026#34;-c\u0026#34; command) (message \u0026#34;Hammerspoon hs executable not found. Make sure you hammerspoon has loaded the ipc module\u0026#34;))) (defun hammerspoon-alert (message) \u0026#34;Show given MESSAGE via Hammerspoon\u0026#39;s alert system.\u0026#34; (hammerspoon-do (concat \u0026#34;hs.alert.show(\u0026#39;\u0026#34; message \u0026#34;\u0026#39;, 1)\u0026#34;))) (defun hammerspoon-test () \u0026#34;Show a test message via Hammerspoon\u0026#39;s alert system. If you see a message, Hammerspoon is working correctly.\u0026#34; (interactive) (hammerspoon-alert \u0026#34;Hammerspoon test message...\u0026#34;)) (defun hammerspoon-edit-end () \u0026#34;Send, via Hammerspoon, contents of buffer back to originating window.\u0026#34; (interactive) (mark-whole-buffer) (call-interactively \u0026#39;kill-ring-save) (hammerspoon-do (concat \u0026#34;spoon.editWithEmacs:endEditing(False)\u0026#34;)) (previous-buffer)) (defun hammerspoon-edit-begin () \u0026#34;Receive, from Hammerspoon, text to edit in Emacs\u0026#34; (interactive) (let ((hs-edit-buffer (get-buffer-create hammerspoon-buffer-name))) (switch-to-buffer hs-edit-buffer) (erase-buffer) ; Ensure we have a clean buffer (yank) (funcall hammerspoon-buffer-mode) (hammerspoon-edit-minor-mode) (message \u0026#34;Type C-c C-c to send back to originating window\u0026#34;) (exchange-point-and-mark))) isync/mbsync This is my isync/mbsync config. I\u0026rsquo;m using the password store for secrets when applicable.\n\u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; Personal Protonmail Accounts I have a number of protonmail accounts. They have virtually the same settings, even the same password. I am not using the password store for the Proton email accounts because this password is only applicable to the Proton bridge on my machine and I don\u0026rsquo;t have a concern about storing it in plaintext since it\u0026rsquo;s already available in plaintext on the machine anyway. I am just storing it in a txt file so that this is a bit more portable.\nThere must be a empty line between accounts. So for this to work we need one empty line at the end of each config. org-tangle removes trailing whitespace, so this means we need to add a new line and then an empty comment. There might be a better way to do this but I am unaware of it.\nTODO Make this programmatic, so it just needs a list of email addresses ipringle@protonmail.com\nIMAPAccount ipringle-protonmail Host 127.0.0.1 Port 1143 User pard@0x44.pw PassCmd \u0026#34;cat ~/.config/isync/proton-bridge-password\u0026#34; SSLType NONE IMAPStore ipringle-protonmail-remote Account ipringle-protonmail MaildirStore ipringle-protonmail-local Subfolders Verbatim Path ~/mail/ipringle@protonmail.com/ Inbox ~/mail/ipringle@protonmail.com/INBOX Channel ipringle-protonmail Far :ipringle-protonmail-remote: Near :ipringle-protonmail-local: Patterns * CopyArrivalDate yes Create Both Expunge Both SyncState * # ian@dapringles.com\nIMAPAccount ian-dapringles Host 127.0.0.1 Port 1143 User ian@dapringles.com PassCmd \u0026#34;cat ~/.config/isync/proton-bridge-password\u0026#34; SSLType NONE IMAPStore ian-dapringles-remote Account ian-dapringles MaildirStore ian-dapringles-local Subfolders Verbatim Path ~/mail/ian@dapringles.com/ Inbox ~/mail/ian@dapringles.com/INBOX Channel ian-dapringles Far :ian-dapringles-remote: Near :ian-dapringles-local: Patterns * CopyArrivalDate yes Create Both Expunge Both SyncState * # pard@0x44.pw\nIMAPAccount pard-0x44 Host 127.0.0.1 Port 1143 User pard@0x44.pw PassCmd \u0026#34;cat ~/.config/isync/proton-bridge-password\u0026#34; SSLType NONE IMAPStore pard-0x44-remote Account pard-0x44 MaildirStore pard-0x44-local Subfolders Verbatim Path ~/mail/pard@0x44.pw/ Inbox ~/mail/pard@0x44.pw/INBOX Channel pard-0x44 Far :pard-0x44-remote: Near :pard-0x44-local: Patterns * CopyArrivalDate yes Create Both Expunge Both SyncState * # Work Gmail This is my config for my work gmail account. I\u0026rsquo;m not tangling this because using Gmail with mbsync/mu4e is super annoying and I cannot get sending to work for some reason. Plus we\u0026rsquo;re migrating away from Gmail so it\u0026rsquo;s less important.\n# ian@hydrobuilder.com IMAPAccount work-gmail Host imap.gmail.com User ian@hydrobuilder.com PassCmd \u0026#34;pass email/ian@hydrobuilder.com\u0026#34; AuthMechs LOGIN SSLType IMAPS IMAPStore gmail-remote Account gmail MaildirStore gmail-local Path ~/mail/hydrobuilder/ Inbox ~/mail/hydrobuilder/INBOX Subfolders Verbatim Channel gmail Far :gmail-remote: Near :gmail-local: CopyArrivalDate yes Patterns * ![Gmail]* \u0026#34;[Gmail]/Sent Mail\u0026#34; \u0026#34;[Gmail]/Trash\u0026#34; Create Both Expunge Both SyncState * # Work Outlook Nothing fancy here, should be noted that the password is an app-password because of 2fa requirements.\n# i.pringle@hbhold.com IMAPAccount work Host outlook.office365.com User i.pringle@hbhold.com PassCmd \u0026#34;pass email/i.pringle@hbhold.com\u0026#34; AuthMechs LOGIN SSLType IMAPS IMAPStore work-remote Account work MaildirStore work-local Path ~/mail/ipringle@hbhold.com/ Inbox ~/mail/ipringle@hbhold.com/Inbox Subfolders Verbatim Channel work Far :work-remote: Near :work-local: Patterns \u0026#34;INBOX\u0026#34; * CopyArrivalDate yes Create Both Sync all Expunge Both SyncState * # yabai #:header-args: :tangle ~/.config/yabai/yabairc :comments link :mkdirp yes :padline no :noweb tangle :cache yes :tangle-mode (identity #o755)\nBoilerplate #!/usr/bin/env sh \u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; Let\u0026rsquo;s make sure yabai is auto-loading the scripting additions on start \u0026ndash; this requires that we can run sudo yabai commands without a password.\nyabai -m signal --add event=dock_did_restart action=\u0026#34;sudo yabai --load-sa\u0026#34; Config Defaults\nWe\u0026rsquo;re going to just leave the mouse totally out of the picture:\n# global settings yabai -m config mouse_follows_focus off yabai -m config focus_follows_mouse off And let\u0026rsquo;s make new windows spawn to the left so that they don\u0026rsquo;t take over the master window and to the bottom:\nyabai -m config window_placement first_child yabai -m config window_topmost off The default layout:\nyabai -m config layout bsp Let\u0026rsquo;s make room for the bar.\nBAR_HEIGHT=$(spacebar -m config height) yabai -m config external_bar all:$BAR_HEIGHT:0 These are the things we always want to float:\nyabai -m rule --add app=\u0026#39;^System Information$\u0026#39; manage=off yabai -m rule --add app=\u0026#39;^System Preferences$\u0026#39; manage=off yabai -m rule --add title=\u0026#39;Preferences$\u0026#39; manage=off yabai -m rule --add title=\u0026#39;Settings$\u0026#39; manage=off FIN\necho \u0026#34;yabai configuration loaded..\u0026#34; Layouts\nBSP Float Stacked\nWhen a space is stacked, these rules apply \u0026ndash; to make it work nicely with stackline\nyabai -m signal --add event=window_created action=\u0026#34;~/.config/yabai/refresh.sh\u0026#34; yabai -m signal --add event=window_destroyed action=\u0026#34;~/.config/yabai/refresh.sh\u0026#34; And of course refresh.sh, which I stole from these two lovely comm-ents: ##+begin_src shell :tangle ~/.config/yabai/refresh.sh :comments link :mkdirp yes :padline no :noweb tangle :cache yes :tangle-mode (identity #o755)\n#!/usr/bin/env bash number_of_windows=$(yabai -m query --windows --space | /usr/local/bin/jq \u0026#39;length\u0026#39;) number_of_stacked=$(yabai -m query --windows --space | /usr/local/bin/jq -c \u0026#39;map(select(.\u0026#34;stack-index\u0026#34; != 0)) | length\u0026#39;) currspace=$(yabai -m query --spaces --space | /usr/local/bin/jq \u0026#39;.index\u0026#39;) padding=0 spadding=40 [[ \u0026#34;$number_of_windows\u0026#34; -eq 1 ]] \u0026amp;\u0026amp; padding=0 [[ \u0026#34;$number_of_stacked\u0026#34; = 0 ]] \u0026amp;\u0026amp; spadding=$padding yabai -m config --space \u0026#34;$currspace\u0026#34; top_padding $padding yabai -m config --space \u0026#34;$currspace\u0026#34; bottom_padding $padding yabai -m config --space \u0026#34;$currspace\u0026#34; left_padding $spadding yabai -m config --space \u0026#34;$currspace\u0026#34; right_padding $padding yabai -m config --space \u0026#34;$currspace\u0026#34; window_gap $padding Keybindings\nFirst, some abstraction to make calling into Yabai a bit simpler \u0026ndash; I stole this from here: ##+begin_src lua :tangle ~/.hammerspoon/init.lua\nfunction yabaiCmd(args) yBin = \u0026#34;/usr/local/bin/yabai\u0026#34; runCmd(yBin, args) end function y(a) return function() yabaiCmd(a) end end And now the hotkeys!\nLet\u0026rsquo;s setup a reload hotkey for Yabai: ##+begin_src lua :tangle ~/.hammerspoon/init.lua\n-- bk(super, \u0026#34;r\u0026#34;, \u0026#34;Yabai Reloaded\u0026#34;, r(\u0026#34;/bin/launchctl\u0026#34;, {\u0026#34;kickstart\u0026#34;, \u0026#34;-k\u0026#34;, \u0026#34;gui/${UID}/homebrew.mxcl.yabai\u0026#34;})) bk(super, \u0026#34;r\u0026#34;, \u0026#34;Yabai: Reloaded\u0026#34;, r(\u0026#34;/usr/local/bin/brew\u0026#34;, \u0026#34;services restart yabai\u0026#34;)) Now some spaces related hotkeys! ##+begin_src lua :tangle ~/.hammerspoon/init.lua\nbk(super, \u0026#34;n\u0026#34;, \u0026#34;Yabai: Created a new space\u0026#34;, y(\u0026#34;-m space --create\u0026#34;)) It\u0026rsquo;d be nice to be able to toggle the various layouts for a space: ##+begin_src lua :tangle ~/.hammerspoon/init.lua\nbk(super, \u0026#34;s\u0026#34;, \u0026#34;Yabai: Stacked Layout\u0026#34;, y(\u0026#34;-m space --layout stack\u0026#34;)) bk(super, \u0026#34;b\u0026#34;, \u0026#34;Yabai: BSP Layout\u0026#34;, y(\u0026#34;-m space --layout bsp\u0026#34;)) bk(super, \u0026#34;f\u0026#34;, \u0026#34;Yabai: Floating Layout\u0026#34;, y(\u0026#34;-m space --layout float\u0026#34;)) How about some stacking related one?! ##+begin_src lua :tangle ~/.hammerspoon/init.lua\nThese some bindings someone created so that you can use the same keys for cycling yabai stacked and non-stacked spaces. I need to convert this to Lua so we can do this with Hammerspoon.\ncmd + shift - k : if [ \u0026#34;$(yabai -m query --spaces --space | jq -r \u0026#39;.type\u0026#39;)\u0026#34; = \u0026#34;stack\u0026#34; ]; then (yabai -m window --focus stack.next || yabai -m window --focus stack.first); else yabai -m window --focus next || yabai -m window --focus first; fi cmd + shift - j : if [ \u0026#34;$(yabai -m query --spaces --space | jq -r \u0026#39;.type\u0026#39;)\u0026#34; = \u0026#34;stack\u0026#34; ]; then (yabai -m window --focus stack.prev || yabai -m window --focus stack.last); else yabai -m window --focus prev || yabai -m window --focus last; fi Named Spaces\nComms Space\nThis is the space for my communication apps, namely Slack, Teams, Signal, and Discord\nYabai Utils stackline\nThis is a spoon for Hammerspoon and it will help us visualize yabai\u0026rsquo;s stacked windows\ntable.insert(spoonList, { name = \u0026#34;stackline\u0026#34;, uri = \u0026#34;git@github.com:pard68/stackline.git\u0026#34;, path = \u0026#34;stackline\u0026#34; }) Stackline isn\u0026rsquo;t technically a spoon but that might be changing, and since I\u0026rsquo;d rather just pretend it is than write a special case in the spoonManager just for stackline, we\u0026rsquo;re just gonna have to get a little hacky\u0026hellip; ##+begin_src lua :tangle ~/.hammerspoon/init.lua\nsl = require(\u0026#39;stackline\u0026#39;) sl:init() We also need to add the following to the yabai config so that stackline redraws can be triggered with yabai signals to speed up the drawing process. These signals came from the these two issues in the stackline repo; \u0026ldquo;Trigger refreshes using yabail -m signal\u0026rdquo; and \u0026ldquo;Reduce redraw lag when switched spaces\u0026rdquo; ##+begin_src shell :tangle ~/.config/yabai/yabairc\nyabai -m signal --add event=space_changed action=\u0026#34;hs -c \u0026#39;stackline.manager:update({forceRedraw = true})\u0026#39;\u0026#34; yabai -m signal --add event=display_added action=\u0026#34;hs -c \u0026#39;stackline.refresh()\u0026#34; yabai -m signal --add event=display_removed action=\u0026#34;hs -c \u0026#39;stackline.refresh()\u0026#34; yabai -m signal --add event=display_changed action=\u0026#34;hs -c \u0026#39;stackline.refresh()\u0026#34; yabai -m signal --add event=space_changed action=\u0026#34;hs -c \u0026#39;stackline.refresh()\u0026#34; yabai -m signal --add event=application_visible action=\u0026#34;hs -c \u0026#39;stackline.refresh()\u0026#34; yabai -m signal --add event=application_hidden action=\u0026#34;hs -c \u0026#39;stackline.refresh()\u0026#34; yabai -m signal --add event=window_created action=\u0026#34;hs -c \u0026#39;stackline.refresh()\u0026#34; yabai -m signal --add event=window_destroyed action=\u0026#34;hs -c \u0026#39;stackline.refresh()\u0026#34; These two lines help with some issues when you switch focus with yabai commands. I found them in this issue comment. ##+begin_src shell :tangle ~/.config/yabai/yabairc\nyabai -m signal --add event=window_created title=\u0026#34;Hammerspoon Console\u0026#34; action=\u0026#34;yabai -m window \\$(yabai -m query --windows | jq \u0026#39;.[] | select(.app==\\\u0026#34;Hammerspoon\\\u0026#34; and .name==\\\u0026#34;Hammerspoon Console\\\u0026#34;) | .id\u0026#39;) --minimize\u0026#34; yabai -m rule --add app=\u0026#34;Hammerspoon\u0026#34; title=\u0026#34;\u0026#34; manage=on layer=\u0026#34;above\u0026#34; sticky=on Keybindings ymsp\nThe Yabai Master-stack Plugin is a tool that takes the BSP mode of Yabai and instead switches Yabai to a master-stack layout like in dwm. This means there is one main window which takes up the majority of the screen and then the remaining windows take up an equal portion of the remaining portion of the screen. To use ymsp we need to install it from npm:\nnpm install --global yabai-master-stack-plugin And then add the following config settings for ymsp: ##+begin_src json :tangle ~/.config/ymsp/ymsp.config.json :comments no :mkdirp yes :padline no :cache yes\n{ \u0026#34;yabaiPath\u0026#34;: \u0026#34;/usr/local/bin/yabai\u0026#34; } Finally to connect ymsp to yabai we need to add the following signals:\nyabai -m signal --add event=window_created action=\u0026#39;ymsp window-created\u0026#39; yabai -m signal --add event=application_launched action=\u0026#39;ymsp window-created\u0026#39; yabai -m signal --add event=window_moved action=\u0026#39;ymsp window-moved\u0026#39; ymsp on-yabai-start spacebar #:header-args: :tangle ~/.config/spacebar/spacebarrc :comments link :mkdirp yes :padline no :noweb tangle :cache yes :tangle-mode (identity #o755)\nBoilerplate #!/usr/bin/env sh \u0026lt;\u0026lt;boilerplate-file-header\u0026gt;\u0026gt; Config Defaults\nspacebar -m config position top spacebar -m config height 26 spacebar -m config title on spacebar -m config spaces on spacebar -m config clock on spacebar -m config power on spacebar -m config padding_left 20 spacebar -m config padding_right 20 spacebar -m config spacing_left 25 spacebar -m config spacing_right 15 spacebar -m config text_font \u0026#34;Helvetica Neue:Bold:12.0\u0026#34; spacebar -m config icon_font \u0026#34;Font Awesome 6 Free:Solid:12.0\u0026#34; spacebar -m config background_color 0xff202020 spacebar -m config foreground_color 0xffa8a8a8 spacebar -m config power_icon_color 0xffcd950c spacebar -m config battery_icon_color 0xffd75f5f spacebar -m config dnd_icon_color 0xffa8a8a8 spacebar -m config clock_icon_color 0xffa8a8a8 spacebar -m config power_icon_strip   spacebar -m config space_icon • spacebar -m config space_icon_color 0xffffab91 spacebar -m config space_icon_color_secondary 0xff78c4d4 spacebar -m config space_icon_color_tertiary 0xfffff9b0 spacebar -m config space_icon_strip 1 2 3 4 5 6 7 8 9 10 spacebar -m config clock_icon  spacebar -m config dnd_icon  spacebar -m config clock_format \u0026#34;%y/%m/%d %R\u0026#34; echo \u0026#34;spacebar configuration loaded..\u0026#34; License Literate Dotfiles -- Collection of configuration files written and compiled with org-mode Copyright (C) 2022 Ian S. Pringle This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see \u0026lt;https://www.gnu.org/licenses/\u0026gt;. ","permalink":"http://ianist.neocities.org/config/dotfiles/","summary":"These are my literate dotfiles. To compile and deploy these files you need to run (org-bable-tangle). There are no additional settings that are needed to tangle this. Running the above command will create all the needed directories and files, and compile the configs specified here and deploy them to the right locations. To update a config file, make the edits and then run the same (org-bable-tangle) function to update. Because of the :cache yes directive, Org-Babel will only change files if there are changes.","title":"Literate Dotfiles"},{"content":"About This is the literate file that defines a server. All of the source files for Lit Server are defined here and are \u0026ldquo;tangled\u0026rdquo; together with org-tangle. This is the only file that should ever be edited (other than the README).\nREADME.org It seems a little weird to build an org file, with an org file. I\u0026rsquo;m really only doing this because the server directory is entry built from this org file, but the intention is that I compile the files in server locally and commit them. There is a chance that someone \u0026ndash; including future me \u0026ndash; might come upon this server directory and be uninformed about it\u0026rsquo;s creation and use.\n#+title: Readme NOTICE: This file and all files in this directory were built with =server.org= and should not be directly edited! This is the server dir used to deploy my bitranchlabs server infra. Deploy There are a number of ways that this could be deployed. I think I will eventually settle on gitlab-ci, but incase I want to deploy from local I have come up with a solution using the package (emacs-ssh-deploy).\ndeploy.sh This is a simple shell script to deploy my server. It assumes all the files that are needed can be found in the remote path /opt/lit-server and it needs to be run as root.\ncp /home/ian/lit-server/Caddyfile /etc/caddy/Caddyfile cp /home/ian/lit-server/docker-compose.yml /opt/composed/docker-compose.yml cd /opt/composed/ docker-compose up -d systemctl reload caddy Makefile Emacs can run make files, that might be enough for local deployments\u0026hellip; This sort of works actually, but the deploy-remote stuff seems to just always fail and then I have to ssh into the machine and run that exact same command. Sort of ridiculous tbh\u0026hellip;\nCaddy has a --watch flag, might be worth looking at using that to watch for changes to the config. But it could also be a disaster, I\u0026rsquo;m not sure\u0026hellip;\n.PHONE: all deploy deploy-local install sync setup, clean all: sync deploy-remote clean: ssh ian@server-01.bitranclabs.net rm -rf ~/lit-server deploy-local: cp /home/ian/lit-server/Caddyfile /etc/caddy/Caddyfile cp /home/ian/lit-server/docker-compose.yml /opt/composed/docker-compose.yml cd /opt/composed/ docker-compose up -d systemctl reload caddy deploy-remote: ssh root@server-01.bitranchlabs.net bash /home/ian/lit-server/deploy.sh install: deploy-remote setup: ssh ian@server-01.bitranchlabs.net mkdir -p /home/ian/lit-server ssh root@server-01.bitranchlabs.net mkdir -p /opt/composed sync: setup @echo \u0026#34;Publishing to remote\u0026#34; rsync -chazve ssh ~/org/server/ ian@server-01.bitranchlabs.net:~/lit-server/ emacs-ssh-deploy ARCHIVE Caddy We\u0026rsquo;re going to try using Caddy for the server for this. I was using Traefik in docker and it was just crapping out, so I gave up after much frustration and decided to put the server outisde of Docker. Caddy is a very straightforward server to setup but has a lot of features. Just an aside, I\u0026rsquo;m using \u0026ldquo;shell\u0026rdquo; for the src type on these blocks because org doesn\u0026rsquo;t know what a Caddyfile type is, and shell and Caddy share the same comment types (ie # ).\nGlobals Here are the global defaults for Caddy. Since Caddy comes with TLS by default, all we have to do is give it an email address:\n{ email ian@dapringles.com } These aren\u0026rsquo;t exactly \u0026ldquo;global\u0026rdquo; but they\u0026rsquo;re some defaults that\u0026rsquo;ll be used with mosta/all subsequent server configurations. First up \u0026ldquo;encoding\u0026rdquo;, some of these settings are the defaults, I am adding them for visibility:\n(encoding) { encode { zstd gzip } } Some default headers we want to upstream:\n(upheaders) { header_up X-Forwarded-Ssl on header_up X-Real-IP {remote} header_up X-Forwarded-Port {server_port} header_up X-Forwarded-Proto {scheme} header_up X-Url-Scheme {scheme} header_up X-Forwarded-Host {host} } Services For the most part, the services Caddy is going to be serving are defined in the section on each server and then noweb will tangle them all into the Caddyfile for us.\nFile Server I think it would be nice to have a fileserver for anything I want to share or access. I\u0026rsquo;m not sure I will keep this up but it\u0026rsquo;s here for the time being.\nThis isn\u0026rsquo;t working right now actually\u0026hellip;\nfiles.bitranchlabs.net { file_server browse { root * /static hide .git precompressed zstd br gzip import upheaders } import encoding } Services One thing of note here, since we\u0026rsquo;re exposing all the docker containers to localhost, we have to keep track of their ports or else there could be a collision and something will not be happy.\nBoilerplate We\u0026rsquo;ll be using docker-compose for most services.\nversion: \u0026#39;3.7\u0026#39; services: whoami This is a pretty worthless service beyond just basic troubleshooting and sanity checking. It\u0026rsquo;ll also serve as something of a \u0026ldquo;template\u0026rdquo; for creating other services I guess.\ndocker-compose.yaml First we need docker-compose file:\nwhoami: image: docker.io/containous/whoami:latest restart: always ports: - 8000:80 Caddyfile This is the definition of this service in our Caddyfile:\nwhoami.bitranchlabs.net { reverse_proxy http://127.0.0.1:8000 { import upheaders } import encoding } Resume site This is my resume website, usually it can be found at https://ianpringle.org/. It can also be found at https://resume.bitranchlabs.net. No real reason for both, just something I like to do I guess\u0026hellip;\ndocker-compose.yaml Make sure there is no collision on local host and then match that with port 80 inside the container:\nresume: image: registry.gitlab.com/pard/resume-site:latest restart: always ports: - 8001:80 Caddyfile This is the definition of this service in our Caddyfile:\nresume.bitranchlabs.net ianpringle.org { reverse_proxy http://127.0.0.1:8001 { import upheaders } import encoding } Ungovernable World docker-compose.yaml Make sure there is no collision on local host and then match that with port 80 inside the container:\nungovernable-world: image: docker.io/pard68/ungovernable restart: always ports: - 8002:80 Caddyfile This is the config for the actual site, we put the redirect block above it so that it can be properly redirected.\nungovernable.world { reverse_proxy http://127.0.0.1:8002 { import upheaders } import encoding } Bitranchlabs Blog docker-compose.yaml\nMake sure there is no collision on local host and then match that with port 80 inside the container:\nbrl-www: image: registry.gitlab.com/bitranchlabs/www:latest restart: always ports: - 8003:80 Caddyfile\nThis is for redirecting some URLs to the desired site.\nbitranchlabs.com, bitranchlabs.net, www.bitranchlabs.net, bitranchlabs.org, www.bitranchlabs.org { redir https://bitranchlabs.com{uri} } This is the config for the actual site, we put the redirect block above it so that it can be properly redirected.\nwww.bitranchlabs.com { reverse_proxy http://127.0.0.1:8003 { import upheaders } import encoding } API I use the bitranchlabs.com domain for some APIs. Because I route by path for these, the setup can be a bit complex (it isn\u0026rsquo;t currently, but if I add API that\u0026rsquo;ll change). In Caddy we will need to use a directive called handle to manage directing ports by path. These directives need to all be in the same block, so we\u0026rsquo;ll use some noweb for that.\napi.bitranchlabs.com { \u0026lt;\u0026lt;brl-your-face-api\u0026gt;\u0026gt; import encoding } Your Face API\ndocker-compose.yaml\nMake sure there is no collision on local host and then match that with port 80 inside the container:\nbrl-your-face-api: image: registry.gitlab.com/pard/yourface-api:master-1 restart: always ports: - 8004:80 Caddyfile\nThis maps that path specified to the port. We are using Caddy\u0026rsquo;s handle_path directive here because we want to strip that path being requested since the upstream microserve isn\u0026rsquo;t aware of paths and thinks it\u0026rsquo;s being served from /\nhandle_path /api/v1/yourface { reverse_proxy http://127.0.0.1:8004 { import upheaders } } Firewall ferm\u0026rsquo;s configuration is pretty straightforward, you tables and chains, you can specific a domain (ip, ipv6) for the table, and you can target specific predefined policies (ACCEPT, DROP, etc.). I am not a networking guy or a firewall guru, but I think I have enough understanding to write something\u0026hellip;\n\u0026lt;\u0026lt;anti-ddos-func\u0026gt;\u0026gt; The filter Table We\u0026rsquo;ll write to the default table filter:\ntable filter { And we\u0026rsquo;ll start with the INPUT chain:\nchain INPUT { Seems like you start with a your catch-all, in this case I want to DROP anything that isn\u0026rsquo;t explicitly allowed, hopefully this will prevent some attacks just by not advertising this server exists.\npolicy DROP; I am still not entirely sure what \u0026ldquo;connection tracking\u0026rdquo; is or means, but this rules controls this and here is a brief synopsis of the idea.\nmod state state INVALID DROP; mod state state (ESTABLISHED RELATED) ACCEPT; This is rather self-explanatory, we allow local connections through the firewall, it probably is safe to say this won\u0026rsquo;t hurt, if an attacker is coming from local we got bigger fish to fry\u0026hellip;\ninterface lo ACCEPT; Contrary to the default settings, I do not want to respond to ICMP:\nproto icmp icmp-type echo-request DROP; Now for the things that this server needs to have open. The use of dport refers to the intended destination of the request.\nproto tcp dport (http https) ACCEPT; We also want to accept SSH connections. I might change this in the future to be over a port other than the default, but for now 22 is good enough!\nproto tcp dport ssh ACCEPT; Everything else is dropped. We also want to allow all outgoing connections, though I might look into changing this eventually and would like to log all outgoing connections at the very least. And since we\u0026rsquo;re a web server and are not in the business of routing for other machines, we will drop all FOWARD requests.\n\u0026lt;\u0026lt;anti-ddos-func-call\u0026gt;\u0026gt; } chain OUTPUT policy ACCEPT; chain FORWARD policy DROP; } Anti-DDoS logic To mitigate DDoS attacks, we can define a function to track requests over time for a specfic IP address and if it exceeds a given threshold, we block that address for some length of time. This comes right from the examples document, except I removed the IP address exceptions logic because I don\u0026rsquo;t have a static address and the address I do get is sometimes shared with other Starlink customers.\n@def \u0026amp;ANTIDDOS($ports, $seconds, $hits, $time) = { proto tcp dport $ports @subchain \u0026#34;ddos_check\u0026#34; { mod conntrack ctstate (ESTABLISHED RELATED) ACCEPT; mod recent name \u0026#34;ddos_check\u0026#34; rcheck seconds $seconds hitcount $hits @subchain \u0026#34;ddos\u0026#34; { mod recent set name \u0026#34;ddos\u0026#34; NOP; DROP; } mod recent set name \u0026#34;ddos_check\u0026#34; NOP; mod recent name \u0026#34;ddos\u0026#34; rcheck seconds $time DROP; mod recent name \u0026#34;ddos\u0026#34; remove NOP; mod conntrack ctstate NEW ACCEPT; DROP; } } To use this we want to do two things, first we need to define this before our filter table declaration and in that table we want to replace the line(s) that declare ports we accept with the following which says \u0026ldquo;check requests to ports 22, 88, and 443 to see if the requester has made more than 50 requests in the last three seconds, and if so, drop their request and ban them for 86400 seconds.\u0026rdquo; The docs say to do (22, 80, 443) however if you try to do that ferm will give a warning and rejects the configuration file. According to the error, arrays should not be comma separated but should just have spaces. I have opened an issue for this and hopefully it\u0026rsquo;ll be resolved before anyone else gets confused.\n\u0026amp;ANTIDDOS((22 80 443), 50, 3, 86400); IPv6 My ipv6 filter table is also right from the docs, except I am dropping ICMP and I\u0026rsquo;m routing traffic through the anti-DDoS logic.\ndomain ip6 table filter { chain INPUT { policy DROP; mod state state INVALID DROP; mod state state (ESTABLISHED RELATED) ACCEPT; interface lo ACCEPT; proto ipv6-icmp DROP; \u0026amp;ANTIDDOS((22 80 443), 50, 3, 86400); } chain OUTPUT policy ACCEPT; chain FORWARD policy DROP; } Utilities (org-tangle-into-dir) This is a helper function to make tangling a little simpler. This is also in my emacs config, but it\u0026rsquo;s here because if this file is to be run on by someone else or with a minimal config, this function would be required still. I got this from here.\n(defun org-tangle-into-dir (sub-path) \u0026#34;Expand the SUB-PATH into the directory given by the tangle-dir property if that property exists, else use the `default-directory\u0026#39;.\u0026#34; (expand-file-name sub-path (or (org-entry-get (point) \u0026#34;tangle-dir\u0026#34; \u0026#39;inherit) (default-directory)))) ","permalink":"http://ianist.neocities.org/config/server/","summary":"About This is the literate file that defines a server. All of the source files for Lit Server are defined here and are \u0026ldquo;tangled\u0026rdquo; together with org-tangle. This is the only file that should ever be edited (other than the README).\nREADME.org It seems a little weird to build an org file, with an org file. I\u0026rsquo;m really only doing this because the server directory is entry built from this org file, but the intention is that I compile the files in server locally and commit them.","title":"Server"}]